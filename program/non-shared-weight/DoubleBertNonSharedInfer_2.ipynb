{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "#from transformers import *\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/train.csv').fillna(' ')\n",
    "test = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/test.csv').fillna(' ')\n",
    "sub = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/sample_submission.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n",
       "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
       "       'url', 'category', 'host', 'question_asker_intent_understanding',\n",
       "       'question_body_critical', 'question_conversational',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False\n",
    "                current_segment_id = 1#新增 \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=512-1, \n",
    "                t_max_len=70-1, q_max_len=219, a_max_len=219):#???\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "        t = t[:t_new_len]\n",
    "        q = norm_token_length(q, q_new_len)\n",
    "        a = norm_token_length(a, a_new_len)\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def norm_token_length(tokens, l):\n",
    "    if len(tokens) > l:\n",
    "        head = l//2\n",
    "        tail = l - head\n",
    "        return tokens[:head] + tokens[-tail:]\n",
    "    else:\n",
    "        return tokens[:l]\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, cate, max_sequence_length=512):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    #stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_1 = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n",
    "    stoken_2 = [\"[CLS]\"] + [cate]+title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    input_ids = _get_ids(stoken_1, tokenizer, max_sequence_length)\n",
    "    input_ids_2 = _get_ids(stoken_2, tokenizer, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken_1, max_sequence_length)\n",
    "    input_segments_2 = _get_segments(stoken_2, max_sequence_length)\n",
    "    \n",
    "    #return [input_ids, input_segments]\n",
    "    return input_ids, input_segments,input_ids_2,input_segments_2\n",
    "\n",
    "def convert_row(row,pretrained_weights):\n",
    "    #c = f\"[{row['category'].lower()}]\"\n",
    "\n",
    "    if pretrained_weights == \"bert-base-uncased\":\n",
    "        c = f\"[{row['category'].lower()}]\"#type:str\n",
    "    elif pretrained_weights == \"bert-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    elif pretrained_weights == \"xlnet-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    t, q, a = title = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]#type:str\n",
    "\n",
    "\n",
    "    t, q, a = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]\n",
    "    t, q, a = _trim_input(t, q, a)\n",
    "    #ids, segments = _convert_to_bert_inputs(t, q, a, c)\n",
    "    ids, segments, ids2, segments2 = _convert_to_bert_inputs(t, q, a, c)\n",
    "    #total_input=[np.array([[ids, segments]]),np.array([[ids2, segments2]])]\n",
    "    # total_input=[]\n",
    "    # print(np.array([[ids, segments]]).shape)\n",
    "    # total_input.append(np.array([[ids, segments]]))\n",
    "    # total_input.append(np.array([[ids2, segments2]]))\n",
    "    # return total_input\n",
    "    return np.array([[ids, segments, ids2, segments2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=\"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./token_model_config/tokenizer/\")\n",
    "#tokenizer.add_tokens(\"./bert_based_tokenizer/added_tokens.json\")\n",
    "#tokenizer.add_tokens(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data,data2, targets,targets2):\n",
    "    \n",
    "    # mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n",
    "    # bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])#??\n",
    "    mse = nn.MSELoss(reduction=\"none\")(data[:,:].sigmoid(), targets[:,:])\n",
    "    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:], targets[:,:])#??\n",
    "    \n",
    "    mse2 = nn.MSELoss(reduction=\"none\")(data2[:,:].sigmoid(), targets2[:,:])\n",
    "    bce2 = nn.BCEWithLogitsLoss(reduction='none')(data2[:,:], targets2[:,:])#??\n",
    "    #w =  targets[:,30:]\n",
    "    #loss = (mse*w).sum() + bce.sum()\n",
    "    loss = (mse).sum()+ bce.sum()+mse2.sum()+bce2.sum()\n",
    "    return loss\n",
    "\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, config_path=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(config_path) \n",
    "        \n",
    "        self.config.Q_labels = 21\n",
    "        self.config.A_labels = 9\n",
    "        self.config.output_hidden_states = True\n",
    "        self.n_use_layer = 4 #原本\n",
    "        #self.n_use_layer = 2\n",
    "        self.double_bert= 1\n",
    "        self.n_labels = self.config.num_labels\n",
    "        #self.config.save_pretrained(\"bert_based_config\")\n",
    "        #self.config.save_pretrained(output_dir+\"config\")\n",
    "        #self.bert = BertModel(config)\n",
    "        self.bert=AutoModel.from_config(self.config)\n",
    "        self.bert2=AutoModel.from_config(self.config)\n",
    "        #self.bert.save_pretrained('bert_based_model')\n",
    "        #self.bert.save_pretrained(output_dir+\"model\")\n",
    "        # self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n",
    "\n",
    "        self.dense1 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dense2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.Q_labels)\n",
    "        self.classifier2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.A_labels)\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None\n",
    "                ,input_ids2=None, attention_mask2=None, token_type_ids2=None,position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "\n",
    "        # outputs = self.bert(input_ids,\n",
    "        #                     attention_mask=attention_mask,\n",
    "        #                     token_type_ids=token_type_ids,\n",
    "        #                     position_ids=position_ids,\n",
    "        #                     head_mask=head_mask,\n",
    "        #                     inputs_embeds=inputs_embeds)\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                            )\n",
    "        outputs2 = self.bert2(input_ids2,\n",
    "                            attention_mask=attention_mask2,\n",
    "                            token_type_ids=token_type_ids2\n",
    "                            )\n",
    "        \n",
    "        #print(outputs[2][-1].shape)\n",
    "        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後4個layer的cls output concat在一起，把4個(8,768) concat，變成(8,3072) #原本\n",
    "        pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        #pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後2個layer的cls output concat在一起,把2個(8,768) concat，變成(8,1536)\n",
    "        #pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#同上\n",
    "        #double_pooled_output=torch.cat([pooled_output,pooled_output],dim=1)#(8,3072)\n",
    "        \n",
    "        pooled_output = self.dense1(pooled_output)\n",
    "        pooled_output = self.dense2(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        pooled_output2 = self.dense1(pooled_output2)\n",
    "        pooled_output2 = self.dense2(pooled_output2)\n",
    "        pooled_output2 = self.dropout(pooled_output2)\n",
    "        logits2 = self.classifier2(pooled_output2)\n",
    "\n",
    "        # double_pooled_output = self.dense1(double_pooled_output)\n",
    "        # double_pooled_output = self.dense2(double_pooled_output)\n",
    "        # double_pooled_output = self.dropout(double_pooled_output)\n",
    "        # logits = self.classifier(double_pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        outputs2 = (logits2,) + outputs2[2:]\n",
    "\n",
    "        return outputs,outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CustomBert(\"token_model_config/config/config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4324 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-cased'\n",
    "#X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].progress_apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#np.vstack(X_test).shape : (476, 2, 512)\n",
    "X_test = np.vstack(X_test).reshape((len(X_test), 2048))\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bert2): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dense2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=21, bias=True)\n",
       "  (classifier2): Linear(in_features=3072, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "model.bert2.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dir_target = \"../input/Optimize binning/bert-base-cased\"#\n",
    "\n",
    "cased_pred_lst = []\n",
    "for fold in range(10):\n",
    "    # if fold in [0,1,2,3,4,5,6,7]:\n",
    "    #     continue\n",
    "    #bert_path = f\"{model_dir_target}/bert-base-cased_f{fold}_best\"\n",
    "    #bert_path=f\"./DoubleBertBasedCase/bce_no_opt_binning/double-bert-based-case_f{fold}_best\"\n",
    "    bert_path=f\"./double/Bce-NoOptbinning2/double-bert-based-case_f{fold}_best\"\n",
    "    model.load_state_dict(torch.load(bert_path),strict=False)\n",
    "    \n",
    "    lst = []\n",
    "    for i, (x_batch,)  in enumerate(test_loader):\n",
    "        # input_ids = x_batch[:, :512]\n",
    "        # token_ids = x_batch[:, 512:]\n",
    "        input_ids = x_batch[:, :512]\n",
    "        token_ids = x_batch[:, 512:1024]\n",
    "        input_ids2 = x_batch[:, 1024:1536]\n",
    "        token_ids2 = x_batch[:, 1536:]\n",
    "        #pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n",
    "        pred, pred2 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n",
    "                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device))\n",
    "        total_y_pred=torch.cat((pred[0],pred2[0]),dim=1)\n",
    "        lst.append(total_y_pred.detach().cpu().squeeze().numpy())\n",
    "    test_pred = np.vstack(lst)#shape:(476, 30)\n",
    "    \n",
    "    cased_pred_lst.append(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.6993563 ,  0.7670746 , -1.825174  , ..., -3.7450032 ,\n",
       "          3.061132  ,  2.3422465 ],\n",
       "        [ 1.9363863 , -0.14408526, -6.081402  , ..., -2.3924952 ,\n",
       "         -2.9265656 ,  2.3032982 ],\n",
       "        [ 2.4231782 ,  0.8726376 , -4.1633663 , ..., -3.3403094 ,\n",
       "          2.2668905 ,  2.400673  ],\n",
       "        ...,\n",
       "        [ 1.8620958 , -0.5957431 , -4.60449   , ..., -2.1452355 ,\n",
       "          0.3978696 ,  2.3020225 ],\n",
       "        [ 2.767667  ,  1.2797338 , -3.7072284 , ..., -2.8156662 ,\n",
       "          3.3323324 ,  2.9924994 ],\n",
       "        [ 2.346679  ,  0.19289768, -3.7224844 , ..., -1.8901788 ,\n",
       "         -0.16990057,  2.1618726 ]], dtype=float32),\n",
       " array([[ 2.1642218 ,  0.23096873, -0.81077343, ..., -6.06564   ,\n",
       "          3.0391514 ,  2.5642312 ],\n",
       "        [ 2.115633  ,  0.1366932 , -5.9039545 , ..., -3.1842408 ,\n",
       "         -3.5807695 ,  2.007156  ],\n",
       "        [ 2.1958456 ,  0.7904063 , -4.384976  , ..., -4.598405  ,\n",
       "          2.1060512 ,  2.497077  ],\n",
       "        ...,\n",
       "        [ 1.6793042 , -0.76081365, -4.4036994 , ..., -3.1196315 ,\n",
       "         -0.45414045,  2.2434359 ],\n",
       "        [ 2.840436  ,  1.7767885 , -3.1660812 , ..., -3.1364765 ,\n",
       "          3.3547049 ,  3.2535152 ],\n",
       "        [ 2.536221  ,  0.24958341, -3.529326  , ..., -0.92866814,\n",
       "         -0.8289035 ,  2.47224   ]], dtype=float32),\n",
       " array([[ 2.384368  ,  0.25863805, -1.8602556 , ..., -6.2446938 ,\n",
       "          3.5057268 ,  2.7497275 ],\n",
       "        [ 2.1111176 ,  0.1691654 , -6.401795  , ..., -4.5454865 ,\n",
       "         -4.0812874 ,  2.1171606 ],\n",
       "        [ 2.1771812 ,  0.8529175 , -3.8643022 , ..., -3.937531  ,\n",
       "          1.7780328 ,  2.239986  ],\n",
       "        ...,\n",
       "        [ 1.6314151 , -0.8044537 , -4.66366   , ..., -4.9092216 ,\n",
       "         -0.9265313 ,  2.4272082 ],\n",
       "        [ 3.3109279 ,  1.7518072 , -3.6378243 , ..., -2.2644706 ,\n",
       "          3.759861  ,  3.5240493 ],\n",
       "        [ 2.4347255 ,  0.3146787 , -3.432053  , ..., -2.5268457 ,\n",
       "         -0.67870367,  2.1263657 ]], dtype=float32),\n",
       " array([[ 2.59988   ,  0.38231042, -1.9283353 , ..., -6.241823  ,\n",
       "          2.9135926 ,  2.874941  ],\n",
       "        [ 1.6486372 ,  0.23292881, -6.189262  , ..., -4.7904634 ,\n",
       "         -4.240046  ,  2.3957317 ],\n",
       "        [ 2.3192053 ,  1.1470877 , -4.137939  , ..., -4.105587  ,\n",
       "          2.2041757 ,  2.7472715 ],\n",
       "        ...,\n",
       "        [ 1.9518715 , -0.8031395 , -4.5702043 , ..., -5.4585505 ,\n",
       "          0.22238292,  2.7250874 ],\n",
       "        [ 3.4302    ,  1.966811  , -3.4623697 , ..., -3.4225593 ,\n",
       "          4.389933  ,  3.325048  ],\n",
       "        [ 2.0537717 ,  0.3927338 , -3.291374  , ..., -2.2124908 ,\n",
       "         -1.0770454 ,  2.046862  ]], dtype=float32),\n",
       " array([[ 2.2039757 ,  0.34492633, -2.429084  , ..., -6.1332135 ,\n",
       "          2.0626986 ,  3.147466  ],\n",
       "        [ 1.677402  ,  0.17365398, -6.198742  , ..., -3.07978   ,\n",
       "         -3.1850772 ,  2.3023336 ],\n",
       "        [ 2.2427478 ,  1.1836708 , -4.6497207 , ..., -4.759159  ,\n",
       "          1.1543998 ,  2.4025593 ],\n",
       "        ...,\n",
       "        [ 2.1174016 , -0.76030296, -4.951028  , ..., -4.983734  ,\n",
       "         -0.06350619,  2.2418861 ],\n",
       "        [ 3.107106  ,  1.9744909 , -3.510597  , ..., -2.7502708 ,\n",
       "          3.1468575 ,  3.4155495 ],\n",
       "        [ 2.0335693 ,  0.35309115, -2.736756  , ..., -3.1088228 ,\n",
       "         -0.5024182 ,  2.7317708 ]], dtype=float32),\n",
       " array([[ 2.5930078e+00,  5.2057290e-01, -2.3648517e+00, ...,\n",
       "         -6.1472163e+00,  1.6265109e+00,  2.8541808e+00],\n",
       "        [ 1.6877427e+00,  6.3004941e-03, -6.6986036e+00, ...,\n",
       "         -3.4159002e+00, -5.2805843e+00,  2.4329116e+00],\n",
       "        [ 1.8110769e+00,  1.1051476e+00, -4.5367527e+00, ...,\n",
       "         -3.5669222e+00,  1.3547784e+00,  3.0511022e+00],\n",
       "        ...,\n",
       "        [ 1.6776477e+00, -7.3848975e-01, -4.4953871e+00, ...,\n",
       "         -5.3748689e+00, -7.1714944e-01,  2.4190297e+00],\n",
       "        [ 3.5172994e+00,  1.8656025e+00, -3.8268275e+00, ...,\n",
       "         -3.6851904e+00,  3.6262810e+00,  3.2785800e+00],\n",
       "        [ 1.9094138e+00,  5.6400102e-01, -3.3360684e+00, ...,\n",
       "         -2.6641572e+00, -6.6662467e-01,  2.3253806e+00]], dtype=float32),\n",
       " array([[ 2.2281587 ,  0.6820624 , -1.7734526 , ..., -7.671956  ,\n",
       "          1.586966  ,  2.9535465 ],\n",
       "        [ 1.5136212 , -0.05084577, -6.4678884 , ..., -6.0111113 ,\n",
       "         -7.5536156 ,  1.5791404 ],\n",
       "        [ 1.5766257 ,  1.0628397 , -4.1057906 , ..., -3.2483435 ,\n",
       "          0.7741    ,  2.8384926 ],\n",
       "        ...,\n",
       "        [ 1.7113516 , -0.7649091 , -5.111641  , ..., -4.4475074 ,\n",
       "          0.19707462,  2.6724668 ],\n",
       "        [ 3.3030565 ,  1.842669  , -4.2801266 , ..., -2.7930088 ,\n",
       "          4.8947196 ,  3.051499  ],\n",
       "        [ 2.154262  ,  0.46342075, -4.014985  , ..., -1.3158295 ,\n",
       "         -0.9696198 ,  2.6626263 ]], dtype=float32),\n",
       " array([[ 2.6164489 ,  0.7353896 , -2.3939948 , ..., -4.481632  ,\n",
       "          3.065399  ,  4.1075587 ],\n",
       "        [ 1.5670507 ,  0.05723696, -7.2908015 , ..., -5.1233974 ,\n",
       "         -5.29082   ,  1.2832236 ],\n",
       "        [ 1.7337124 ,  1.0298926 , -4.637871  , ..., -2.3023088 ,\n",
       "          0.3030666 ,  3.4047914 ],\n",
       "        ...,\n",
       "        [ 1.634076  , -0.89440596, -5.526259  , ..., -5.3244    ,\n",
       "         -0.47272384,  2.7603889 ],\n",
       "        [ 3.621685  ,  1.6989737 , -4.3975677 , ..., -4.5222993 ,\n",
       "          3.0362928 ,  2.6639636 ],\n",
       "        [ 1.9543682 ,  0.44519028, -4.493746  , ..., -2.7425928 ,\n",
       "         -0.32634285,  3.0459533 ]], dtype=float32),\n",
       " array([[ 3.142735  ,  0.76286   , -2.4962409 , ..., -7.1027226 ,\n",
       "          2.1881003 ,  4.0437675 ],\n",
       "        [ 1.6612014 , -0.09099367, -7.805243  , ..., -4.4130244 ,\n",
       "         -3.2217522 ,  2.183517  ],\n",
       "        [ 1.8781852 ,  1.5961145 , -5.0713162 , ..., -4.7461386 ,\n",
       "          0.43433157,  3.1998496 ],\n",
       "        ...,\n",
       "        [ 1.7004082 , -0.85110706, -5.9141517 , ..., -3.700533  ,\n",
       "         -0.05216195,  2.572738  ],\n",
       "        [ 3.6788905 ,  1.7520696 , -4.7295895 , ..., -4.5377593 ,\n",
       "          4.594072  ,  2.8306627 ],\n",
       "        [ 1.7991937 ,  0.3236501 , -3.4267871 , ..., -1.8034245 ,\n",
       "         -0.8350085 ,  2.8994324 ]], dtype=float32),\n",
       " array([[ 2.6783063 ,  0.60304904, -2.6328824 , ..., -8.424651  ,\n",
       "          3.2275763 ,  3.8103814 ],\n",
       "        [ 1.9850011 , -0.05844418, -7.832484  , ..., -5.3283677 ,\n",
       "         -8.060108  ,  1.5443873 ],\n",
       "        [ 1.6566267 ,  1.1589851 , -5.013866  , ..., -3.9588308 ,\n",
       "          0.38382456,  3.1845655 ],\n",
       "        ...,\n",
       "        [ 1.6391245 , -0.93221915, -5.8279333 , ..., -3.2165072 ,\n",
       "          0.02890084,  2.6377568 ],\n",
       "        [ 3.4326057 ,  1.3727556 , -4.6730266 , ..., -5.117884  ,\n",
       "          5.1313434 ,  3.6070166 ],\n",
       "        [ 2.1253774 ,  0.44614324, -4.6922064 , ..., -4.850297  ,\n",
       "          0.1257864 ,  3.1883144 ]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6]]#(2,3)\n",
    "#b=[[7,8,9],[10,11,12]]\n",
    "a=np.array(a)\n",
    "#b=np.array(b)\n",
    "c=[]\n",
    "c.append(a)\n",
    "#c.append(b)\n",
    "np.array(c).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.531046  ,  0.5287851 , -2.0515046 , ..., -6.225855  ,\n",
       "         2.6276855 ,  3.1448047 ],\n",
       "       [ 1.7903793 ,  0.043161  , -6.687018  , ..., -4.228427  ,\n",
       "        -4.7420626 ,  2.0148864 ],\n",
       "       [ 2.0014386 ,  1.0799699 , -4.45659   , ..., -3.8563538 ,\n",
       "         1.2759651 ,  2.796637  ],\n",
       "       ...,\n",
       "       [ 1.7604697 , -0.7905584 , -5.0068455 , ..., -4.268019  ,\n",
       "        -0.18399851,  2.500202  ],\n",
       "       [ 3.3009872 ,  1.7281702 , -3.9391239 , ..., -3.5045586 ,\n",
       "         3.92664   ,  3.1942382 ],\n",
       "       [ 2.1347585 ,  0.374539  , -3.6675785 , ..., -2.4043307 ,\n",
       "        -0.59287816,  2.5660818 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cased_pred_lst).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9494082 , 0.63013375, 0.14897776, ..., 0.00253813, 0.9804977 ,\n",
       "        0.9521161 ],\n",
       "       [0.808026  , 0.412042  , 0.00171434, ..., 0.01682095, 0.00647272,\n",
       "        0.90910053],\n",
       "       [0.9450579 , 0.67390245, 0.01062978, ..., 0.002915  , 0.9784374 ,\n",
       "        0.9000374 ],\n",
       "       ...,\n",
       "       [0.8384446 , 0.40093726, 0.01027456, ..., 0.21919301, 0.4604722 ,\n",
       "        0.90800893],\n",
       "       [0.9636179 , 0.90189177, 0.02156096, ..., 0.02346952, 0.97254926,\n",
       "        0.9802336 ],\n",
       "       [0.9293306 , 0.430232  , 0.02866988, ..., 0.07433899, 0.13348521,\n",
       "        0.8728599 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "cased_pred = np.array(cased_pred_lst).mean(0)\n",
    "cased_pred = sigmoid(cased_pred)\n",
    "cased_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.949099</td>\n",
       "      <td>0.602632</td>\n",
       "      <td>0.082691</td>\n",
       "      <td>0.425644</td>\n",
       "      <td>0.664275</td>\n",
       "      <td>0.655471</td>\n",
       "      <td>0.707268</td>\n",
       "      <td>0.669800</td>\n",
       "      <td>0.798551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947240</td>\n",
       "      <td>0.972848</td>\n",
       "      <td>0.715149</td>\n",
       "      <td>0.991980</td>\n",
       "      <td>0.992476</td>\n",
       "      <td>0.928810</td>\n",
       "      <td>0.097158</td>\n",
       "      <td>0.026617</td>\n",
       "      <td>0.950756</td>\n",
       "      <td>0.953038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.884563</td>\n",
       "      <td>0.476672</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.846933</td>\n",
       "      <td>0.742485</td>\n",
       "      <td>0.994332</td>\n",
       "      <td>0.540612</td>\n",
       "      <td>0.412230</td>\n",
       "      <td>0.099950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.983204</td>\n",
       "      <td>0.682555</td>\n",
       "      <td>0.993719</td>\n",
       "      <td>0.994706</td>\n",
       "      <td>0.920328</td>\n",
       "      <td>0.979071</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>0.863808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.950187</td>\n",
       "      <td>0.658466</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.696439</td>\n",
       "      <td>0.949114</td>\n",
       "      <td>0.970600</td>\n",
       "      <td>0.607235</td>\n",
       "      <td>0.509221</td>\n",
       "      <td>0.411673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.985808</td>\n",
       "      <td>0.730065</td>\n",
       "      <td>0.995348</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>0.945892</td>\n",
       "      <td>0.093498</td>\n",
       "      <td>0.042117</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.948664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.938729</td>\n",
       "      <td>0.525467</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.762707</td>\n",
       "      <td>0.837885</td>\n",
       "      <td>0.890279</td>\n",
       "      <td>0.553451</td>\n",
       "      <td>0.437848</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779918</td>\n",
       "      <td>0.947412</td>\n",
       "      <td>0.658828</td>\n",
       "      <td>0.973937</td>\n",
       "      <td>0.982233</td>\n",
       "      <td>0.886768</td>\n",
       "      <td>0.884983</td>\n",
       "      <td>0.145141</td>\n",
       "      <td>0.473806</td>\n",
       "      <td>0.905280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.945720</td>\n",
       "      <td>0.569130</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.893930</td>\n",
       "      <td>0.744055</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.572701</td>\n",
       "      <td>0.508597</td>\n",
       "      <td>0.111417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502510</td>\n",
       "      <td>0.941061</td>\n",
       "      <td>0.680172</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>0.972880</td>\n",
       "      <td>0.852857</td>\n",
       "      <td>0.290666</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.774137</td>\n",
       "      <td>0.900799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.949099                0.602632   \n",
       "1     46                             0.884563                0.476672   \n",
       "2     70                             0.950187                0.658466   \n",
       "3    132                             0.938729                0.525467   \n",
       "4    200                             0.945720                0.569130   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.082691                      0.425644   \n",
       "1                 0.000969                      0.846933   \n",
       "2                 0.003706                      0.696439   \n",
       "3                 0.002455                      0.762707   \n",
       "4                 0.014231                      0.893930   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.664275                               0.655471   \n",
       "1               0.742485                               0.994332   \n",
       "2               0.949114                               0.970600   \n",
       "3               0.837885                               0.890279   \n",
       "4               0.744055                               0.986870   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.707268                       0.669800   \n",
       "1                         0.540612                       0.412230   \n",
       "2                         0.607235                       0.509221   \n",
       "3                         0.553451                       0.437848   \n",
       "4                         0.572701                       0.508597   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.798551  ...               0.947240        0.972848   \n",
       "1               0.099950  ...               0.515464        0.983204   \n",
       "2               0.411673  ...               0.935586        0.985808   \n",
       "3               0.049915  ...               0.779918        0.947412   \n",
       "4               0.111417  ...               0.502510        0.941061   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.715149          0.991980          0.992476   \n",
       "1                     0.682555          0.993719          0.994706   \n",
       "2                     0.730065          0.995348          0.992168   \n",
       "3                     0.658828          0.973937          0.982233   \n",
       "4                     0.680172          0.984167          0.972880   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.928810                  0.097158               0.026617   \n",
       "1             0.920328                  0.979071               0.041499   \n",
       "2             0.945892                  0.093498               0.042117   \n",
       "3             0.886768                  0.884983               0.145141   \n",
       "4             0.852857                  0.290666               0.074808   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.950756             0.953038  \n",
       "1                        0.024477             0.863808  \n",
       "2                        0.930348             0.948664  \n",
       "3                        0.473806             0.905280  \n",
       "4                        0.774137             0.900799  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.columns[1:]] = cased_pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "490296f01f129d1791d2b0949f01d8bcbb5336528260279af7e468eefab7c316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
