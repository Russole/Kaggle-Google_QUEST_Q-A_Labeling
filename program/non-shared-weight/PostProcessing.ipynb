{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "#from transformers import *\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/train.csv').fillna(' ')\n",
    "test = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/test.csv').fillna(' ')\n",
    "sub = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/sample_submission.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n",
       "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
       "       'url', 'category', 'host', 'question_asker_intent_understanding',\n",
       "       'question_body_critical', 'question_conversational',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False\n",
    "                current_segment_id = 1#新增 \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=512-1, \n",
    "                t_max_len=70-1, q_max_len=219, a_max_len=219):#???\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "        t = t[:t_new_len]\n",
    "        q = norm_token_length(q, q_new_len)\n",
    "        a = norm_token_length(a, a_new_len)\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def norm_token_length(tokens, l):\n",
    "    if len(tokens) > l:\n",
    "        head = l//2\n",
    "        tail = l - head\n",
    "        return tokens[:head] + tokens[-tail:]\n",
    "    else:\n",
    "        return tokens[:l]\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, cate, max_sequence_length=512):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    #stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_1 = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n",
    "    stoken_2 = [\"[CLS]\"] + [cate]+title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    input_ids = _get_ids(stoken_1, tokenizer, max_sequence_length)\n",
    "    input_ids_2 = _get_ids(stoken_2, tokenizer, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken_1, max_sequence_length)\n",
    "    input_segments_2 = _get_segments(stoken_2, max_sequence_length)\n",
    "    \n",
    "    #return [input_ids, input_segments]\n",
    "    return input_ids, input_segments,input_ids_2,input_segments_2\n",
    "\n",
    "def convert_row(row,pretrained_weights):\n",
    "    #c = f\"[{row['category'].lower()}]\"\n",
    "\n",
    "    if pretrained_weights == \"bert-base-uncased\":\n",
    "        c = f\"[{row['category'].lower()}]\"#type:str\n",
    "    elif pretrained_weights == \"bert-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    elif pretrained_weights == \"xlnet-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    t, q, a = title = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]#type:str\n",
    "\n",
    "\n",
    "    t, q, a = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]\n",
    "    t, q, a = _trim_input(t, q, a)\n",
    "    #ids, segments = _convert_to_bert_inputs(t, q, a, c)\n",
    "    ids, segments, ids2, segments2 = _convert_to_bert_inputs(t, q, a, c)\n",
    "    #total_input=[np.array([[ids, segments]]),np.array([[ids2, segments2]])]\n",
    "    # total_input=[]\n",
    "    # print(np.array([[ids, segments]]).shape)\n",
    "    # total_input.append(np.array([[ids, segments]]))\n",
    "    # total_input.append(np.array([[ids2, segments2]]))\n",
    "    # return total_input\n",
    "    return np.array([[ids, segments, ids2, segments2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=\"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./double/token_model_config/tokenizer/\")\n",
    "#tokenizer.add_tokens(\"./bert_based_tokenizer/added_tokens.json\")\n",
    "#tokenizer.add_tokens(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data,data2, targets,targets2):\n",
    "    \n",
    "    # mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n",
    "    # bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])#??\n",
    "    mse = nn.MSELoss(reduction=\"none\")(data[:,:].sigmoid(), targets[:,:])\n",
    "    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:], targets[:,:])#??\n",
    "    \n",
    "    mse2 = nn.MSELoss(reduction=\"none\")(data2[:,:].sigmoid(), targets2[:,:])\n",
    "    bce2 = nn.BCEWithLogitsLoss(reduction='none')(data2[:,:], targets2[:,:])#??\n",
    "    #w =  targets[:,30:]\n",
    "    #loss = (mse*w).sum() + bce.sum()\n",
    "    loss = (mse).sum()+ bce.sum()+mse2.sum()+bce2.sum()\n",
    "    return loss\n",
    "\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, config_path=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(config_path) \n",
    "        \n",
    "        self.config.Q_labels = 21\n",
    "        self.config.A_labels = 9\n",
    "        self.config.output_hidden_states = True\n",
    "        self.n_use_layer = 4 #原本\n",
    "        #self.n_use_layer = 2\n",
    "        self.double_bert= 1\n",
    "        self.n_labels = self.config.num_labels\n",
    "        #self.config.save_pretrained(\"bert_based_config\")\n",
    "        #self.config.save_pretrained(output_dir+\"config\")\n",
    "        #self.bert = BertModel(config)\n",
    "        self.bert=AutoModel.from_config(self.config)\n",
    "        self.bert2=AutoModel.from_config(self.config)\n",
    "        #self.bert.save_pretrained('bert_based_model')\n",
    "        #self.bert.save_pretrained(output_dir+\"model\")\n",
    "        # self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n",
    "\n",
    "        self.dense1 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dense2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.Q_labels)\n",
    "        self.classifier2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.A_labels)\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None\n",
    "                ,input_ids2=None, attention_mask2=None, token_type_ids2=None,position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "\n",
    "        # outputs = self.bert(input_ids,\n",
    "        #                     attention_mask=attention_mask,\n",
    "        #                     token_type_ids=token_type_ids,\n",
    "        #                     position_ids=position_ids,\n",
    "        #                     head_mask=head_mask,\n",
    "        #                     inputs_embeds=inputs_embeds)\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                            )\n",
    "        outputs2 = self.bert2(input_ids2,\n",
    "                            attention_mask=attention_mask2,\n",
    "                            token_type_ids=token_type_ids2\n",
    "                            )\n",
    "        \n",
    "        #print(outputs[2][-1].shape)\n",
    "        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後4個layer的cls output concat在一起，把4個(8,768) concat，變成(8,3072) #原本\n",
    "        pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        #pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後2個layer的cls output concat在一起,把2個(8,768) concat，變成(8,1536)\n",
    "        #pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#同上\n",
    "        #double_pooled_output=torch.cat([pooled_output,pooled_output],dim=1)#(8,3072)\n",
    "        \n",
    "        pooled_output = self.dense1(pooled_output)\n",
    "        pooled_output = self.dense2(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        pooled_output2 = self.dense1(pooled_output2)\n",
    "        pooled_output2 = self.dense2(pooled_output2)\n",
    "        pooled_output2 = self.dropout(pooled_output2)\n",
    "        logits2 = self.classifier2(pooled_output2)\n",
    "\n",
    "        # double_pooled_output = self.dense1(double_pooled_output)\n",
    "        # double_pooled_output = self.dense2(double_pooled_output)\n",
    "        # double_pooled_output = self.dropout(double_pooled_output)\n",
    "        # logits = self.classifier(double_pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        outputs2 = (logits2,) + outputs2[2:]\n",
    "\n",
    "        return outputs,outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CustomBert(\"double/token_model_config/config/config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4324 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-cased'\n",
    "X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#X_train = train[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#np.vstack(X_test).shape : (476, 2, 512)\n",
    "X_test = np.vstack(X_test).reshape((len(X_test), 2048))\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bert2): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dense2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=21, bias=True)\n",
       "  (classifier2): Linear(in_features=3072, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "model.bert2.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dir_target = \"../input/Optimize binning/bert-base-cased\"#\n",
    "\n",
    "cased_pred_lst = []\n",
    "for fold in range(10):\n",
    "    # if fold in [0,1,2,3,4,5,6,7]:\n",
    "    #     continue\n",
    "    #bert_path = f\"{model_dir_target}/bert-base-cased_f{fold}_best\"\n",
    "    #bert_path=f\"./DoubleBertBasedCase/bce_no_opt_binning/double-bert-based-case_f{fold}_best\"\n",
    "    bert_path=f\"./double/Bce-NoOptbinning/double-bert-based-case_f{fold}_best\"\n",
    "    model.load_state_dict(torch.load(bert_path),strict=False)\n",
    "    \n",
    "    lst = []\n",
    "    for i, (x_batch,)  in enumerate(test_loader):\n",
    "        # input_ids = x_batch[:, :512]\n",
    "        # token_ids = x_batch[:, 512:]\n",
    "        input_ids = x_batch[:, :512]\n",
    "        token_ids = x_batch[:, 512:1024]\n",
    "        input_ids2 = x_batch[:, 1024:1536]\n",
    "        token_ids2 = x_batch[:, 1536:]\n",
    "        #pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n",
    "        pred, pred2 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n",
    "                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device))\n",
    "        total_y_pred=torch.cat((pred[0],pred2[0]),dim=1)\n",
    "        lst.append(total_y_pred.detach().cpu().squeeze().numpy())\n",
    "    train_pred = np.vstack(lst)#shape:(476, 30)\n",
    "    \n",
    "    cased_pred_lst.append(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.9148734 ,  0.5870639 , -1.0286921 , ..., -3.9417024 ,\n",
       "          3.10868   ,  2.7866461 ],\n",
       "        [ 1.9138436 , -0.14367273, -5.5822263 , ..., -2.0265653 ,\n",
       "         -2.8845267 ,  2.1542585 ],\n",
       "        [ 2.260144  ,  0.7972341 , -4.2451344 , ..., -3.3293252 ,\n",
       "          2.7163298 ,  2.2225938 ],\n",
       "        ...,\n",
       "        [ 1.6526257 , -0.734839  , -4.6569324 , ..., -1.4699891 ,\n",
       "         -0.48530427,  1.9625342 ],\n",
       "        [ 3.188662  ,  1.6525309 , -4.248226  , ..., -2.487862  ,\n",
       "          3.2956543 ,  2.9502594 ],\n",
       "        [ 2.392885  ,  0.2380366 , -3.6111574 , ..., -1.605704  ,\n",
       "         -1.4362035 ,  2.105583  ]], dtype=float32),\n",
       " array([[ 2.5103564 ,  0.45609975, -2.0337408 , ..., -3.6385996 ,\n",
       "          2.5943546 ,  2.7311163 ],\n",
       "        [ 1.9764313 , -0.17333022, -6.054926  , ..., -1.9884539 ,\n",
       "         -2.7503853 ,  2.3761356 ],\n",
       "        [ 2.3559232 ,  0.8823283 , -4.627333  , ..., -3.3722978 ,\n",
       "          2.6931622 ,  2.3779893 ],\n",
       "        ...,\n",
       "        [ 1.5696981 , -0.64607036, -4.4800634 , ..., -1.7597274 ,\n",
       "          0.1621161 ,  2.4484308 ],\n",
       "        [ 2.9438741 ,  1.555677  , -3.6107452 , ..., -2.4905987 ,\n",
       "          2.6066194 ,  2.9100482 ],\n",
       "        [ 2.5028286 , -0.08038376, -4.2873487 , ..., -2.0626779 ,\n",
       "         -1.9099687 ,  2.138699  ]], dtype=float32),\n",
       " array([[ 2.7413955 ,  0.49686697, -1.139848  , ..., -3.5026126 ,\n",
       "          2.801488  ,  2.4525678 ],\n",
       "        [ 1.854656  , -0.20697246, -5.5248923 , ..., -1.9294177 ,\n",
       "         -2.8864546 ,  2.0854151 ],\n",
       "        [ 2.554181  ,  0.9449198 , -4.778121  , ..., -2.8906264 ,\n",
       "          2.3344169 ,  2.190161  ],\n",
       "        ...,\n",
       "        [ 1.884864  , -0.51858646, -4.894277  , ..., -1.6033946 ,\n",
       "         -1.691344  ,  1.8583857 ],\n",
       "        [ 2.6513488 ,  1.4080722 , -3.420844  , ..., -2.746457  ,\n",
       "          3.6349485 ,  2.7363155 ],\n",
       "        [ 2.2694716 ,  0.22983024, -3.7165256 , ..., -1.9667453 ,\n",
       "         -1.0660452 ,  1.9637207 ]], dtype=float32),\n",
       " array([[ 2.8536332 ,  0.55421054, -1.3037102 , ..., -3.7246604 ,\n",
       "          2.5915303 ,  2.4627233 ],\n",
       "        [ 1.6757438 , -0.20795946, -5.3240175 , ..., -2.0022755 ,\n",
       "         -3.1192534 ,  1.8289504 ],\n",
       "        [ 2.6733403 ,  0.89554834, -4.252328  , ..., -3.5183883 ,\n",
       "          2.076346  ,  2.4355876 ],\n",
       "        ...,\n",
       "        [ 1.5733832 , -0.7812666 , -3.7443368 , ..., -1.828633  ,\n",
       "          0.32921764,  1.7987202 ],\n",
       "        [ 3.0194285 ,  2.0560486 , -3.6404738 , ..., -2.1957102 ,\n",
       "          3.150835  ,  2.6381435 ],\n",
       "        [ 2.3509135 ,  0.07888149, -4.5634427 , ..., -1.6077464 ,\n",
       "         -0.0573183 ,  2.009958  ]], dtype=float32),\n",
       " array([[ 2.6895049 ,  0.26972637, -1.8492647 , ..., -3.8140335 ,\n",
       "          2.1177218 ,  2.526196  ],\n",
       "        [ 1.7833078 ,  0.00873065, -5.2332926 , ..., -1.7525616 ,\n",
       "         -2.6962817 ,  2.3390772 ],\n",
       "        [ 2.4779594 ,  0.80492574, -4.43564   , ..., -3.1765945 ,\n",
       "          3.0134487 ,  2.7113783 ],\n",
       "        ...,\n",
       "        [ 1.4198315 , -0.64762485, -3.776958  , ..., -1.8199574 ,\n",
       "         -0.2034427 ,  2.4370813 ],\n",
       "        [ 2.780403  ,  2.1151276 , -3.8020592 , ..., -2.4431942 ,\n",
       "          3.0494657 ,  2.5879183 ],\n",
       "        [ 2.3771398 ,  0.17081831, -3.5545852 , ..., -1.982633  ,\n",
       "         -0.3157804 ,  2.4182806 ]], dtype=float32),\n",
       " array([[ 2.8235967 ,  0.44112566, -1.330617  , ..., -4.1427627 ,\n",
       "          2.3605535 ,  2.405228  ],\n",
       "        [ 1.5948689 , -0.39676347, -5.4312167 , ..., -1.7371391 ,\n",
       "         -2.7527637 ,  2.0954156 ],\n",
       "        [ 2.3369076 ,  0.92122996, -3.3947783 , ..., -3.783685  ,\n",
       "          3.050911  ,  2.3718314 ],\n",
       "        ...,\n",
       "        [ 1.7609894 , -0.60736793, -4.210984  , ..., -1.3377184 ,\n",
       "          0.03782983,  2.2063048 ],\n",
       "        [ 2.5287693 ,  1.5789748 , -3.424512  , ..., -2.9056697 ,\n",
       "          3.5599377 ,  2.7744796 ],\n",
       "        [ 2.154482  ,  0.12568769, -3.2179391 , ..., -1.77831   ,\n",
       "         -1.6189035 ,  2.0105193 ]], dtype=float32),\n",
       " array([[ 2.8013396 ,  0.43353888, -1.5575541 , ..., -3.2911708 ,\n",
       "          2.7166998 ,  2.2021058 ],\n",
       "        [ 1.8147146 ,  0.10664671, -5.278747  , ..., -2.1068206 ,\n",
       "         -2.964353  ,  2.3790812 ],\n",
       "        [ 2.509939  ,  0.6591157 , -4.8322988 , ..., -3.7833633 ,\n",
       "          3.5224452 ,  2.6479979 ],\n",
       "        ...,\n",
       "        [ 1.726836  , -0.63026506, -4.403735  , ..., -1.4332482 ,\n",
       "         -0.08453802,  2.6559014 ],\n",
       "        [ 2.4932666 ,  1.2886096 , -4.3053846 , ..., -2.892618  ,\n",
       "          3.7375245 ,  2.9670742 ],\n",
       "        [ 2.2487023 , -0.1334288 , -4.694021  , ..., -2.0025775 ,\n",
       "         -1.0209807 ,  2.3298826 ]], dtype=float32),\n",
       " array([[ 3.0332334 ,  0.31014982, -1.7405893 , ..., -4.0959897 ,\n",
       "          2.7210143 ,  2.6309114 ],\n",
       "        [ 1.9239984 , -0.12701887, -5.091317  , ..., -2.428308  ,\n",
       "         -2.9899044 ,  2.3494062 ],\n",
       "        [ 2.2904658 ,  0.7118155 , -4.5009346 , ..., -3.7010858 ,\n",
       "          3.1441548 ,  2.4558895 ],\n",
       "        ...,\n",
       "        [ 1.7633356 , -0.6515487 , -3.958963  , ..., -1.6939629 ,\n",
       "         -0.8844008 ,  2.0595012 ],\n",
       "        [ 2.561701  ,  1.6283351 , -3.2732139 , ..., -2.4250503 ,\n",
       "          3.233177  ,  2.891486  ],\n",
       "        [ 2.1740294 , -0.03110471, -4.1821523 , ..., -2.379321  ,\n",
       "         -0.6106037 ,  2.4704392 ]], dtype=float32),\n",
       " array([[ 2.9836059e+00,  4.8836246e-01, -1.4444849e+00, ...,\n",
       "         -4.3021259e+00,  3.0791321e+00,  2.5806334e+00],\n",
       "        [ 1.9159243e+00,  2.5672939e-02, -5.5604129e+00, ...,\n",
       "         -2.1879957e+00, -3.0817246e+00,  2.6186860e+00],\n",
       "        [ 2.5949304e+00,  7.3588669e-01, -4.1842351e+00, ...,\n",
       "         -3.7180860e+00,  3.3907647e+00,  2.6132977e+00],\n",
       "        ...,\n",
       "        [ 1.7730703e+00, -7.1660745e-01, -4.0451298e+00, ...,\n",
       "         -1.4466888e+00, -2.7978450e-01,  2.0171435e+00],\n",
       "        [ 2.8728821e+00,  1.4406235e+00, -3.6221802e+00, ...,\n",
       "         -2.2268448e+00,  2.2593331e+00,  2.5485733e+00],\n",
       "        [ 2.2660956e+00, -9.1604167e-04, -4.0312061e+00, ...,\n",
       "         -1.8790981e+00, -1.7195098e+00,  2.2321978e+00]], dtype=float32),\n",
       " array([[ 2.6330345 ,  0.36627933, -1.0524104 , ..., -4.1108313 ,\n",
       "          3.3260808 ,  2.6060486 ],\n",
       "        [ 1.6672678 , -0.14990923, -5.7948112 , ..., -1.9245125 ,\n",
       "         -3.421963  ,  2.2009091 ],\n",
       "        [ 2.4642432 ,  0.72592044, -4.1336794 , ..., -2.9745278 ,\n",
       "          2.9030645 ,  2.320065  ],\n",
       "        ...,\n",
       "        [ 1.4474846 , -0.8101059 , -4.178406  , ..., -1.5448532 ,\n",
       "         -0.8040441 ,  1.7410512 ],\n",
       "        [ 2.7158735 ,  1.7802432 , -3.4755187 , ..., -2.5386913 ,\n",
       "          3.0043454 ,  2.8831728 ],\n",
       "        [ 2.1443026 , -0.14552173, -4.035122  , ..., -2.1688285 ,\n",
       "         -1.5552309 ,  1.9457452 ]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6]]#(2,3)\n",
    "#b=[[7,8,9],[10,11,12]]\n",
    "a=np.array(a)\n",
    "#b=np.array(b)\n",
    "c=[]\n",
    "c.append(a)\n",
    "#c.append(b)\n",
    "np.array(c).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cased_pred_lst).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94259244, 0.6083406 , 0.1902955 , ..., 0.02070517, 0.9394443 ,\n",
       "        0.92679155],\n",
       "       [0.8596125 , 0.46842766, 0.00412077, ..., 0.11832326, 0.04951198,\n",
       "        0.90402186],\n",
       "       [0.9206932 , 0.6916602 , 0.01288849, ..., 0.03152938, 0.9470751 ,\n",
       "        0.91943383],\n",
       "       ...,\n",
       "       [0.8398634 , 0.337506  , 0.01427344, ..., 0.16884752, 0.40362835,\n",
       "        0.8926889 ],\n",
       "       [0.9413441 , 0.83894837, 0.02454691, ..., 0.07342236, 0.95903397,\n",
       "        0.94206464],\n",
       "       [0.90788543, 0.5112956 , 0.01817529, ..., 0.12527874, 0.24396653,\n",
       "        0.89683133]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "cased_pred = np.array(cased_pred_lst).mean(0)\n",
    "cased_pred = sigmoid(cased_pred)\n",
    "cased_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4TH Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy import stats\n",
    "\n",
    "# def spearmanr(y_true, y_pred):\n",
    "#     if np.ndim(y_pred) == 2:\n",
    "#         corr = np.nan_to_num([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])]).mean()\n",
    "#     else:\n",
    "#         corr = stats.spearmanr(y_true, y_pred)[0]\n",
    "#     return corr\n",
    "def metric3(y_true,y_pred):\n",
    "    y = copy.deepcopy(y_pred) #make_copy\n",
    "    list_of_max_voters=[] #  list_of_max_voters[i] = how many voters did label the data (instead of 90 for all the columns)\n",
    "    for i in (range(y_pred.shape[1])):\n",
    "        best_score= 0 #initilize score for the the column i\n",
    "        best_max_voters=1 #\n",
    "        history_score=[]\n",
    "        for max_voters in range(1,200):\n",
    "            y[:,i]= (y_pred[:,i]//(1/max_voters))*(1/max_voters)\n",
    "            score = stats.spearmanr(y_true[:, i], y[:, i]).correlation\n",
    "            history_score.append(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_max_voters= max_voters\n",
    "        list_of_max_voters.append(best_max_voters)\n",
    "\n",
    "        y[:,i]= (y_pred[:,i]//(1/best_max_voters))*(1/best_max_voters)\n",
    "    return np.mean([stats.spearmanr(y_true[:, ind], y[:, ind]).correlation for ind in range(y.shape[1])])#,list_of_max_voters```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=metric3(y3,cased_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1th PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def postprocess_single(target, ref):\n",
    "    \"\"\"\n",
    "    The idea here is to make the distribution of a particular predicted column\n",
    "    to match the correspoding distribution of the corresponding column in the\n",
    "    training dataset (called ref here)\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = np.argsort(target)\n",
    "    counts = sorted(Counter(ref).items(), key=lambda s: s[0])\n",
    "    scores = np.zeros_like(target)\n",
    "    \n",
    "    last_pos = 0\n",
    "    v = 0\n",
    "    \n",
    "    for value, count in counts:\n",
    "        next_pos = last_pos + int(round(count / len(ref) * len(target)))\n",
    "        if next_pos == last_pos:\n",
    "            next_pos += 1\n",
    "\n",
    "        cond = ids[last_pos:next_pos]\n",
    "        scores[cond] = v\n",
    "        last_pos = next_pos\n",
    "        v += 1\n",
    "        \n",
    "    return scores / scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_prediction(prediction, actual):\n",
    "    \n",
    "    postprocessed = prediction.copy()\n",
    "    \n",
    "    for col in target_columns:\n",
    "        scores = postprocess_single(prediction[col].values, actual[col].values)\n",
    "        # Those are columns where our postprocessing gave substantial improvement.\n",
    "        # It also helped for some others, but we didn't include them as the gain was\n",
    "        # very marginal (less than 0.01)\n",
    "        if col in (\n",
    "            \"question_conversational\",\n",
    "            \"question_type_compare\",\n",
    "            \"question_type_definition\",\n",
    "            \"question_type_entity\",\n",
    "            \"question_has_commonly_accepted_answer\",\n",
    "            \"question_type_consequence\",\n",
    "            \"question_type_spelling\"\n",
    "        ):\n",
    "            postprocessed[col] = scores\n",
    "            \n",
    "        # scale to 0-1 interval\n",
    "        v = postprocessed[col].values\n",
    "        postprocessed[col] = (v - v.min()) / (v.max() - v.min())\n",
    "    \n",
    "    return postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy=test.copy()\n",
    "target_columns=sub.columns\n",
    "target_columns=target_columns[1:]\n",
    "for id,target in enumerate(target_columns):\n",
    "    test_copy[target]=cased_pred[:,id]\n",
    "test_copy=test_copy.drop(columns=['question_title', 'question_body', 'question_user_name',\n",
    "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
    "       'url', 'category', 'host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed=postprocess_prediction(test_copy,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in target_columns:\n",
    "    if(postprocessed[column]==0.00).all():\n",
    "        print(f\"All values in the column {column} are Zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub[sub.columns[1:]] = cased_pred\n",
    "# sub.to_csv(\"submission.csv\", index=False)\n",
    "# sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "490296f01f129d1791d2b0949f01d8bcbb5336528260279af7e468eefab7c316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
