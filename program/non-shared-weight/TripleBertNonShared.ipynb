{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lab000\\anaconda3\\envs\\contrastive_learning2\\lib\\site-packages\\transformers\\generation_utils.py:27: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  FutureWarning,\n",
      "c:\\Users\\Lab000\\anaconda3\\envs\\contrastive_learning2\\lib\\site-packages\\transformers\\generation_tf_utils.py:27: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  FutureWarning,\n",
      "c:\\Users\\Lab000\\anaconda3\\envs\\contrastive_learning2\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from transformers import *\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda')\n",
    "#device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"./token_model_config/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def spearman_corr(y_true, y_pred):\n",
    "    if np.ndim(y_pred) == 2:\n",
    "        corr = np.nan_to_num([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])]).mean()\n",
    "    else:\n",
    "        corr = stats.spearmanr(y_true, y_pred)[0]\n",
    "    return corr\n",
    "  \n",
    "def calc_each_spearman(valid_y, valid_pred):\n",
    "    lst = []\n",
    "    for idx in range(30):\n",
    "        spearman = spearman_corr(valid_y[:,idx], valid_pred[:,idx])\n",
    "        lst.append(spearman)\n",
    "    df = pd.DataFrame(lst).T\n",
    "    df.columns = class_names3\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False\n",
    "                current_segment_id = 1#新增 \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=512-1, \n",
    "                t_max_len=70-1, q_max_len=219, a_max_len=219):#???\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "        t = t[:t_new_len]\n",
    "        q = norm_token_length(q, q_new_len)\n",
    "        a = norm_token_length(a, a_new_len)\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def norm_token_length(tokens, l):\n",
    "    if len(tokens) > l:\n",
    "        head = l//2\n",
    "        tail = l - head\n",
    "        return tokens[:head] + tokens[-tail:]\n",
    "    else:\n",
    "        return tokens[:l]\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, cate, max_sequence_length=512):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    #stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_1 = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n",
    "    # stoken_2 = [\"[CLS]\"] + title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    # stoken_3 = [\"[CLS]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_2 = [\"[CLS]\"] + [cate]+title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_3 = [\"[CLS]\"] + [cate]+question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    input_ids = _get_ids(stoken_1, tokenizer, max_sequence_length)\n",
    "    input_ids_2 = _get_ids(stoken_2, tokenizer, max_sequence_length)\n",
    "    input_ids_3 = _get_ids(stoken_3, tokenizer, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken_1, max_sequence_length)\n",
    "    input_segments_2 = _get_segments(stoken_2, max_sequence_length)\n",
    "    input_segments_3 = _get_segments(stoken_3, max_sequence_length)\n",
    "    \n",
    "\n",
    "    \n",
    "    #return [input_ids, input_segments]\n",
    "    return input_ids, input_segments,input_ids_2,input_segments_2, input_ids_3, input_segments_3\n",
    "\n",
    "def convert_row(row):\n",
    "    #c = f\"[{row['category'].lower()}]\"\n",
    "    c = f\"[{row['category']}]\"\n",
    "    t, q, a = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]\n",
    "    t, q, a = _trim_input(t, q, a)\n",
    "    #ids, segments = _convert_to_bert_inputs(t, q, a, c)\n",
    "    ids, segments, ids2, segments2, ids3, segments3 = _convert_to_bert_inputs(t, q, a, c)\n",
    "    #total_input=[np.array([[ids, segments]]),np.array([[ids2, segments2]])]\n",
    "    # total_input=[]\n",
    "    # print(np.array([[ids, segments]]).shape)\n",
    "    # total_input.append(np.array([[ids, segments]]))\n",
    "    # total_input.append(np.array([[ids2, segments2]]))\n",
    "    # return total_input\n",
    "    return np.array([[ids, segments, ids2, segments2, ids3, segments3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/train.csv').fillna(' ')\n",
    "sub = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/sample_submission.csv').fillna(' ')\n",
    "\n",
    "#model_class, tokenizer_class = transformer_models_dict[pretrained_weights]\n",
    "#tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "categories = train[\"category\"].unique().tolist()\n",
    "categories = [f\"[{c}]\" for c in categories]\n",
    "#tokenizer.add_tokens(categories)#??\n",
    "\n",
    "#tokenizer.added_tokens_encoder#??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=\"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "tokenizer.add_tokens(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./token_model_config/tokenizer\\tokenizer_config.json\n",
      "Special tokens file saved in ./token_model_config/tokenizer\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./token_model_config/tokenizer\\\\tokenizer_config.json',\n",
       " './token_model_config/tokenizer\\\\special_tokens_map.json',\n",
       " './token_model_config/tokenizer\\\\vocab.txt',\n",
       " './token_model_config/tokenizer\\\\added_tokens.json',\n",
       " './token_model_config/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path=\"./bert_based_tokenizer\"\n",
    "tokenizer.save_pretrained(output_dir+\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = train.apply(convert_row, axis=1).values\n",
    "X = np.vstack(X).reshape((len(X), 3072))\n",
    "assert X.shape == (6079, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6079, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 28996,  1327,  1821,   146,  3196,  1165,  1606,  4973,\n",
       "       11182,  1939,  1104,   170, 23639,  2180, 11039,   136,   102,\n",
       "        1258,  1773,  1213,  1114, 23639,  2180,  6427,  1113,   118,\n",
       "        1103,   118, 10928,   113,  2373,   131, 11802, 11039,   117,\n",
       "        1231,  1964,   119, 11039,  5378,  1113,   170,  2632, 11039,\n",
       "         117, 14403,  4973, 11182,   114,   117,   146,  1156,  1176,\n",
       "        1106,  1243,  1748,  1114,  1142,   119,  1109,  2645,  1114,\n",
       "        1103,  4884,   146,  1215,  1110,  1115,  2817,  1110,  9506,\n",
       "        1105, 22769,  1654,  1110, 20405,  1120,  1436,   119,  1188,\n",
       "        2609,  1139, 18011,  1106,  1253,  5174,   113,  2373,   131,\n",
       "        2044,  9895,   114,  1986,   117,  1112,  3450,  1110,  8320,\n",
       "         117,   146,  1328,  1106,  1129,  1682,  1106,  5211,  1686,\n",
       "        9895,   119,   146,  2059,  1115,  1111,  1142,   117, 12365,\n",
       "       14467,  6697,  1105,  1383,  8637, 22769,  1209,  1129,  1104,\n",
       "        1632,  1494,   119,  1573,   117,  1141,  5119,  1133,  5865,\n",
       "        5146,  1110,   170, 23639,  2180, 11039,   113,  1474,   117,\n",
       "         142,  2271,  1620,  6262,  6603,  2180,   114,  1438,   117,\n",
       "         146,  1821,  1136,  1541,  3888,  1107,  1870,  1330,  5748,\n",
       "       11039,   119,  1760,  4174,  1110,  1103,  6538,  4973, 11182,\n",
       "         119,  9656,  1111,  4177,  7781,  2462,   117,  1184,  1821,\n",
       "         146,  3196,  1165,  1606, 11182,   113, 11646,  1114,   170,\n",
       "        2503, 11039,   117,  1474,   142,  2271, 20829,   118,  2363,\n",
       "         120,   123,   119,   129,   114,  1939,  1104,   170, 23639,\n",
       "        2180, 11039,   136,   102,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][512:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 28996,  1327,  1821,   146,  3196,  1165,  1606,  4973,\n",
       "       11182,  1939,  1104,   170, 23639,  2180, 11039,   136,   102,\n",
       "         146,  1198,  1400,  4973, 11182,   117,  1177,  1303,   112,\n",
       "         188,  1103, 19244,   119,   119,   119,   119,  1184,  1821,\n",
       "         146,  3196,  1165,  1606, 11182,   119,   119,   119,   136,\n",
       "         138,  1304,  5602,  2971,  1104,  1609,   106,  3561, 11811,\n",
       "        4253,  1115,  2462,  1121,  1103,  1322,  1104,  1103, 11039,\n",
       "        1106,  1103, 15228,  1169,  2195,  1240,  1609,  1317,  6260,\n",
       "         119, 16544,  1114,  1103,  1864,  1115,  1128,   112,  1325,\n",
       "        1932,  5211,  2141,  1205,   118,  5363,  1106,  1444,  1106,\n",
       "        2773,  1240, 11533,  9627,   119,  1109,  1864,  1103, 23639,\n",
       "        2180,   112,   188,  1132,  1932,  1737,  1304,  1304,  4295,\n",
       "         117,  1780,   146,  2059,  1115,  3102,   118,  2363,  6262,\n",
       "         123,   119,   129,  1110,  3155,  1106,  1129,  2385,  4295,\n",
       "         119,  1109, 18737,  1822, 25856,  4701,  1104,  1242, 23639,\n",
       "        5864,   119,   146,  2010,   112,   189,  3994,  1315,  1277,\n",
       "        1164,  1103,   171,  9143,  1324,  1290,  1103,   141,  2346,\n",
       "        2271,  1209,  1253,  1129,  2385,  2609,   119,  3291,  4455,\n",
       "        2433,  1113,  1139,  1851,  6262,   117,   170,  1554,  2539,\n",
       "        6262,   112,  1110,  1324,  4973,  7159,  2686,  1107,   170,\n",
       "         141,  2346,  2271,  1104,  1164,   170,  2337,  4519,  1107,\n",
       "        1524,  1104,  1103, 11039,   119,  1212,  1139,  3102,   118,\n",
       "        3127,   117,  1157,  1930,  1213,   123,   118,   124,  1623,\n",
       "        1107,  1524,  1104,  1103, 11039,  1106,  1164,   170,  2555,\n",
       "        1107,  1524,  1104,  1103, 11039,   119,   102,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][1024:1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][1536:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 28996,  1258,  1773,  1213,  1114, 23639,  2180,  6427,\n",
       "        1113,   118,  1103,   118, 10928,   113,  2373,   131, 11802,\n",
       "       11039,   117,  1231,  1964,   119, 11039,  5378,  1113,   170,\n",
       "        2632, 11039,   117, 14403,  4973, 11182,   114,   117,   146,\n",
       "        1156,  1176,  1106,  1243,  1748,  1114,  1142,   119,  1109,\n",
       "        2645,  1114,  1103,  4884,   146,  1215,  1110,  1115,  2817,\n",
       "        1110,  9506,  1105, 22769,  1654,  1110, 20405,  1120,  1436,\n",
       "         119,  1188,  2609,  1139, 18011,  1106,  1253,  5174,   113,\n",
       "        2373,   131,  2044,  9895,   114,  1986,   117,  1112,  3450,\n",
       "        1110,  8320,   117,   146,  1328,  1106,  1129,  1682,  1106,\n",
       "        5211,  1686,  9895,   119,   146,  2059,  1115,  1111,  1142,\n",
       "         117, 12365, 14467,  6697,  1105,  1383,  8637, 22769,  1209,\n",
       "        1129,  1104,  1632,  1494,   119,  1573,   117,  1141,  5119,\n",
       "        1133,  5865,  5146,  1110,   170, 23639,  2180, 11039,   113,\n",
       "        1474,   117,   142,  2271,  1620,  6262,  6603,  2180,   114,\n",
       "        1438,   117,   146,  1821,  1136,  1541,  3888,  1107,  1870,\n",
       "        1330,  5748, 11039,   119,  1760,  4174,  1110,  1103,  6538,\n",
       "        4973, 11182,   119,  9656,  1111,  4177,  7781,  2462,   117,\n",
       "        1184,  1821,   146,  3196,  1165,  1606, 11182,   113, 11646,\n",
       "        1114,   170,  2503, 11039,   117,  1474,   142,  2271, 20829,\n",
       "         118,  2363,   120,   123,   119,   129,   114,  1939,  1104,\n",
       "         170, 23639,  2180, 11039,   136,   102,   146,  1198,  1400,\n",
       "        4973, 11182,   117,  1177,  1303,   112,   188,  1103, 19244,\n",
       "         119,   119,   119,   119,  1184,  1821,   146,  3196,  1165,\n",
       "        1606, 11182,   119,   119,   119,   136,   138,  1304,  5602,\n",
       "        2971,  1104,  1609,   106,  3561, 11811,  4253,  1115,  2462,\n",
       "        1121,  1103,  1322,  1104,  1103, 11039,  1106,  1103, 15228,\n",
       "        1169,  2195,  1240,  1609,  1317,  6260,   119, 16544,  1114,\n",
       "        1103,  1864,  1115,  1128,   112,  1325,  1932,  5211,  2141,\n",
       "        1205,   118,  5363,  1106,  1444,  1106,  2773,  1240, 11533,\n",
       "        9627,   119,  1109,  1864,  1103, 23639,  2180,   112,   188,\n",
       "        1132,  1932,  1737,  1304,  1304,  4295,   117,  1780,   146,\n",
       "        2059,  1115,  3102,   118,  2363,  6262,   123,   119,   129,\n",
       "        1110,  3155,  1106,  1129,  2385,  4295,   119,  1109, 18737,\n",
       "        1822, 25856,  4701,  1104,  1242, 23639,  5864,   119,   146,\n",
       "        2010,   112,   189,  3994,  1315,  1277,  1164,  1103,   171,\n",
       "        9143,  1324,  1290,  1103,   141,  2346,  2271,  1209,  1253,\n",
       "        1129,  2385,  2609,   119,  3291,  4455,  2433,  1113,  1139,\n",
       "        1851,  6262,   117,   170,  1554,  2539,  6262,   112,  1110,\n",
       "        1324,  4973,  7159,  2686,  1107,   170,   141,  2346,  2271,\n",
       "        1104,  1164,   170,  2337,  4519,  1107,  1524,  1104,  1103,\n",
       "       11039,   119,  1212,  1139,  3102,   118,  3127,   117,  1157,\n",
       "        1930,  1213,   123,   118,   124,  1623,  1107,  1524,  1104,\n",
       "        1103, 11039,  1106,  1164,   170,  2555,  1107,  1524,  1104,\n",
       "        1103, 11039,   119,   102,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][2048:2560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][2560:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = list(sub.columns[1:])\n",
    "# y = train[class_names].values#(6079,30)\n",
    "\n",
    "# lst = []\n",
    "# for idx in range(30):\n",
    "#     t = pd.DataFrame(y[:,idx])[0]\n",
    "#     # print(len(t))\n",
    "#     #print(1-t.value_counts())\n",
    "#     #print(1-t.value_counts()/len(t))\n",
    "#     w_df = (1-t.value_counts()/len(t)).reset_index()\n",
    "#     #print(w_df)\n",
    "#     w_dic = {row[\"index\"]: row[0] for _, row in w_df.iterrows()}\n",
    "#     # print(\"=======================\")\n",
    "#     # print(w_dic)\n",
    "#     w = t.map(w_dic).values#(6079,)\n",
    "#     #print(w.shape)\n",
    "#     lst.append(w)\n",
    "# # print(lst)\n",
    "# # print(\"==================================\")\n",
    "# weights = np.vstack(lst).T#轉置, shape:(6079,30)\n",
    "\n",
    "# import copy\n",
    "# y_true = copy.deepcopy(y)\n",
    "# y = np.hstack([y, weights])#(6079,60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_asker_intent_understanding', 'question_body_critical',\n",
       "       'question_conversational', 'question_expect_short_answer',\n",
       "       'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.columns[1:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(sub.columns[1:22])\n",
    "class_names2 = list(sub.columns[22:])\n",
    "class_names3= list(sub.columns[1:])\n",
    "y = train[class_names].values#(6079,21)\n",
    "y2 = train[class_names2].values\n",
    "y3 = train[class_names3].values\n",
    "lst = []\n",
    "# for idx in range(30):\n",
    "#     t = pd.DataFrame(y[:,idx])[0]\n",
    "#     # print(len(t))\n",
    "#     #print(1-t.value_counts())\n",
    "#     #print(1-t.value_counts()/len(t))\n",
    "#     w_df = (1-t.value_counts()/len(t)).reset_index()\n",
    "#     #print(w_df)\n",
    "#     w_dic = {row[\"index\"]: row[0] for _, row in w_df.iterrows()}\n",
    "#     # print(\"=======================\")\n",
    "#     # print(w_dic)\n",
    "#     w = t.map(w_dic).values#(6079,)\n",
    "#     #print(w.shape)\n",
    "#     lst.append(w)\n",
    "# print(lst)\n",
    "# print(\"==================================\")\n",
    "# weights = np.vstack(lst).T#轉置, shape:(6079,30)\n",
    "\n",
    "import copy\n",
    "y_true = copy.deepcopy(y)\n",
    "y_true2 = copy.deepcopy(y2)\n",
    "#y = np.hstack([y, weights])#(6079,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 512:].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data,data2, data3,targets,targets2,targets3):\n",
    "    \n",
    "    # mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n",
    "    # bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])#??\n",
    "    mse = nn.MSELoss(reduction=\"none\")(data[:,:].sigmoid(), targets[:,:])\n",
    "    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:], targets[:,:])#??\n",
    "    \n",
    "    mse2 = nn.MSELoss(reduction=\"none\")(data2[:,:].sigmoid(), targets2[:,:])\n",
    "    bce2 = nn.BCEWithLogitsLoss(reduction='none')(data2[:,:], targets2[:,:])#??\n",
    "\n",
    "    mse3 = nn.MSELoss(reduction=\"none\")(data3[:,:].sigmoid(), targets3[:,:])\n",
    "    bce3 = nn.BCEWithLogitsLoss(reduction='none')(data3[:,:], targets3[:,:])#??\n",
    "    #w =  targets[:,30:]\n",
    "    #loss = (mse*w).sum() + bce.sum()\n",
    "    loss = (mse).sum()+ bce.sum()+mse2.sum()+bce2.sum()+mse3.sum()+bce3.sum()\n",
    "    return loss\n",
    "\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, model,config_path=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model) \n",
    "        \n",
    "        self.config.Q_labels = 21\n",
    "        self.config.A_labels = 9\n",
    "        self.config.All_labels = 30\n",
    "        self.config.output_hidden_states = True\n",
    "        self.n_use_layer = 4 #原本\n",
    "        #self.n_use_layer = 2\n",
    "        self.double_bert= 1\n",
    "        self.n_labels = self.config.num_labels\n",
    "        #self.config.save_pretrained(\"bert_based_config\")\n",
    "        self.config.save_pretrained(output_dir+\"config\")\n",
    "        #self.bert = BertModel(config)\n",
    "        self.bert=AutoModel.from_pretrained(model, config=self.config)\n",
    "        self.bert2=AutoModel.from_pretrained(model, config=self.config)\n",
    "        self.bert3=AutoModel.from_pretrained(model, config=self.config)\n",
    "        #self.bert.save_pretrained('bert_based_model')\n",
    "        self.bert.save_pretrained(output_dir+\"model\")\n",
    "        # self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n",
    "\n",
    "        self.dense1 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dense2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.Q_labels)\n",
    "        self.classifier2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.A_labels)\n",
    "        self.classifier3 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.All_labels)\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None\n",
    "                ,input_ids2=None, attention_mask2=None, token_type_ids2=None,\n",
    "                input_ids3=None, attention_mask3=None, token_type_ids3=None,\n",
    "                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "\n",
    "        # outputs = self.bert(input_ids,\n",
    "        #                     attention_mask=attention_mask,\n",
    "        #                     token_type_ids=token_type_ids,\n",
    "        #                     position_ids=position_ids,\n",
    "        #                     head_mask=head_mask,\n",
    "        #                     inputs_embeds=inputs_embeds)\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                            )\n",
    "        outputs2 = self.bert2(input_ids2,\n",
    "                            attention_mask=attention_mask2,\n",
    "                            token_type_ids=token_type_ids2\n",
    "                            )\n",
    "        \n",
    "        outputs3 = self.bert3(input_ids3,\n",
    "                            attention_mask=attention_mask3,\n",
    "                            token_type_ids=token_type_ids3\n",
    "                            )\n",
    "        #print(outputs[2][-1].shape)\n",
    "        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後4個layer的cls output concat在一起，把4個(8,768) concat，變成(8,3072) #原本\n",
    "        pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        pooled_output3 = torch.cat([outputs3[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        #pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後2個layer的cls output concat在一起,把2個(8,768) concat，變成(8,1536)\n",
    "        #pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#同上\n",
    "        #double_pooled_output=torch.cat([pooled_output,pooled_output],dim=1)#(8,3072)\n",
    "        \n",
    "        pooled_output = self.dense1(pooled_output)\n",
    "        pooled_output = self.dense2(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        pooled_output2 = self.dense1(pooled_output2)\n",
    "        pooled_output2 = self.dense2(pooled_output2)\n",
    "        pooled_output2 = self.dropout(pooled_output2)\n",
    "        logits2 = self.classifier2(pooled_output2)\n",
    "        \n",
    "        pooled_output3 = self.dense1(pooled_output3)\n",
    "        pooled_output3 = self.dense2(pooled_output3)\n",
    "        pooled_output3 = self.dropout(pooled_output3)\n",
    "        logits3 = self.classifier3(pooled_output3)\n",
    "        # double_pooled_output = self.dense1(double_pooled_output)\n",
    "        # double_pooled_output = self.dense2(double_pooled_output)\n",
    "        # double_pooled_output = self.dropout(double_pooled_output)\n",
    "        # logits = self.classifier(double_pooled_output)\n",
    "        \n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        outputs2 = (logits2,) + outputs2[2:]\n",
    "        outputs3 = (logits3,) + outputs3[2:]\n",
    "\n",
    "        return outputs,outputs2,outputs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=CustomBert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_optimizer = list(model.named_parameters())\n",
    "# #print(param_optimizer[0])\n",
    "# print(\"==============================\")\n",
    "# print(param_optimizer[0][0])\n",
    "# print(\"==============================\")\n",
    "# print(param_optimizer[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(param_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "# model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "# fold=7\n",
    "# bert_path=f\"./Bce-NoOptbinning/double-bert-based-case_f{fold}_best\"\n",
    "# model.load_state_dict(torch.load(bert_path),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280b773cbb8c4fa78afd8df8e77e1a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453731</td>\n",
       "      <td>0.688572</td>\n",
       "      <td>0.296974</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.303619</td>\n",
       "      <td>0.361379</td>\n",
       "      <td>0.318654</td>\n",
       "      <td>0.475862</td>\n",
       "      <td>0.501662</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518833</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.377539</td>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.141013</td>\n",
       "      <td>0.237259</td>\n",
       "      <td>0.695178</td>\n",
       "      <td>0.218975</td>\n",
       "      <td>0.567409</td>\n",
       "      <td>0.117885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.453731                0.688572   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.296974                      0.209405   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.303619                               0.361379   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.318654                       0.475862   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.501662                        0.062339  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.518833        0.234342                     0.377539   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.034318          0.141013             0.237259   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.695178               0.218975   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.567409             0.117885  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-1 epoch 0: 0.3635655513119051 / loss avg: 51.75513201638272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0182cb8efdeb41a090739a94432616b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.415535</td>\n",
       "      <td>0.707705</td>\n",
       "      <td>0.337191</td>\n",
       "      <td>0.259851</td>\n",
       "      <td>0.31279</td>\n",
       "      <td>0.358814</td>\n",
       "      <td>0.36066</td>\n",
       "      <td>0.518947</td>\n",
       "      <td>0.545929</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521757</td>\n",
       "      <td>0.208919</td>\n",
       "      <td>0.331187</td>\n",
       "      <td>0.12857</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.272252</td>\n",
       "      <td>0.734242</td>\n",
       "      <td>0.251885</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.139996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.415535                0.707705   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.337191                      0.259851   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.31279                               0.358814   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.36066                       0.518947   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.545929                        0.071719  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.521757        0.208919                     0.331187   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0           0.12857            0.1366             0.272252   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.734242               0.251885   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.629254             0.139996  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-1 epoch 1: 0.3904751859168864 / loss avg: 50.15014406254417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac66b707abb45b39438494e9ec2d194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448355</td>\n",
       "      <td>0.709077</td>\n",
       "      <td>0.339699</td>\n",
       "      <td>0.322908</td>\n",
       "      <td>0.33578</td>\n",
       "      <td>0.359071</td>\n",
       "      <td>0.386427</td>\n",
       "      <td>0.527935</td>\n",
       "      <td>0.56657</td>\n",
       "      <td>0.062327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562728</td>\n",
       "      <td>0.220154</td>\n",
       "      <td>0.364288</td>\n",
       "      <td>0.127093</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>0.291691</td>\n",
       "      <td>0.735073</td>\n",
       "      <td>0.259686</td>\n",
       "      <td>0.631185</td>\n",
       "      <td>0.205427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.448355                0.709077   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.339699                      0.322908   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.33578                               0.359071   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.386427                       0.527935   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                0.56657                        0.062327  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.562728        0.220154                     0.364288   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.127093          0.162312             0.291691   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.735073               0.259686   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.631185             0.205427  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-1 epoch 2: 0.40666583651676286 / loss avg: 49.273471662872716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498af75982694c57a5ee622203ce378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.600262</td>\n",
       "      <td>0.336393</td>\n",
       "      <td>0.206833</td>\n",
       "      <td>0.249241</td>\n",
       "      <td>0.416189</td>\n",
       "      <td>0.336893</td>\n",
       "      <td>0.395622</td>\n",
       "      <td>0.497644</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514976</td>\n",
       "      <td>0.228704</td>\n",
       "      <td>0.436811</td>\n",
       "      <td>0.177209</td>\n",
       "      <td>0.163432</td>\n",
       "      <td>0.336095</td>\n",
       "      <td>0.675892</td>\n",
       "      <td>0.23915</td>\n",
       "      <td>0.55985</td>\n",
       "      <td>0.163978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.347619                0.600262   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.336393                      0.206833   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.249241                               0.416189   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.336893                       0.395622   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.497644                         0.05455  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.514976        0.228704                     0.436811   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.177209          0.163432             0.336095   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.675892                0.23915   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.55985             0.163978  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-2 epoch 0: 0.3579074340072513 / loss avg: 52.12703221722653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c682794701ae4f7fbdc0f76bdc04db2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366546</td>\n",
       "      <td>0.640786</td>\n",
       "      <td>0.365937</td>\n",
       "      <td>0.254477</td>\n",
       "      <td>0.31436</td>\n",
       "      <td>0.448313</td>\n",
       "      <td>0.379643</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.519452</td>\n",
       "      <td>0.123507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519777</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.13608</td>\n",
       "      <td>0.21643</td>\n",
       "      <td>0.351842</td>\n",
       "      <td>0.715551</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.62021</td>\n",
       "      <td>0.195609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.366546                0.640786   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.365937                      0.254477   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.31436                               0.448313   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.379643                           0.47   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.519452                        0.123507  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.519777        0.297008                       0.4384   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0           0.13608           0.21643             0.351842   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.715551               0.311111   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.62021             0.195609  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-2 epoch 1: 0.38880654894836775 / loss avg: 50.654271979081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0767603f1c5f454f93c0ccd7ee44fe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.363224</td>\n",
       "      <td>0.650295</td>\n",
       "      <td>0.366166</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>0.322366</td>\n",
       "      <td>0.445573</td>\n",
       "      <td>0.395201</td>\n",
       "      <td>0.48462</td>\n",
       "      <td>0.538351</td>\n",
       "      <td>0.102864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529853</td>\n",
       "      <td>0.261838</td>\n",
       "      <td>0.485719</td>\n",
       "      <td>0.129249</td>\n",
       "      <td>0.179509</td>\n",
       "      <td>0.348739</td>\n",
       "      <td>0.716286</td>\n",
       "      <td>0.302156</td>\n",
       "      <td>0.636145</td>\n",
       "      <td>0.238945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.363224                0.650295   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.366166                      0.282453   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.322366                               0.445573   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.395201                        0.48462   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.538351                        0.102864  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.529853        0.261838                     0.485719   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.129249          0.179509             0.348739   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.716286               0.302156   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.636145             0.238945  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-2 epoch 2: 0.3951324570238007 / loss avg: 50.19039057430468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24087bc4bbe0409ba19c9b5fc35c8014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219817</td>\n",
       "      <td>0.638898</td>\n",
       "      <td>0.31969</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.288633</td>\n",
       "      <td>0.339509</td>\n",
       "      <td>0.272235</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.55219</td>\n",
       "      <td>0.070207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50736</td>\n",
       "      <td>0.19159</td>\n",
       "      <td>0.39274</td>\n",
       "      <td>0.100821</td>\n",
       "      <td>0.089356</td>\n",
       "      <td>0.224369</td>\n",
       "      <td>0.725208</td>\n",
       "      <td>0.231683</td>\n",
       "      <td>0.660738</td>\n",
       "      <td>0.248238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.219817                0.638898   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                  0.31969                      0.250034   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.288633                               0.339509   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.272235                       0.451239   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                0.55219                        0.070207  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0                0.50736         0.19159                      0.39274   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.100821          0.089356             0.224369   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.725208               0.231683   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.660738             0.248238  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-3 epoch 0: 0.3603013925531088 / loss avg: 51.79635229236201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f522abe8280f44fa82e55b9b20acb374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.356663</td>\n",
       "      <td>0.66988</td>\n",
       "      <td>0.345582</td>\n",
       "      <td>0.238474</td>\n",
       "      <td>0.315262</td>\n",
       "      <td>0.38365</td>\n",
       "      <td>0.31927</td>\n",
       "      <td>0.447006</td>\n",
       "      <td>0.511507</td>\n",
       "      <td>0.150768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536916</td>\n",
       "      <td>0.261052</td>\n",
       "      <td>0.399484</td>\n",
       "      <td>0.124378</td>\n",
       "      <td>0.173476</td>\n",
       "      <td>0.294212</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.198955</td>\n",
       "      <td>0.675127</td>\n",
       "      <td>0.235387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.356663                 0.66988   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.345582                      0.238474   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.315262                                0.38365   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.31927                       0.447006   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.511507                        0.150768  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.536916        0.261052                     0.399484   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.124378          0.173476             0.294212   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                     0.739               0.198955   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.675127             0.235387  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-3 epoch 1: 0.3836680979665319 / loss avg: 50.29585624368567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b25f9eede044c2889c19c6a978db788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374886</td>\n",
       "      <td>0.69929</td>\n",
       "      <td>0.370348</td>\n",
       "      <td>0.244548</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.374951</td>\n",
       "      <td>0.33343</td>\n",
       "      <td>0.469174</td>\n",
       "      <td>0.56193</td>\n",
       "      <td>0.144416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539495</td>\n",
       "      <td>0.272787</td>\n",
       "      <td>0.43138</td>\n",
       "      <td>0.137485</td>\n",
       "      <td>0.163357</td>\n",
       "      <td>0.283974</td>\n",
       "      <td>0.748957</td>\n",
       "      <td>0.189303</td>\n",
       "      <td>0.685992</td>\n",
       "      <td>0.256928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.374886                 0.69929   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.370348                      0.244548   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.316523                               0.374951   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.33343                       0.469174   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                0.56193                        0.144416  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.539495        0.272787                      0.43138   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.137485          0.163357             0.283974   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.748957               0.189303   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.685992             0.256928  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-3 epoch 2: 0.3939932441755045 / loss avg: 49.145515410523664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc625bb2df9841f78b507b57d1e1e3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382996</td>\n",
       "      <td>0.54864</td>\n",
       "      <td>0.396163</td>\n",
       "      <td>0.35675</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.406748</td>\n",
       "      <td>0.236301</td>\n",
       "      <td>0.477085</td>\n",
       "      <td>0.510004</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480107</td>\n",
       "      <td>0.180818</td>\n",
       "      <td>0.31184</td>\n",
       "      <td>0.100186</td>\n",
       "      <td>0.16285</td>\n",
       "      <td>0.178163</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>0.61912</td>\n",
       "      <td>0.160237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.382996                 0.54864   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.396163                       0.35675   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                 0.3184                               0.406748   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.236301                       0.477085   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.510004                        0.014579  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.480107        0.180818                      0.31184   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.100186           0.16285             0.178163   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.716037               0.222562   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.61912             0.160237  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-4 epoch 0: 0.3643723006565961 / loss avg: 51.439658786121164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab16ac4c81e241128186590a4abf5436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37955</td>\n",
       "      <td>0.589564</td>\n",
       "      <td>0.380379</td>\n",
       "      <td>0.32638</td>\n",
       "      <td>0.286301</td>\n",
       "      <td>0.424473</td>\n",
       "      <td>0.301825</td>\n",
       "      <td>0.494189</td>\n",
       "      <td>0.564084</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>0.219642</td>\n",
       "      <td>0.29829</td>\n",
       "      <td>0.144373</td>\n",
       "      <td>0.190839</td>\n",
       "      <td>0.214932</td>\n",
       "      <td>0.730486</td>\n",
       "      <td>0.231207</td>\n",
       "      <td>0.668948</td>\n",
       "      <td>0.210328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                              0.37955                0.589564   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.380379                       0.32638   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.286301                               0.424473   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.301825                       0.494189   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.564084                        0.046908  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.524007        0.219642                      0.29829   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.144373          0.190839             0.214932   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.730486               0.231207   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.668948             0.210328  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-4 epoch 1: 0.3822240544341434 / loss avg: 49.32229473716334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ecb6d8ba74e63a99bc7b2473906e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.39594</td>\n",
       "      <td>0.606558</td>\n",
       "      <td>0.394594</td>\n",
       "      <td>0.364562</td>\n",
       "      <td>0.368293</td>\n",
       "      <td>0.446117</td>\n",
       "      <td>0.30544</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.579188</td>\n",
       "      <td>0.02811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530044</td>\n",
       "      <td>0.264265</td>\n",
       "      <td>0.333902</td>\n",
       "      <td>0.201055</td>\n",
       "      <td>0.189855</td>\n",
       "      <td>0.262759</td>\n",
       "      <td>0.740425</td>\n",
       "      <td>0.242866</td>\n",
       "      <td>0.665772</td>\n",
       "      <td>0.235414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                              0.39594                0.606558   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.394594                      0.364562   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.368293                               0.446117   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.30544                       0.520516   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.579188                         0.02811  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.530044        0.264265                     0.333902   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.201055          0.189855             0.262759   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.740425               0.242866   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.665772             0.235414  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-4 epoch 2: 0.40077184113193287 / loss avg: 48.523101474109446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc77564f8709439882f0600bfb3d42b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.324427</td>\n",
       "      <td>0.638124</td>\n",
       "      <td>0.371821</td>\n",
       "      <td>0.171209</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>0.286022</td>\n",
       "      <td>0.338005</td>\n",
       "      <td>0.326053</td>\n",
       "      <td>0.575589</td>\n",
       "      <td>0.03066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426873</td>\n",
       "      <td>0.172664</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.169053</td>\n",
       "      <td>0.28131</td>\n",
       "      <td>0.713174</td>\n",
       "      <td>0.238116</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>0.220528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.324427                0.638124   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.371821                      0.171209   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                 0.2954                               0.286022   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.338005                       0.326053   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.575589                         0.03066  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.426873        0.172664                     0.384248   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.158495          0.169053              0.28131   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.713174               0.238116   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                          0.6297             0.220528  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-5 epoch 0: 0.35965300210658235 / loss avg: 51.790085309430175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a1c61ab23c44429752a04af79152c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355329</td>\n",
       "      <td>0.714179</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.193842</td>\n",
       "      <td>0.280537</td>\n",
       "      <td>0.367522</td>\n",
       "      <td>0.332348</td>\n",
       "      <td>0.45296</td>\n",
       "      <td>0.618293</td>\n",
       "      <td>0.016866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473192</td>\n",
       "      <td>0.232677</td>\n",
       "      <td>0.378749</td>\n",
       "      <td>0.189124</td>\n",
       "      <td>0.183507</td>\n",
       "      <td>0.315436</td>\n",
       "      <td>0.720823</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>0.663977</td>\n",
       "      <td>0.233145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.355329                0.714179   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.379091                      0.193842   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.280537                               0.367522   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.332348                        0.45296   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.618293                        0.016866  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.473192        0.232677                     0.378749   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.189124          0.183507             0.315436   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.720823               0.277548   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.663977             0.233145  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-5 epoch 1: 0.38697605964005527 / loss avg: 49.327952108885114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686f1bc50d304bf499367ef15b66254e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366159</td>\n",
       "      <td>0.71697</td>\n",
       "      <td>0.383453</td>\n",
       "      <td>0.234259</td>\n",
       "      <td>0.31537</td>\n",
       "      <td>0.362027</td>\n",
       "      <td>0.384236</td>\n",
       "      <td>0.466823</td>\n",
       "      <td>0.628002</td>\n",
       "      <td>0.037499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469759</td>\n",
       "      <td>0.248507</td>\n",
       "      <td>0.395941</td>\n",
       "      <td>0.195111</td>\n",
       "      <td>0.154449</td>\n",
       "      <td>0.316362</td>\n",
       "      <td>0.716627</td>\n",
       "      <td>0.274158</td>\n",
       "      <td>0.670387</td>\n",
       "      <td>0.197837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.366159                 0.71697   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.383453                      0.234259   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.31537                               0.362027   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.384236                       0.466823   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.628002                        0.037499  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.469759        0.248507                     0.395941   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.195111          0.154449             0.316362   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.716627               0.274158   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.670387             0.197837  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-5 epoch 2: 0.39486878412826676 / loss avg: 48.871017430958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b01d1c76e84029bbc930f6afe3eaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257932</td>\n",
       "      <td>0.615891</td>\n",
       "      <td>0.471133</td>\n",
       "      <td>0.287469</td>\n",
       "      <td>0.343784</td>\n",
       "      <td>0.440561</td>\n",
       "      <td>0.299461</td>\n",
       "      <td>0.403643</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480622</td>\n",
       "      <td>0.179225</td>\n",
       "      <td>0.385034</td>\n",
       "      <td>0.13307</td>\n",
       "      <td>0.176022</td>\n",
       "      <td>0.270132</td>\n",
       "      <td>0.707777</td>\n",
       "      <td>0.256561</td>\n",
       "      <td>0.553739</td>\n",
       "      <td>0.11678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.257932                0.615891   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.471133                      0.287469   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.343784                               0.440561   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.299461                       0.403643   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                 0.4924                          0.0041  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.480622        0.179225                     0.385034   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0           0.13307          0.176022             0.270132   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.707777               0.256561   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.553739              0.11678  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-6 epoch 0: 0.35365237429392843 / loss avg: 53.629215503993784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d81f84b10848b18a5d5f074aa3b9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.364423</td>\n",
       "      <td>0.639267</td>\n",
       "      <td>0.461243</td>\n",
       "      <td>0.306278</td>\n",
       "      <td>0.378362</td>\n",
       "      <td>0.474521</td>\n",
       "      <td>0.33361</td>\n",
       "      <td>0.452942</td>\n",
       "      <td>0.538859</td>\n",
       "      <td>0.080495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51127</td>\n",
       "      <td>0.217143</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.166128</td>\n",
       "      <td>0.163817</td>\n",
       "      <td>0.262839</td>\n",
       "      <td>0.692935</td>\n",
       "      <td>0.218339</td>\n",
       "      <td>0.554148</td>\n",
       "      <td>0.127206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.364423                0.639267   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.461243                      0.306278   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.378362                               0.474521   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.33361                       0.452942   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.538859                        0.080495  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0                0.51127        0.217143                     0.461215   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.166128          0.163817             0.262839   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.692935               0.218339   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.554148             0.127206  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-6 epoch 1: 0.38466873787927564 / loss avg: 51.79725502666674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b2c40605c644489030ddd98582b8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382929</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.493737</td>\n",
       "      <td>0.314211</td>\n",
       "      <td>0.40714</td>\n",
       "      <td>0.481413</td>\n",
       "      <td>0.304248</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.57203</td>\n",
       "      <td>0.074927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548317</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>0.438169</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.150492</td>\n",
       "      <td>0.290001</td>\n",
       "      <td>0.721884</td>\n",
       "      <td>0.214275</td>\n",
       "      <td>0.561234</td>\n",
       "      <td>0.114311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.382929                0.651042   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.493737                      0.314211   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.40714                               0.481413   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.304248                          0.471   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0                0.57203                        0.074927  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.548317        0.217177                     0.438169   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0            0.1554          0.150492             0.290001   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.721884               0.214275   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.561234             0.114311  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-6 epoch 2: 0.3953643433454056 / loss avg: 50.6818452508826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Configuration saved in ./token_model_config/config\\config.json\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Lab000/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Configuration saved in ./token_model_config/model\\config.json\n",
      "Model weights saved in ./token_model_config/model\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31158fe04c114082b011ab65975d5818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.587487</td>\n",
       "      <td>0.388509</td>\n",
       "      <td>0.195275</td>\n",
       "      <td>0.251259</td>\n",
       "      <td>0.384145</td>\n",
       "      <td>0.298486</td>\n",
       "      <td>0.469867</td>\n",
       "      <td>0.562054</td>\n",
       "      <td>0.095795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402184</td>\n",
       "      <td>0.113755</td>\n",
       "      <td>0.318011</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>0.071072</td>\n",
       "      <td>0.241512</td>\n",
       "      <td>0.74989</td>\n",
       "      <td>0.277352</td>\n",
       "      <td>0.631331</td>\n",
       "      <td>0.128723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                               0.3331                0.587487   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.388509                      0.195275   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.251259                               0.384145   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.298486                       0.469867   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.562054                        0.095795  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.402184        0.113755                     0.318011   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.025492          0.071072             0.241512   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                   0.74989               0.277352   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.631331             0.128723  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-7 epoch 0: 0.3521414562480321 / loss avg: 52.97065596831472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95cb71576bc448c8200dbd102d0aaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.331086</td>\n",
       "      <td>0.626157</td>\n",
       "      <td>0.449936</td>\n",
       "      <td>0.284308</td>\n",
       "      <td>0.340565</td>\n",
       "      <td>0.469894</td>\n",
       "      <td>0.358787</td>\n",
       "      <td>0.530761</td>\n",
       "      <td>0.599947</td>\n",
       "      <td>0.164623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45651</td>\n",
       "      <td>0.238913</td>\n",
       "      <td>0.260035</td>\n",
       "      <td>0.109817</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.33479</td>\n",
       "      <td>0.74318</td>\n",
       "      <td>0.304152</td>\n",
       "      <td>0.648177</td>\n",
       "      <td>0.092573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_asker_intent_understanding  question_body_critical  \\\n",
       "0                             0.331086                0.626157   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.449936                      0.284308   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.340565                               0.469894   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.358787                       0.530761   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  ...  \\\n",
       "0               0.599947                        0.164623  ...   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0                0.45651        0.238913                     0.260035   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.109817          0.187583              0.33479   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                   0.74318               0.304152   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.648177             0.092573  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-7 epoch 1: 0.395664750462516 / loss avg: 49.86160350473303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b629fbdddd4fbb9f5e3f343ece8c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19928\\3426699424.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m       \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lab000\\anaconda3\\envs\\contrastive_learning2\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mclip_coef_clamped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef_clamped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "N_FOLD=10\n",
    "N_BERT_LABEL = 30\n",
    "SEED = 42\n",
    "#BS = 8\n",
    "BS = 2\n",
    "# parameter\n",
    "n_epoch = 3\n",
    "learning_rate = 5e-5\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "gkf = GroupKFold(n_splits=N_FOLD).split(X=train[\"question_body\"], groups=train[\"question_body\"])#??\n",
    "\n",
    "spearman_scores = []\n",
    "best_spearman_lst = []\n",
    "losses_lst = []\n",
    "epoch_spearman_lst = []\n",
    "lr_lst_lst = []\n",
    "each_speaman_dfs = []\n",
    "#model=CustomBert(model)\n",
    "#torch.save(model.config, 'config.pth')\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):#??\n",
    "  # print(train_idx)\n",
    "  # print(\"=======================\")\n",
    "  # print(valid_idx)\n",
    "  # if fold>=1:\n",
    "  #   break\n",
    "  if fold in [0]:\n",
    "    continue\n",
    "\n",
    "  seed_everything(SEED)\n",
    "\n",
    "  # Load Model\n",
    "#   config = BertConfig.from_pretrained(pretrained_weights)\n",
    "#   model = CustomBert.from_pretrained(pretrained_weights, config=config)\n",
    "  model_name=\"bert-base-cased\"\n",
    "  model=CustomBert(model_name)\n",
    "  model = model.to(device)\n",
    "  model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "  model.bert2.resize_token_embeddings(len(tokenizer))\n",
    "  model.bert3.resize_token_embeddings(len(tokenizer))\n",
    "  model = model.train()\n",
    "  \n",
    "  # optimizer setting\n",
    "  param_optimizer = list(model.named_parameters())\n",
    "  no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
    "  optimizer_grouped_parameters = []\n",
    "  max_lrs = []\n",
    "  for param in param_optimizer:\n",
    "    if any(n in param[0] for n in no_decay):#weight_decay\n",
    "      weight_decay = 0.0\n",
    "    else:\n",
    "      weight_decay = 0.1\n",
    "    if param[0].find(\"bert.encoder.layer\") != -1:\n",
    "      \n",
    "      n_diff_last = 11 - int(param[0].split(\".\")[3])\n",
    "      lr = learning_rate*0.9**n_diff_last\n",
    "    elif \"embeddings\" in param[0]:\n",
    "      lr = learning_rate*0.9**11\n",
    "    else:\n",
    "      lr = learning_rate\n",
    "    max_lrs.append(lr)\n",
    "    d = {\"params\": param[1], \"weight_decay\": weight_decay}\n",
    "    optimizer_grouped_parameters.append(d)\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=True)\n",
    "\n",
    "  # print(train_idx)\n",
    "  # print(\"===========================\")\n",
    "  # print(valid_idx)\n",
    "  \n",
    "  # train valid split\n",
    "  train_x = X[train_idx]\n",
    "  valid_x = X[valid_idx]\n",
    "  train_y = y[train_idx]\n",
    "  valid_y = y[valid_idx]\n",
    "\n",
    "  train_y2 = y2[train_idx]\n",
    "  train_y3 = y3[train_idx]\n",
    "  valid_y2 = y2[valid_idx]\n",
    "  valid_y3 = y3[valid_idx]\n",
    "  # set loader  \n",
    "  train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_x, dtype=torch.long), \n",
    "                                                 torch.tensor(train_y, dtype=torch.float),torch.tensor(train_y2, dtype=torch.float)\n",
    "                                                 ,torch.tensor(train_y3, dtype=torch.float))\n",
    "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "  valid_dataset = torch.utils.data.TensorDataset(torch.tensor(valid_x, dtype=torch.long), \n",
    "                                                 torch.tensor(valid_y, dtype=torch.float),torch.tensor(valid_y2, dtype=torch.float)\n",
    "                                                 ,torch.tensor(valid_y3, dtype=torch.float))\n",
    "  valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "  # set schedueler\n",
    "  num_training_steps = len(train_loader)*n_epoch\n",
    "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lrs, total_steps=num_training_steps)\n",
    "\n",
    "  model.zero_grad()\n",
    "  optimizer.zero_grad()\n",
    "   \n",
    "  best_spearman = 0\n",
    "  losses = []\n",
    "  epoch_spearman = []\n",
    "  lr_lst = []\n",
    "  for epoch in range(n_epoch):\n",
    "    lr = np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean()\n",
    "    tk0 = tqdm_notebook(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for i, (x_batch, y_batch,y_batch2,y_batch3) in tk0:\n",
    "      input_ids = x_batch[:, :512]\n",
    "      token_ids = x_batch[:, 512:1024]\n",
    "      input_ids2 = x_batch[:, 1024:1536]\n",
    "      token_ids2 = x_batch[:, 1536:2048]\n",
    "      input_ids3 = x_batch[:, 2048:2560]\n",
    "      token_ids3 = x_batch[:, 2560:]\n",
    "      #print((input_ids > 0))\n",
    "      #print(token_ids.max())\n",
    "      #mask=(input_ids > 0).type(torch.uint8)\n",
    "      #print(mask) \n",
    "      y_pred,y_pred2,y_pred3 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n",
    "                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device)\n",
    "                     ,input_ids3=input_ids3.to(device),attention_mask3=(input_ids3 > 0).to(device),token_type_ids3=token_ids3.to(device))\n",
    "      #y_pred = model(input_ids.to(device), attention_mask=mask.to(device), token_type_ids=token_ids.to(device))\n",
    "      loss = custom_loss(y_pred[0], y_pred2[0],y_pred3[0],y_batch.to(device),y_batch2.to(device),y_batch3.to(device))\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) \n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      scheduler.step()\n",
    "      lr_lst.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
    "      losses.append(float(loss))\n",
    "\n",
    "    # epoch validation\n",
    "    for param in model.parameters():\n",
    "      param.requires_grad=False\n",
    "    model.eval()\n",
    "\n",
    "    lst = []\n",
    "    sum_loss = 0\n",
    "    for i, (x_batch, y_batch,y_batch2,y_batch3)  in enumerate(valid_loader):\n",
    "      input_ids = x_batch[:, :512]\n",
    "      token_ids = x_batch[:, 512:1024]\n",
    "      input_ids2 = x_batch[:, 1024:1536]\n",
    "      token_ids2 = x_batch[:, 1536:2048]\n",
    "      input_ids3 = x_batch[:, 2048:2560]\n",
    "      token_ids3 = x_batch[:, 2560:]\n",
    "\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        #y_pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n",
    "        y_pred,y_pred2,y_pred3 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n",
    "                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device)\n",
    "                     ,input_ids3=input_ids3.to(device),attention_mask3=(input_ids3 > 0).to(device),token_type_ids3=token_ids3.to(device))\n",
    "        loss = custom_loss(y_pred[0], y_pred2[0],y_pred3[0],y_batch.to(device),y_batch2.to(device),y_batch3.to(device))\n",
    "      #print(y_pred[0].shape)\n",
    "      \n",
    "      total_y_pred=torch.cat((y_pred[0],y_pred2[0]),dim=1)\n",
    "      \n",
    "      #lst.append(y_pred[0].sigmoid().cpu().squeeze().numpy())\n",
    "      lst.append(total_y_pred.sigmoid().cpu().squeeze().numpy())\n",
    "      #lst+(y_pred2[0].sigmoid().cpu().squeeze().numpy())\n",
    "      sum_loss += loss.cpu().squeeze().numpy()\n",
    "    valid_pred = np.vstack(lst)#(608,30)\n",
    "    \n",
    "    ave_loss = sum_loss/len(valid_loader)\n",
    "\n",
    "    spearman_score = spearman_corr(valid_y3[:,:N_BERT_LABEL], valid_pred)  \n",
    "    epoch_spearman.append(spearman_score)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "      param.requires_grad=True\n",
    "    model.train()\n",
    "    model_name=\"triple-bert-based-case\"\n",
    "    # print(f\"{model}_f{fold}_best\")\n",
    "    # print(\"=======================================\")\n",
    "    if best_spearman <= spearman_score:\n",
    "      #torch.save(model.state_dict(), f\"{model_name}_f{fold}_best\")\n",
    "      torch.save(model.state_dict(), f\"./triple/Bce-NoOptbinning/{model_name}_f{fold}_best\")\n",
    "      best_spearman = spearman_score\n",
    "      #print(valid_y3[:,:N_BERT_LABEL])\n",
    "      each_speaman_df = calc_each_spearman(valid_y3[:,:N_BERT_LABEL], valid_pred)\n",
    "      display(each_speaman_df)\n",
    "\n",
    "    print(f\"fold-{fold} epoch {epoch}: {spearman_score} / loss avg: {ave_loss}\")\n",
    "    \n",
    "  best_spearman_lst.append(best_spearman)\n",
    "  losses_lst.append(losses)\n",
    "  epoch_spearman_lst.append(epoch_spearman)\n",
    "  lr_lst_lst.append(lr_lst)\n",
    "  each_speaman_dfs.append(each_speaman_df)\n",
    "\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "490296f01f129d1791d2b0949f01d8bcbb5336528260279af7e468eefab7c316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
