{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:28.594147Z","iopub.status.busy":"2023-03-16T06:15:28.593081Z","iopub.status.idle":"2023-03-16T06:15:40.597027Z","shell.execute_reply":"2023-03-16T06:15:40.595913Z","shell.execute_reply.started":"2023-03-16T06:15:28.594103Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","from scipy import stats\n","from sklearn.model_selection import GroupKFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.utils.data\n","#from transformers import *\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","import os\n","import re\n","import math\n","import random\n","from matplotlib import pyplot as plt\n","import warnings\n","from math import floor, ceil\n","\n","warnings.filterwarnings('ignore')\n","device = torch.device('cuda')\n","torch.backends.cudnn.benchmark=True\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:40.600831Z","iopub.status.busy":"2023-03-16T06:15:40.59978Z","iopub.status.idle":"2023-03-16T06:15:40.952859Z","shell.execute_reply":"2023-03-16T06:15:40.951674Z","shell.execute_reply.started":"2023-03-16T06:15:40.600785Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/train.csv').fillna(' ')\n","test = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/test.csv').fillna(' ')\n","sub = pd.read_csv('C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/my-solution/input/google-quest-challenge/sample_submission.csv').fillna(' ')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:40.954563Z","iopub.status.busy":"2023-03-16T06:15:40.954192Z","iopub.status.idle":"2023-03-16T06:15:40.963483Z","shell.execute_reply":"2023-03-16T06:15:40.962414Z","shell.execute_reply.started":"2023-03-16T06:15:40.954526Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n","       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n","       'url', 'category', 'host', 'question_asker_intent_understanding',\n","       'question_body_critical', 'question_conversational',\n","       'question_expect_short_answer', 'question_fact_seeking',\n","       'question_has_commonly_accepted_answer',\n","       'question_interestingness_others', 'question_interestingness_self',\n","       'question_multi_intent', 'question_not_really_a_question',\n","       'question_opinion_seeking', 'question_type_choice',\n","       'question_type_compare', 'question_type_consequence',\n","       'question_type_definition', 'question_type_entity',\n","       'question_type_instructions', 'question_type_procedure',\n","       'question_type_reason_explanation', 'question_type_spelling',\n","       'question_well_written', 'answer_helpful',\n","       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n","       'answer_satisfaction', 'answer_type_instructions',\n","       'answer_type_procedure', 'answer_type_reason_explanation',\n","       'answer_well_written'],\n","      dtype='object')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train.columns"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:40.967543Z","iopub.status.busy":"2023-03-16T06:15:40.966745Z","iopub.status.idle":"2023-03-16T06:15:40.987097Z","shell.execute_reply":"2023-03-16T06:15:40.985939Z","shell.execute_reply.started":"2023-03-16T06:15:40.967499Z"},"trusted":true},"outputs":[],"source":["def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            if first_sep:\n","                first_sep = False\n","                current_segment_id = 1#新增 \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input(title, question, answer, max_sequence_length=512-1, \n","                t_max_len=70-1, q_max_len=219, a_max_len=219):#???\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","\n","        t = t[:t_new_len]\n","        q = norm_token_length(q, q_new_len)\n","        a = norm_token_length(a, a_new_len)\n","    \n","    return t, q, a\n","\n","def norm_token_length(tokens, l):\n","    if len(tokens) > l:\n","        head = l//2\n","        tail = l - head\n","        return tokens[:head] + tokens[-tail:]\n","    else:\n","        return tokens[:l]\n","\n","def _convert_to_bert_inputs(title, question, answer, cate, max_sequence_length=512):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    #stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n","    stoken_1 = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n","    stoken_2 = [\"[CLS]\"] + [cate]+title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n","    input_ids = _get_ids(stoken_1, tokenizer, max_sequence_length)\n","    input_ids_2 = _get_ids(stoken_2, tokenizer, max_sequence_length)\n","    input_segments = _get_segments(stoken_1, max_sequence_length)\n","    input_segments_2 = _get_segments(stoken_2, max_sequence_length)\n","    \n","    #return [input_ids, input_segments]\n","    return input_ids, input_segments,input_ids_2,input_segments_2\n","\n","def convert_row(row,pretrained_weights):\n","    #c = f\"[{row['category'].lower()}]\"\n","\n","    if pretrained_weights == \"bert-base-uncased\":\n","        c = f\"[{row['category'].lower()}]\"#type:str\n","    elif pretrained_weights == \"bert-base-cased\":\n","        c = f\"[{row['category']}]\"#type:str\n","    elif pretrained_weights == \"xlnet-base-cased\":\n","        c = f\"[{row['category']}]\"#type:str\n","    t, q, a = title = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]#type:str\n","\n","\n","    t, q, a = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]\n","    t, q, a = _trim_input(t, q, a)\n","    #ids, segments = _convert_to_bert_inputs(t, q, a, c)\n","    ids, segments, ids2, segments2 = _convert_to_bert_inputs(t, q, a, c)\n","    #total_input=[np.array([[ids, segments]]),np.array([[ids2, segments2]])]\n","    # total_input=[]\n","    # print(np.array([[ids, segments]]).shape)\n","    # total_input.append(np.array([[ids, segments]]))\n","    # total_input.append(np.array([[ids2, segments2]]))\n","    # return total_input\n","    return np.array([[ids, segments, ids2, segments2]])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:40.990992Z","iopub.status.busy":"2023-03-16T06:15:40.990637Z","iopub.status.idle":"2023-03-16T06:15:41.06523Z","shell.execute_reply":"2023-03-16T06:15:41.064135Z","shell.execute_reply.started":"2023-03-16T06:15:40.990966Z"},"trusted":true},"outputs":[],"source":["#model=\"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(\"./double/token_model_config/tokenizer/\")\n","#tokenizer.add_tokens(\"./bert_based_tokenizer/added_tokens.json\")\n","#tokenizer.add_tokens(categories)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:41.066913Z","iopub.status.busy":"2023-03-16T06:15:41.066511Z","iopub.status.idle":"2023-03-16T06:15:41.073524Z","shell.execute_reply":"2023-03-16T06:15:41.072458Z","shell.execute_reply.started":"2023-03-16T06:15:41.06687Z"},"trusted":true},"outputs":[{"data":{"text/plain":["29001"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["len(tokenizer)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:41.07598Z","iopub.status.busy":"2023-03-16T06:15:41.07525Z","iopub.status.idle":"2023-03-16T06:15:41.09558Z","shell.execute_reply":"2023-03-16T06:15:41.094669Z","shell.execute_reply.started":"2023-03-16T06:15:41.075942Z"},"trusted":true},"outputs":[],"source":["def custom_loss(data,data2, targets,targets2):\n","    \n","    # mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n","    # bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])#??\n","    mse = nn.MSELoss(reduction=\"none\")(data[:,:].sigmoid(), targets[:,:])\n","    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:], targets[:,:])#??\n","    \n","    mse2 = nn.MSELoss(reduction=\"none\")(data2[:,:].sigmoid(), targets2[:,:])\n","    bce2 = nn.BCEWithLogitsLoss(reduction='none')(data2[:,:], targets2[:,:])#??\n","    #w =  targets[:,30:]\n","    #loss = (mse*w).sum() + bce.sum()\n","    loss = (mse).sum()+ bce.sum()+mse2.sum()+bce2.sum()\n","    return loss\n","\n","class CustomBert(nn.Module):\n","    def __init__(self, config_path=None):\n","        super(CustomBert, self).__init__()\n","        self.config = AutoConfig.from_pretrained(config_path) \n","        \n","        self.config.Q_labels = 21\n","        self.config.A_labels = 9\n","        self.config.output_hidden_states = True\n","        self.n_use_layer = 4 #原本\n","        #self.n_use_layer = 2\n","        self.double_bert= 1\n","        self.n_labels = self.config.num_labels\n","        #self.config.save_pretrained(\"bert_based_config\")\n","        #self.config.save_pretrained(output_dir+\"config\")\n","        #self.bert = BertModel(config)\n","        self.bert=AutoModel.from_config(self.config)\n","        self.bert2=AutoModel.from_config(self.config)\n","        #self.bert.save_pretrained('bert_based_model')\n","        #self.bert.save_pretrained(output_dir+\"model\")\n","        # self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n","        # self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n","        # self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n","        # self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n","\n","        self.dense1 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n","        self.dense2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n","        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.Q_labels)\n","        self.classifier2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.A_labels)\n","        #self.init_weights()\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None\n","                ,input_ids2=None, attention_mask2=None, token_type_ids2=None,position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n","\n","        # outputs = self.bert(input_ids,\n","        #                     attention_mask=attention_mask,\n","        #                     token_type_ids=token_type_ids,\n","        #                     position_ids=position_ids,\n","        #                     head_mask=head_mask,\n","        #                     inputs_embeds=inputs_embeds)\n","        outputs = self.bert(input_ids,\n","                            attention_mask=attention_mask,\n","                            token_type_ids=token_type_ids\n","                            )\n","        outputs2 = self.bert2(input_ids2,\n","                            attention_mask=attention_mask2,\n","                            token_type_ids=token_type_ids2\n","                            )\n","        \n","        #print(outputs[2][-1].shape)\n","        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後4個layer的cls output concat在一起，把4個(8,768) concat，變成(8,3072) #原本\n","        pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n","        #pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後2個layer的cls output concat在一起,把2個(8,768) concat，變成(8,1536)\n","        #pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#同上\n","        #double_pooled_output=torch.cat([pooled_output,pooled_output],dim=1)#(8,3072)\n","        \n","        pooled_output = self.dense1(pooled_output)\n","        pooled_output = self.dense2(pooled_output)\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        pooled_output2 = self.dense1(pooled_output2)\n","        pooled_output2 = self.dense2(pooled_output2)\n","        pooled_output2 = self.dropout(pooled_output2)\n","        logits2 = self.classifier2(pooled_output2)\n","\n","        # double_pooled_output = self.dense1(double_pooled_output)\n","        # double_pooled_output = self.dense2(double_pooled_output)\n","        # double_pooled_output = self.dropout(double_pooled_output)\n","        # logits = self.classifier(double_pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]\n","        outputs2 = (logits2,) + outputs2[2:]\n","\n","        return outputs,outputs2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:41.099107Z","iopub.status.busy":"2023-03-16T06:15:41.098672Z","iopub.status.idle":"2023-03-16T06:15:45.540015Z","shell.execute_reply":"2023-03-16T06:15:45.538714Z","shell.execute_reply.started":"2023-03-16T06:15:41.09907Z"},"trusted":true},"outputs":[],"source":["model=CustomBert(\"double/token_model_config/config/config.json\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:45.542445Z","iopub.status.busy":"2023-03-16T06:15:45.542034Z","iopub.status.idle":"2023-03-16T06:15:45.548834Z","shell.execute_reply":"2023-03-16T06:15:45.54723Z","shell.execute_reply.started":"2023-03-16T06:15:45.542401Z"},"trusted":true},"outputs":[],"source":["BS=8"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:45.555718Z","iopub.status.busy":"2023-03-16T06:15:45.554518Z","iopub.status.idle":"2023-03-16T06:15:46.44659Z","shell.execute_reply":"2023-03-16T06:15:46.445535Z","shell.execute_reply.started":"2023-03-16T06:15:45.555673Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4324 > 512). Running this sequence through the model will result in indexing errors\n"]}],"source":["pretrained_weights = 'bert-base-cased'\n","X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n","#X_train = train[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n","#np.vstack(X_test).shape : (476, 2, 512)\n","X_test = np.vstack(X_test).reshape((len(X_test), 2048))\n","\n","test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:15:46.451002Z","iopub.status.busy":"2023-03-16T06:15:46.450453Z","iopub.status.idle":"2023-03-16T06:15:52.10067Z","shell.execute_reply":"2023-03-16T06:15:52.099745Z","shell.execute_reply.started":"2023-03-16T06:15:46.450971Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CustomBert(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29001, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert2): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29001, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dense1): Linear(in_features=3072, out_features=3072, bias=True)\n","  (dense2): Linear(in_features=3072, out_features=3072, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=3072, out_features=21, bias=True)\n","  (classifier2): Linear(in_features=3072, out_features=9, bias=True)\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model = model.to(device)\n","for param in model.parameters():\n","    param.requires_grad=False\n","model.bert.resize_token_embeddings(len(tokenizer))#??\n","model.bert2.resize_token_embeddings(len(tokenizer))\n","model.eval()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-16T06:17:40.965284Z","iopub.status.busy":"2023-03-16T06:17:40.964097Z"},"trusted":true},"outputs":[],"source":["#model_dir_target = \"../input/Optimize binning/bert-base-cased\"#\n","\n","cased_pred_lst = []\n","for fold in range(10):\n","    # if fold in [0,1,2,3,4,5,6,7]:\n","    #     continue\n","    #bert_path = f\"{model_dir_target}/bert-base-cased_f{fold}_best\"\n","    #bert_path=f\"./DoubleBertBasedCase/bce_no_opt_binning/double-bert-based-case_f{fold}_best\"\n","    bert_path=f\"./double/Bce-NoOptbinning/double-bert-based-case_f{fold}_best\"\n","    model.load_state_dict(torch.load(bert_path),strict=False)\n","    \n","    lst = []\n","    for i, (x_batch,)  in enumerate(test_loader):\n","        # input_ids = x_batch[:, :512]\n","        # token_ids = x_batch[:, 512:]\n","        input_ids = x_batch[:, :512]\n","        token_ids = x_batch[:, 512:1024]\n","        input_ids2 = x_batch[:, 1024:1536]\n","        token_ids2 = x_batch[:, 1536:]\n","        #pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n","        pred, pred2 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n","                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device))\n","        total_y_pred=torch.cat((pred[0],pred2[0]),dim=1)\n","        lst.append(total_y_pred.detach().cpu().squeeze().numpy())\n","    train_pred = np.vstack(lst)#shape:(476, 30)\n","    \n","    cased_pred_lst.append(train_pred)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.812104Z","iopub.status.idle":"2023-03-16T06:15:52.812914Z","shell.execute_reply":"2023-03-16T06:15:52.812651Z","shell.execute_reply.started":"2023-03-16T06:15:52.812624Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(476, 30)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["cased_pred_lst[0].shape"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.814439Z","iopub.status.idle":"2023-03-16T06:15:52.81533Z","shell.execute_reply":"2023-03-16T06:15:52.815074Z","shell.execute_reply.started":"2023-03-16T06:15:52.815046Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[array([[ 2.9148734 ,  0.5870639 , -1.0286921 , ..., -3.9417024 ,\n","          3.10868   ,  2.7866461 ],\n","        [ 1.9138436 , -0.14367273, -5.5822263 , ..., -2.0265653 ,\n","         -2.8845267 ,  2.1542585 ],\n","        [ 2.260144  ,  0.7972341 , -4.2451344 , ..., -3.3293252 ,\n","          2.7163298 ,  2.2225938 ],\n","        ...,\n","        [ 1.6526257 , -0.734839  , -4.6569324 , ..., -1.4699891 ,\n","         -0.48530427,  1.9625342 ],\n","        [ 3.188662  ,  1.6525309 , -4.248226  , ..., -2.487862  ,\n","          3.2956543 ,  2.9502594 ],\n","        [ 2.392885  ,  0.2380366 , -3.6111574 , ..., -1.605704  ,\n","         -1.4362035 ,  2.105583  ]], dtype=float32),\n"," array([[ 2.5103564 ,  0.45609975, -2.0337408 , ..., -3.6385996 ,\n","          2.5943546 ,  2.7311163 ],\n","        [ 1.9764313 , -0.17333022, -6.054926  , ..., -1.9884539 ,\n","         -2.7503853 ,  2.3761356 ],\n","        [ 2.3559232 ,  0.8823283 , -4.627333  , ..., -3.3722978 ,\n","          2.6931622 ,  2.3779893 ],\n","        ...,\n","        [ 1.5696981 , -0.64607036, -4.4800634 , ..., -1.7597274 ,\n","          0.1621161 ,  2.4484308 ],\n","        [ 2.9438741 ,  1.555677  , -3.6107452 , ..., -2.4905987 ,\n","          2.6066194 ,  2.9100482 ],\n","        [ 2.5028286 , -0.08038376, -4.2873487 , ..., -2.0626779 ,\n","         -1.9099687 ,  2.138699  ]], dtype=float32),\n"," array([[ 2.7413955 ,  0.49686697, -1.139848  , ..., -3.5026126 ,\n","          2.801488  ,  2.4525678 ],\n","        [ 1.854656  , -0.20697246, -5.5248923 , ..., -1.9294177 ,\n","         -2.8864546 ,  2.0854151 ],\n","        [ 2.554181  ,  0.9449198 , -4.778121  , ..., -2.8906264 ,\n","          2.3344169 ,  2.190161  ],\n","        ...,\n","        [ 1.884864  , -0.51858646, -4.894277  , ..., -1.6033946 ,\n","         -1.691344  ,  1.8583857 ],\n","        [ 2.6513488 ,  1.4080722 , -3.420844  , ..., -2.746457  ,\n","          3.6349485 ,  2.7363155 ],\n","        [ 2.2694716 ,  0.22983024, -3.7165256 , ..., -1.9667453 ,\n","         -1.0660452 ,  1.9637207 ]], dtype=float32),\n"," array([[ 2.8536332 ,  0.55421054, -1.3037102 , ..., -3.7246604 ,\n","          2.5915303 ,  2.4627233 ],\n","        [ 1.6757438 , -0.20795946, -5.3240175 , ..., -2.0022755 ,\n","         -3.1192534 ,  1.8289504 ],\n","        [ 2.6733403 ,  0.89554834, -4.252328  , ..., -3.5183883 ,\n","          2.076346  ,  2.4355876 ],\n","        ...,\n","        [ 1.5733832 , -0.7812666 , -3.7443368 , ..., -1.828633  ,\n","          0.32921764,  1.7987202 ],\n","        [ 3.0194285 ,  2.0560486 , -3.6404738 , ..., -2.1957102 ,\n","          3.150835  ,  2.6381435 ],\n","        [ 2.3509135 ,  0.07888149, -4.5634427 , ..., -1.6077464 ,\n","         -0.0573183 ,  2.009958  ]], dtype=float32),\n"," array([[ 2.6895049 ,  0.26972637, -1.8492647 , ..., -3.8140335 ,\n","          2.1177218 ,  2.526196  ],\n","        [ 1.7833078 ,  0.00873065, -5.2332926 , ..., -1.7525616 ,\n","         -2.6962817 ,  2.3390772 ],\n","        [ 2.4779594 ,  0.80492574, -4.43564   , ..., -3.1765945 ,\n","          3.0134487 ,  2.7113783 ],\n","        ...,\n","        [ 1.4198315 , -0.64762485, -3.776958  , ..., -1.8199574 ,\n","         -0.2034427 ,  2.4370813 ],\n","        [ 2.780403  ,  2.1151276 , -3.8020592 , ..., -2.4431942 ,\n","          3.0494657 ,  2.5879183 ],\n","        [ 2.3771398 ,  0.17081831, -3.5545852 , ..., -1.982633  ,\n","         -0.3157804 ,  2.4182806 ]], dtype=float32),\n"," array([[ 2.8235967 ,  0.44112566, -1.330617  , ..., -4.1427627 ,\n","          2.3605535 ,  2.405228  ],\n","        [ 1.5948689 , -0.39676347, -5.4312167 , ..., -1.7371391 ,\n","         -2.7527637 ,  2.0954156 ],\n","        [ 2.3369076 ,  0.92122996, -3.3947783 , ..., -3.783685  ,\n","          3.050911  ,  2.3718314 ],\n","        ...,\n","        [ 1.7609894 , -0.60736793, -4.210984  , ..., -1.3377184 ,\n","          0.03782983,  2.2063048 ],\n","        [ 2.5287693 ,  1.5789748 , -3.424512  , ..., -2.9056697 ,\n","          3.5599377 ,  2.7744796 ],\n","        [ 2.154482  ,  0.12568769, -3.2179391 , ..., -1.77831   ,\n","         -1.6189035 ,  2.0105193 ]], dtype=float32),\n"," array([[ 2.8013396 ,  0.43353888, -1.5575541 , ..., -3.2911708 ,\n","          2.7166998 ,  2.2021058 ],\n","        [ 1.8147146 ,  0.10664671, -5.278747  , ..., -2.1068206 ,\n","         -2.964353  ,  2.3790812 ],\n","        [ 2.509939  ,  0.6591157 , -4.8322988 , ..., -3.7833633 ,\n","          3.5224452 ,  2.6479979 ],\n","        ...,\n","        [ 1.726836  , -0.63026506, -4.403735  , ..., -1.4332482 ,\n","         -0.08453802,  2.6559014 ],\n","        [ 2.4932666 ,  1.2886096 , -4.3053846 , ..., -2.892618  ,\n","          3.7375245 ,  2.9670742 ],\n","        [ 2.2487023 , -0.1334288 , -4.694021  , ..., -2.0025775 ,\n","         -1.0209807 ,  2.3298826 ]], dtype=float32),\n"," array([[ 3.0332334 ,  0.31014982, -1.7405893 , ..., -4.0959897 ,\n","          2.7210143 ,  2.6309114 ],\n","        [ 1.9239984 , -0.12701887, -5.091317  , ..., -2.428308  ,\n","         -2.9899044 ,  2.3494062 ],\n","        [ 2.2904658 ,  0.7118155 , -4.5009346 , ..., -3.7010858 ,\n","          3.1441548 ,  2.4558895 ],\n","        ...,\n","        [ 1.7633356 , -0.6515487 , -3.958963  , ..., -1.6939629 ,\n","         -0.8844008 ,  2.0595012 ],\n","        [ 2.561701  ,  1.6283351 , -3.2732139 , ..., -2.4250503 ,\n","          3.233177  ,  2.891486  ],\n","        [ 2.1740294 , -0.03110471, -4.1821523 , ..., -2.379321  ,\n","         -0.6106037 ,  2.4704392 ]], dtype=float32),\n"," array([[ 2.9836059e+00,  4.8836246e-01, -1.4444849e+00, ...,\n","         -4.3021259e+00,  3.0791321e+00,  2.5806334e+00],\n","        [ 1.9159243e+00,  2.5672939e-02, -5.5604129e+00, ...,\n","         -2.1879957e+00, -3.0817246e+00,  2.6186860e+00],\n","        [ 2.5949304e+00,  7.3588669e-01, -4.1842351e+00, ...,\n","         -3.7180860e+00,  3.3907647e+00,  2.6132977e+00],\n","        ...,\n","        [ 1.7730703e+00, -7.1660745e-01, -4.0451298e+00, ...,\n","         -1.4466888e+00, -2.7978450e-01,  2.0171435e+00],\n","        [ 2.8728821e+00,  1.4406235e+00, -3.6221802e+00, ...,\n","         -2.2268448e+00,  2.2593331e+00,  2.5485733e+00],\n","        [ 2.2660956e+00, -9.1604167e-04, -4.0312061e+00, ...,\n","         -1.8790981e+00, -1.7195098e+00,  2.2321978e+00]], dtype=float32),\n"," array([[ 2.6330345 ,  0.36627933, -1.0524104 , ..., -4.1108313 ,\n","          3.3260808 ,  2.6060486 ],\n","        [ 1.6672678 , -0.14990923, -5.7948112 , ..., -1.9245125 ,\n","         -3.421963  ,  2.2009091 ],\n","        [ 2.4642432 ,  0.72592044, -4.1336794 , ..., -2.9745278 ,\n","          2.9030645 ,  2.320065  ],\n","        ...,\n","        [ 1.4474846 , -0.8101059 , -4.178406  , ..., -1.5448532 ,\n","         -0.8040441 ,  1.7410512 ],\n","        [ 2.7158735 ,  1.7802432 , -3.4755187 , ..., -2.5386913 ,\n","          3.0043454 ,  2.8831728 ],\n","        [ 2.1443026 , -0.14552173, -4.035122  , ..., -2.1688285 ,\n","         -1.5552309 ,  1.9457452 ]], dtype=float32)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["cased_pred_lst"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.816673Z","iopub.status.idle":"2023-03-16T06:15:52.817452Z","shell.execute_reply":"2023-03-16T06:15:52.817205Z","shell.execute_reply.started":"2023-03-16T06:15:52.81718Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[1., 2., 3.],\n","       [4., 5., 6.]])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["a=[[1,2,3],[4,5,6]]#(2,3)\n","#b=[[7,8,9],[10,11,12]]\n","a=np.array(a)\n","#b=np.array(b)\n","c=[]\n","c.append(a)\n","#c.append(b)\n","np.array(c).mean(0)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.818796Z","iopub.status.idle":"2023-03-16T06:15:52.819515Z","shell.execute_reply":"2023-03-16T06:15:52.819268Z","shell.execute_reply.started":"2023-03-16T06:15:52.819243Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[ 2.7984574 ,  0.44034234, -1.4480911 , ..., -3.8564491 ,\n","         2.7417254 ,  2.5384176 ],\n","       [ 1.8120759 , -0.12645762, -5.487586  , ..., -2.0084052 ,\n","        -2.954761  ,  2.2427335 ],\n","       [ 2.4518034 ,  0.80789244, -4.338448  , ..., -3.4247983 ,\n","         2.8845046 ,  2.434679  ],\n","       ...,\n","       [ 1.6572119 , -0.6744283 , -4.2349787 , ..., -1.5938172 ,\n","        -0.39036947,  2.1185052 ],\n","       [ 2.775621  ,  1.6504242 , -3.6823158 , ..., -2.5352695 ,\n","         3.153184  ,  2.7887468 ],\n","       [ 2.288085  ,  0.04518992, -3.9893498 , ..., -1.9433641 ,\n","        -1.1310546 ,  2.1625025 ]], dtype=float32)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["np.array(cased_pred_lst).mean(0)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.820873Z","iopub.status.idle":"2023-03-16T06:15:52.821609Z","shell.execute_reply":"2023-03-16T06:15:52.821391Z","shell.execute_reply.started":"2023-03-16T06:15:52.821364Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0.94259244, 0.6083406 , 0.1902955 , ..., 0.02070517, 0.9394443 ,\n","        0.92679155],\n","       [0.8596125 , 0.46842766, 0.00412077, ..., 0.11832326, 0.04951198,\n","        0.90402186],\n","       [0.9206932 , 0.6916602 , 0.01288849, ..., 0.03152938, 0.9470751 ,\n","        0.91943383],\n","       ...,\n","       [0.8398634 , 0.337506  , 0.01427344, ..., 0.16884752, 0.40362835,\n","        0.8926889 ],\n","       [0.9413441 , 0.83894837, 0.02454691, ..., 0.07342236, 0.95903397,\n","        0.94206464],\n","       [0.90788543, 0.5112956 , 0.01817529, ..., 0.12527874, 0.24396653,\n","        0.89683133]], dtype=float32)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["def sigmoid(x):\n","    return 1.0 / (1.0 + np.exp(-x))\n","cased_pred = np.array(cased_pred_lst).mean(0)\n","cased_pred = sigmoid(cased_pred)\n","cased_pred"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#21th PostProcessing"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.822919Z","iopub.status.idle":"2023-03-16T06:15:52.823636Z","shell.execute_reply":"2023-03-16T06:15:52.823403Z","shell.execute_reply.started":"2023-03-16T06:15:52.823379Z"},"trusted":true},"outputs":[],"source":["#####21th postprocessing############\n","def postProcessing(x):\n","\n","    x = np.where(x>=0.9241, 1.0, x)\n","    x = np.where(x<=0.0759, 0.0, x)\n","\n","    return x\n","\n","targets = ['question_conversational',\n","           'question_type_compare', \n","           'question_type_consequence', \n","           'question_type_definition', \n","           'question_type_entity', \n","           'question_type_choice']"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.825003Z","iopub.status.idle":"2023-03-16T06:15:52.825836Z","shell.execute_reply":"2023-03-16T06:15:52.825566Z","shell.execute_reply.started":"2023-03-16T06:15:52.825538Z"},"trusted":true},"outputs":[],"source":["sub[sub.columns[1:]] = cased_pred"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qa_id</th>\n","      <th>question_asker_intent_understanding</th>\n","      <th>question_body_critical</th>\n","      <th>question_conversational</th>\n","      <th>question_expect_short_answer</th>\n","      <th>question_fact_seeking</th>\n","      <th>question_has_commonly_accepted_answer</th>\n","      <th>question_interestingness_others</th>\n","      <th>question_interestingness_self</th>\n","      <th>question_multi_intent</th>\n","      <th>...</th>\n","      <th>question_well_written</th>\n","      <th>answer_helpful</th>\n","      <th>answer_level_of_information</th>\n","      <th>answer_plausible</th>\n","      <th>answer_relevance</th>\n","      <th>answer_satisfaction</th>\n","      <th>answer_type_instructions</th>\n","      <th>answer_type_procedure</th>\n","      <th>answer_type_reason_explanation</th>\n","      <th>answer_well_written</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0.942592</td>\n","      <td>0.608341</td>\n","      <td>0.190296</td>\n","      <td>0.394527</td>\n","      <td>0.653499</td>\n","      <td>0.488018</td>\n","      <td>0.678720</td>\n","      <td>0.661841</td>\n","      <td>0.806845</td>\n","      <td>...</td>\n","      <td>0.926952</td>\n","      <td>0.949924</td>\n","      <td>0.623096</td>\n","      <td>0.979302</td>\n","      <td>0.984692</td>\n","      <td>0.883128</td>\n","      <td>0.010401</td>\n","      <td>0.020705</td>\n","      <td>0.939444</td>\n","      <td>0.926792</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46</td>\n","      <td>0.859613</td>\n","      <td>0.468428</td>\n","      <td>0.004121</td>\n","      <td>0.806487</td>\n","      <td>0.759366</td>\n","      <td>0.950711</td>\n","      <td>0.550465</td>\n","      <td>0.434654</td>\n","      <td>0.107945</td>\n","      <td>...</td>\n","      <td>0.612518</td>\n","      <td>0.955891</td>\n","      <td>0.639856</td>\n","      <td>0.976430</td>\n","      <td>0.986246</td>\n","      <td>0.885631</td>\n","      <td>0.949764</td>\n","      <td>0.118323</td>\n","      <td>0.049512</td>\n","      <td>0.904022</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>0.920693</td>\n","      <td>0.691660</td>\n","      <td>0.012888</td>\n","      <td>0.766912</td>\n","      <td>0.928296</td>\n","      <td>0.949284</td>\n","      <td>0.610134</td>\n","      <td>0.523464</td>\n","      <td>0.176267</td>\n","      <td>...</td>\n","      <td>0.902476</td>\n","      <td>0.905701</td>\n","      <td>0.545887</td>\n","      <td>0.960385</td>\n","      <td>0.960636</td>\n","      <td>0.775189</td>\n","      <td>0.035798</td>\n","      <td>0.031529</td>\n","      <td>0.947075</td>\n","      <td>0.919434</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>132</td>\n","      <td>0.921804</td>\n","      <td>0.466582</td>\n","      <td>0.002555</td>\n","      <td>0.757888</td>\n","      <td>0.731844</td>\n","      <td>0.927062</td>\n","      <td>0.580946</td>\n","      <td>0.452688</td>\n","      <td>0.052629</td>\n","      <td>...</td>\n","      <td>0.733163</td>\n","      <td>0.965430</td>\n","      <td>0.682734</td>\n","      <td>0.982170</td>\n","      <td>0.989428</td>\n","      <td>0.907438</td>\n","      <td>0.872733</td>\n","      <td>0.138131</td>\n","      <td>0.785100</td>\n","      <td>0.904953</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>200</td>\n","      <td>0.914812</td>\n","      <td>0.473769</td>\n","      <td>0.014146</td>\n","      <td>0.831799</td>\n","      <td>0.810358</td>\n","      <td>0.939746</td>\n","      <td>0.625637</td>\n","      <td>0.571752</td>\n","      <td>0.145085</td>\n","      <td>...</td>\n","      <td>0.599233</td>\n","      <td>0.902090</td>\n","      <td>0.648120</td>\n","      <td>0.957160</td>\n","      <td>0.957328</td>\n","      <td>0.809481</td>\n","      <td>0.206990</td>\n","      <td>0.137857</td>\n","      <td>0.643624</td>\n","      <td>0.907880</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>9569</td>\n","      <td>0.917615</td>\n","      <td>0.613147</td>\n","      <td>0.002426</td>\n","      <td>0.799397</td>\n","      <td>0.813021</td>\n","      <td>0.951803</td>\n","      <td>0.573499</td>\n","      <td>0.478682</td>\n","      <td>0.013501</td>\n","      <td>...</td>\n","      <td>0.748576</td>\n","      <td>0.969766</td>\n","      <td>0.707017</td>\n","      <td>0.982367</td>\n","      <td>0.992383</td>\n","      <td>0.924765</td>\n","      <td>0.939419</td>\n","      <td>0.119204</td>\n","      <td>0.068360</td>\n","      <td>0.911224</td>\n","    </tr>\n","    <tr>\n","      <th>472</th>\n","      <td>9590</td>\n","      <td>0.873975</td>\n","      <td>0.413324</td>\n","      <td>0.008971</td>\n","      <td>0.734115</td>\n","      <td>0.737940</td>\n","      <td>0.863177</td>\n","      <td>0.546444</td>\n","      <td>0.442354</td>\n","      <td>0.035308</td>\n","      <td>...</td>\n","      <td>0.626073</td>\n","      <td>0.933129</td>\n","      <td>0.654583</td>\n","      <td>0.955060</td>\n","      <td>0.973723</td>\n","      <td>0.867835</td>\n","      <td>0.721704</td>\n","      <td>0.156412</td>\n","      <td>0.281047</td>\n","      <td>0.895195</td>\n","    </tr>\n","    <tr>\n","      <th>473</th>\n","      <td>9597</td>\n","      <td>0.839863</td>\n","      <td>0.337506</td>\n","      <td>0.014273</td>\n","      <td>0.646739</td>\n","      <td>0.756892</td>\n","      <td>0.870595</td>\n","      <td>0.530085</td>\n","      <td>0.414903</td>\n","      <td>0.564897</td>\n","      <td>...</td>\n","      <td>0.686889</td>\n","      <td>0.897195</td>\n","      <td>0.589416</td>\n","      <td>0.946907</td>\n","      <td>0.955668</td>\n","      <td>0.787406</td>\n","      <td>0.536958</td>\n","      <td>0.168848</td>\n","      <td>0.403628</td>\n","      <td>0.892689</td>\n","    </tr>\n","    <tr>\n","      <th>474</th>\n","      <td>9623</td>\n","      <td>0.941344</td>\n","      <td>0.838948</td>\n","      <td>0.024547</td>\n","      <td>0.952103</td>\n","      <td>0.899094</td>\n","      <td>0.976213</td>\n","      <td>0.647700</td>\n","      <td>0.551966</td>\n","      <td>0.036413</td>\n","      <td>...</td>\n","      <td>0.901255</td>\n","      <td>0.977404</td>\n","      <td>0.751842</td>\n","      <td>0.987522</td>\n","      <td>0.992603</td>\n","      <td>0.943564</td>\n","      <td>0.066447</td>\n","      <td>0.073422</td>\n","      <td>0.959034</td>\n","      <td>0.942065</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>9640</td>\n","      <td>0.907885</td>\n","      <td>0.511296</td>\n","      <td>0.018175</td>\n","      <td>0.856991</td>\n","      <td>0.746297</td>\n","      <td>0.869712</td>\n","      <td>0.624243</td>\n","      <td>0.572271</td>\n","      <td>0.065945</td>\n","      <td>...</td>\n","      <td>0.744468</td>\n","      <td>0.948611</td>\n","      <td>0.647664</td>\n","      <td>0.973055</td>\n","      <td>0.980959</td>\n","      <td>0.886897</td>\n","      <td>0.664759</td>\n","      <td>0.125279</td>\n","      <td>0.243967</td>\n","      <td>0.896831</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>476 rows × 31 columns</p>\n","</div>"],"text/plain":["     qa_id  question_asker_intent_understanding  question_body_critical  \\\n","0       39                             0.942592                0.608341   \n","1       46                             0.859613                0.468428   \n","2       70                             0.920693                0.691660   \n","3      132                             0.921804                0.466582   \n","4      200                             0.914812                0.473769   \n","..     ...                                  ...                     ...   \n","471   9569                             0.917615                0.613147   \n","472   9590                             0.873975                0.413324   \n","473   9597                             0.839863                0.337506   \n","474   9623                             0.941344                0.838948   \n","475   9640                             0.907885                0.511296   \n","\n","     question_conversational  question_expect_short_answer  \\\n","0                   0.190296                      0.394527   \n","1                   0.004121                      0.806487   \n","2                   0.012888                      0.766912   \n","3                   0.002555                      0.757888   \n","4                   0.014146                      0.831799   \n","..                       ...                           ...   \n","471                 0.002426                      0.799397   \n","472                 0.008971                      0.734115   \n","473                 0.014273                      0.646739   \n","474                 0.024547                      0.952103   \n","475                 0.018175                      0.856991   \n","\n","     question_fact_seeking  question_has_commonly_accepted_answer  \\\n","0                 0.653499                               0.488018   \n","1                 0.759366                               0.950711   \n","2                 0.928296                               0.949284   \n","3                 0.731844                               0.927062   \n","4                 0.810358                               0.939746   \n","..                     ...                                    ...   \n","471               0.813021                               0.951803   \n","472               0.737940                               0.863177   \n","473               0.756892                               0.870595   \n","474               0.899094                               0.976213   \n","475               0.746297                               0.869712   \n","\n","     question_interestingness_others  question_interestingness_self  \\\n","0                           0.678720                       0.661841   \n","1                           0.550465                       0.434654   \n","2                           0.610134                       0.523464   \n","3                           0.580946                       0.452688   \n","4                           0.625637                       0.571752   \n","..                               ...                            ...   \n","471                         0.573499                       0.478682   \n","472                         0.546444                       0.442354   \n","473                         0.530085                       0.414903   \n","474                         0.647700                       0.551966   \n","475                         0.624243                       0.572271   \n","\n","     question_multi_intent  ...  question_well_written  answer_helpful  \\\n","0                 0.806845  ...               0.926952        0.949924   \n","1                 0.107945  ...               0.612518        0.955891   \n","2                 0.176267  ...               0.902476        0.905701   \n","3                 0.052629  ...               0.733163        0.965430   \n","4                 0.145085  ...               0.599233        0.902090   \n","..                     ...  ...                    ...             ...   \n","471               0.013501  ...               0.748576        0.969766   \n","472               0.035308  ...               0.626073        0.933129   \n","473               0.564897  ...               0.686889        0.897195   \n","474               0.036413  ...               0.901255        0.977404   \n","475               0.065945  ...               0.744468        0.948611   \n","\n","     answer_level_of_information  answer_plausible  answer_relevance  \\\n","0                       0.623096          0.979302          0.984692   \n","1                       0.639856          0.976430          0.986246   \n","2                       0.545887          0.960385          0.960636   \n","3                       0.682734          0.982170          0.989428   \n","4                       0.648120          0.957160          0.957328   \n","..                           ...               ...               ...   \n","471                     0.707017          0.982367          0.992383   \n","472                     0.654583          0.955060          0.973723   \n","473                     0.589416          0.946907          0.955668   \n","474                     0.751842          0.987522          0.992603   \n","475                     0.647664          0.973055          0.980959   \n","\n","     answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n","0               0.883128                  0.010401               0.020705   \n","1               0.885631                  0.949764               0.118323   \n","2               0.775189                  0.035798               0.031529   \n","3               0.907438                  0.872733               0.138131   \n","4               0.809481                  0.206990               0.137857   \n","..                   ...                       ...                    ...   \n","471             0.924765                  0.939419               0.119204   \n","472             0.867835                  0.721704               0.156412   \n","473             0.787406                  0.536958               0.168848   \n","474             0.943564                  0.066447               0.073422   \n","475             0.886897                  0.664759               0.125279   \n","\n","     answer_type_reason_explanation  answer_well_written  \n","0                          0.939444             0.926792  \n","1                          0.049512             0.904022  \n","2                          0.947075             0.919434  \n","3                          0.785100             0.904953  \n","4                          0.643624             0.907880  \n","..                              ...                  ...  \n","471                        0.068360             0.911224  \n","472                        0.281047             0.895195  \n","473                        0.403628             0.892689  \n","474                        0.959034             0.942065  \n","475                        0.243967             0.896831  \n","\n","[476 rows x 31 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["sub"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_conversational</th>\n","      <th>question_type_compare</th>\n","      <th>question_type_consequence</th>\n","      <th>question_type_definition</th>\n","      <th>question_type_entity</th>\n","      <th>question_type_choice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.190296</td>\n","      <td>0.017910</td>\n","      <td>0.100128</td>\n","      <td>0.005460</td>\n","      <td>0.011716</td>\n","      <td>0.694558</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.004121</td>\n","      <td>0.002647</td>\n","      <td>0.001281</td>\n","      <td>0.001035</td>\n","      <td>0.004834</td>\n","      <td>0.531083</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.012888</td>\n","      <td>0.006700</td>\n","      <td>0.023339</td>\n","      <td>0.002856</td>\n","      <td>0.007018</td>\n","      <td>0.828513</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.002555</td>\n","      <td>0.000512</td>\n","      <td>0.000572</td>\n","      <td>0.000250</td>\n","      <td>0.002771</td>\n","      <td>0.011929</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.014146</td>\n","      <td>0.003843</td>\n","      <td>0.017026</td>\n","      <td>0.001848</td>\n","      <td>0.018479</td>\n","      <td>0.521110</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>0.002426</td>\n","      <td>0.000840</td>\n","      <td>0.000116</td>\n","      <td>0.000487</td>\n","      <td>0.001193</td>\n","      <td>0.008016</td>\n","    </tr>\n","    <tr>\n","      <th>472</th>\n","      <td>0.008971</td>\n","      <td>0.004834</td>\n","      <td>0.000598</td>\n","      <td>0.001323</td>\n","      <td>0.019019</td>\n","      <td>0.026801</td>\n","    </tr>\n","    <tr>\n","      <th>473</th>\n","      <td>0.014273</td>\n","      <td>0.028365</td>\n","      <td>0.007982</td>\n","      <td>0.004151</td>\n","      <td>0.013865</td>\n","      <td>0.693887</td>\n","    </tr>\n","    <tr>\n","      <th>474</th>\n","      <td>0.024547</td>\n","      <td>0.003466</td>\n","      <td>0.023522</td>\n","      <td>0.004807</td>\n","      <td>0.007954</td>\n","      <td>0.948098</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>0.018175</td>\n","      <td>0.002950</td>\n","      <td>0.002381</td>\n","      <td>0.002554</td>\n","      <td>0.019840</td>\n","      <td>0.628798</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>476 rows × 6 columns</p>\n","</div>"],"text/plain":["     question_conversational  question_type_compare  \\\n","0                   0.190296               0.017910   \n","1                   0.004121               0.002647   \n","2                   0.012888               0.006700   \n","3                   0.002555               0.000512   \n","4                   0.014146               0.003843   \n","..                       ...                    ...   \n","471                 0.002426               0.000840   \n","472                 0.008971               0.004834   \n","473                 0.014273               0.028365   \n","474                 0.024547               0.003466   \n","475                 0.018175               0.002950   \n","\n","     question_type_consequence  question_type_definition  \\\n","0                     0.100128                  0.005460   \n","1                     0.001281                  0.001035   \n","2                     0.023339                  0.002856   \n","3                     0.000572                  0.000250   \n","4                     0.017026                  0.001848   \n","..                         ...                       ...   \n","471                   0.000116                  0.000487   \n","472                   0.000598                  0.001323   \n","473                   0.007982                  0.004151   \n","474                   0.023522                  0.004807   \n","475                   0.002381                  0.002554   \n","\n","     question_type_entity  question_type_choice  \n","0                0.011716              0.694558  \n","1                0.004834              0.531083  \n","2                0.007018              0.828513  \n","3                0.002771              0.011929  \n","4                0.018479              0.521110  \n","..                    ...                   ...  \n","471              0.001193              0.008016  \n","472              0.019019              0.026801  \n","473              0.013865              0.693887  \n","474              0.007954              0.948098  \n","475              0.019840              0.628798  \n","\n","[476 rows x 6 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["sub.loc[:, targets]"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.827138Z","iopub.status.idle":"2023-03-16T06:15:52.827996Z","shell.execute_reply":"2023-03-16T06:15:52.827747Z","shell.execute_reply.started":"2023-03-16T06:15:52.827717Z"},"trusted":true},"outputs":[],"source":["sub.loc[:, targets] = postProcessing(sub.loc[:, targets].values)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["array(['qa_id', 'question_asker_intent_understanding',\n","       'question_body_critical', 'question_conversational',\n","       'question_expect_short_answer', 'question_fact_seeking',\n","       'question_has_commonly_accepted_answer',\n","       'question_interestingness_others', 'question_interestingness_self',\n","       'question_multi_intent', 'question_not_really_a_question',\n","       'question_opinion_seeking', 'question_type_choice',\n","       'question_type_compare', 'question_type_consequence',\n","       'question_type_definition', 'question_type_entity',\n","       'question_type_instructions', 'question_type_procedure',\n","       'question_type_reason_explanation', 'question_type_spelling',\n","       'question_well_written', 'answer_helpful',\n","       'answer_level_of_information', 'answer_plausible',\n","       'answer_relevance', 'answer_satisfaction',\n","       'answer_type_instructions', 'answer_type_procedure',\n","       'answer_type_reason_explanation', 'answer_well_written'],\n","      dtype=object)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["sub_columns=sub.columns.values"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_conversational</th>\n","      <th>question_type_compare</th>\n","      <th>question_type_consequence</th>\n","      <th>question_type_definition</th>\n","      <th>question_type_entity</th>\n","      <th>question_type_choice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.190296</td>\n","      <td>0.0</td>\n","      <td>0.100128</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.694558</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.531083</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.828513</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.521110</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>472</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>473</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.693887</td>\n","    </tr>\n","    <tr>\n","      <th>474</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.628798</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>476 rows × 6 columns</p>\n","</div>"],"text/plain":["     question_conversational  question_type_compare  \\\n","0                   0.190296                    0.0   \n","1                   0.000000                    0.0   \n","2                   0.000000                    0.0   \n","3                   0.000000                    0.0   \n","4                   0.000000                    0.0   \n","..                       ...                    ...   \n","471                 0.000000                    0.0   \n","472                 0.000000                    0.0   \n","473                 0.000000                    0.0   \n","474                 0.000000                    0.0   \n","475                 0.000000                    0.0   \n","\n","     question_type_consequence  question_type_definition  \\\n","0                     0.100128                       0.0   \n","1                     0.000000                       0.0   \n","2                     0.000000                       0.0   \n","3                     0.000000                       0.0   \n","4                     0.000000                       0.0   \n","..                         ...                       ...   \n","471                   0.000000                       0.0   \n","472                   0.000000                       0.0   \n","473                   0.000000                       0.0   \n","474                   0.000000                       0.0   \n","475                   0.000000                       0.0   \n","\n","     question_type_entity  question_type_choice  \n","0                     0.0              0.694558  \n","1                     0.0              0.531083  \n","2                     0.0              0.828513  \n","3                     0.0              0.000000  \n","4                     0.0              0.521110  \n","..                    ...                   ...  \n","471                   0.0              0.000000  \n","472                   0.0              0.000000  \n","473                   0.0              0.693887  \n","474                   0.0              1.000000  \n","475                   0.0              0.628798  \n","\n","[476 rows x 6 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["sub.loc[:, targets]"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_asker_intent_understanding</th>\n","      <th>question_body_critical</th>\n","      <th>question_conversational</th>\n","      <th>question_expect_short_answer</th>\n","      <th>question_fact_seeking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.942592</td>\n","      <td>0.608341</td>\n","      <td>0.190296</td>\n","      <td>0.394527</td>\n","      <td>0.653499</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.859613</td>\n","      <td>0.468428</td>\n","      <td>0.000000</td>\n","      <td>0.806487</td>\n","      <td>0.759366</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.920693</td>\n","      <td>0.691660</td>\n","      <td>0.000000</td>\n","      <td>0.766912</td>\n","      <td>0.928296</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.921804</td>\n","      <td>0.466582</td>\n","      <td>0.000000</td>\n","      <td>0.757888</td>\n","      <td>0.731844</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.914812</td>\n","      <td>0.473769</td>\n","      <td>0.000000</td>\n","      <td>0.831799</td>\n","      <td>0.810358</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>0.917615</td>\n","      <td>0.613147</td>\n","      <td>0.000000</td>\n","      <td>0.799397</td>\n","      <td>0.813021</td>\n","    </tr>\n","    <tr>\n","      <th>472</th>\n","      <td>0.873975</td>\n","      <td>0.413324</td>\n","      <td>0.000000</td>\n","      <td>0.734115</td>\n","      <td>0.737940</td>\n","    </tr>\n","    <tr>\n","      <th>473</th>\n","      <td>0.839863</td>\n","      <td>0.337506</td>\n","      <td>0.000000</td>\n","      <td>0.646739</td>\n","      <td>0.756892</td>\n","    </tr>\n","    <tr>\n","      <th>474</th>\n","      <td>0.941344</td>\n","      <td>0.838948</td>\n","      <td>0.000000</td>\n","      <td>0.952103</td>\n","      <td>0.899094</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>0.907885</td>\n","      <td>0.511296</td>\n","      <td>0.000000</td>\n","      <td>0.856991</td>\n","      <td>0.746297</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>476 rows × 5 columns</p>\n","</div>"],"text/plain":["     question_asker_intent_understanding  question_body_critical  \\\n","0                               0.942592                0.608341   \n","1                               0.859613                0.468428   \n","2                               0.920693                0.691660   \n","3                               0.921804                0.466582   \n","4                               0.914812                0.473769   \n","..                                   ...                     ...   \n","471                             0.917615                0.613147   \n","472                             0.873975                0.413324   \n","473                             0.839863                0.337506   \n","474                             0.941344                0.838948   \n","475                             0.907885                0.511296   \n","\n","     question_conversational  question_expect_short_answer  \\\n","0                   0.190296                      0.394527   \n","1                   0.000000                      0.806487   \n","2                   0.000000                      0.766912   \n","3                   0.000000                      0.757888   \n","4                   0.000000                      0.831799   \n","..                       ...                           ...   \n","471                 0.000000                      0.799397   \n","472                 0.000000                      0.734115   \n","473                 0.000000                      0.646739   \n","474                 0.000000                      0.952103   \n","475                 0.000000                      0.856991   \n","\n","     question_fact_seeking  \n","0                 0.653499  \n","1                 0.759366  \n","2                 0.928296  \n","3                 0.731844  \n","4                 0.810358  \n","..                     ...  \n","471               0.813021  \n","472               0.737940  \n","473               0.756892  \n","474               0.899094  \n","475               0.746297  \n","\n","[476 rows x 5 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["sub.loc[:, sub_columns[1:6]]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2023-03-16T06:15:52.833435Z","iopub.status.idle":"2023-03-16T06:15:52.834132Z","shell.execute_reply":"2023-03-16T06:15:52.833903Z","shell.execute_reply.started":"2023-03-16T06:15:52.833878Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qa_id</th>\n","      <th>question_asker_intent_understanding</th>\n","      <th>question_body_critical</th>\n","      <th>question_conversational</th>\n","      <th>question_expect_short_answer</th>\n","      <th>question_fact_seeking</th>\n","      <th>question_has_commonly_accepted_answer</th>\n","      <th>question_interestingness_others</th>\n","      <th>question_interestingness_self</th>\n","      <th>question_multi_intent</th>\n","      <th>...</th>\n","      <th>question_well_written</th>\n","      <th>answer_helpful</th>\n","      <th>answer_level_of_information</th>\n","      <th>answer_plausible</th>\n","      <th>answer_relevance</th>\n","      <th>answer_satisfaction</th>\n","      <th>answer_type_instructions</th>\n","      <th>answer_type_procedure</th>\n","      <th>answer_type_reason_explanation</th>\n","      <th>answer_well_written</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0.942592</td>\n","      <td>0.608341</td>\n","      <td>0.190296</td>\n","      <td>0.394527</td>\n","      <td>0.653499</td>\n","      <td>0.488018</td>\n","      <td>0.678720</td>\n","      <td>0.661841</td>\n","      <td>0.806845</td>\n","      <td>...</td>\n","      <td>0.926952</td>\n","      <td>0.949924</td>\n","      <td>0.623096</td>\n","      <td>0.979302</td>\n","      <td>0.984692</td>\n","      <td>0.883128</td>\n","      <td>0.010401</td>\n","      <td>0.020705</td>\n","      <td>0.939444</td>\n","      <td>0.926792</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46</td>\n","      <td>0.859613</td>\n","      <td>0.468428</td>\n","      <td>0.000000</td>\n","      <td>0.806487</td>\n","      <td>0.759366</td>\n","      <td>0.950711</td>\n","      <td>0.550465</td>\n","      <td>0.434654</td>\n","      <td>0.107945</td>\n","      <td>...</td>\n","      <td>0.612518</td>\n","      <td>0.955891</td>\n","      <td>0.639856</td>\n","      <td>0.976430</td>\n","      <td>0.986246</td>\n","      <td>0.885631</td>\n","      <td>0.949764</td>\n","      <td>0.118323</td>\n","      <td>0.049512</td>\n","      <td>0.904022</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>0.920693</td>\n","      <td>0.691660</td>\n","      <td>0.000000</td>\n","      <td>0.766912</td>\n","      <td>0.928296</td>\n","      <td>0.949284</td>\n","      <td>0.610134</td>\n","      <td>0.523464</td>\n","      <td>0.176267</td>\n","      <td>...</td>\n","      <td>0.902476</td>\n","      <td>0.905701</td>\n","      <td>0.545887</td>\n","      <td>0.960385</td>\n","      <td>0.960636</td>\n","      <td>0.775189</td>\n","      <td>0.035798</td>\n","      <td>0.031529</td>\n","      <td>0.947075</td>\n","      <td>0.919434</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>132</td>\n","      <td>0.921804</td>\n","      <td>0.466582</td>\n","      <td>0.000000</td>\n","      <td>0.757888</td>\n","      <td>0.731844</td>\n","      <td>0.927062</td>\n","      <td>0.580946</td>\n","      <td>0.452688</td>\n","      <td>0.052629</td>\n","      <td>...</td>\n","      <td>0.733163</td>\n","      <td>0.965430</td>\n","      <td>0.682734</td>\n","      <td>0.982170</td>\n","      <td>0.989428</td>\n","      <td>0.907438</td>\n","      <td>0.872733</td>\n","      <td>0.138131</td>\n","      <td>0.785100</td>\n","      <td>0.904953</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>200</td>\n","      <td>0.914812</td>\n","      <td>0.473769</td>\n","      <td>0.000000</td>\n","      <td>0.831799</td>\n","      <td>0.810358</td>\n","      <td>0.939746</td>\n","      <td>0.625637</td>\n","      <td>0.571752</td>\n","      <td>0.145085</td>\n","      <td>...</td>\n","      <td>0.599233</td>\n","      <td>0.902090</td>\n","      <td>0.648120</td>\n","      <td>0.957160</td>\n","      <td>0.957328</td>\n","      <td>0.809481</td>\n","      <td>0.206990</td>\n","      <td>0.137857</td>\n","      <td>0.643624</td>\n","      <td>0.907880</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>"],"text/plain":["   qa_id  question_asker_intent_understanding  question_body_critical  \\\n","0     39                             0.942592                0.608341   \n","1     46                             0.859613                0.468428   \n","2     70                             0.920693                0.691660   \n","3    132                             0.921804                0.466582   \n","4    200                             0.914812                0.473769   \n","\n","   question_conversational  question_expect_short_answer  \\\n","0                 0.190296                      0.394527   \n","1                 0.000000                      0.806487   \n","2                 0.000000                      0.766912   \n","3                 0.000000                      0.757888   \n","4                 0.000000                      0.831799   \n","\n","   question_fact_seeking  question_has_commonly_accepted_answer  \\\n","0               0.653499                               0.488018   \n","1               0.759366                               0.950711   \n","2               0.928296                               0.949284   \n","3               0.731844                               0.927062   \n","4               0.810358                               0.939746   \n","\n","   question_interestingness_others  question_interestingness_self  \\\n","0                         0.678720                       0.661841   \n","1                         0.550465                       0.434654   \n","2                         0.610134                       0.523464   \n","3                         0.580946                       0.452688   \n","4                         0.625637                       0.571752   \n","\n","   question_multi_intent  ...  question_well_written  answer_helpful  \\\n","0               0.806845  ...               0.926952        0.949924   \n","1               0.107945  ...               0.612518        0.955891   \n","2               0.176267  ...               0.902476        0.905701   \n","3               0.052629  ...               0.733163        0.965430   \n","4               0.145085  ...               0.599233        0.902090   \n","\n","   answer_level_of_information  answer_plausible  answer_relevance  \\\n","0                     0.623096          0.979302          0.984692   \n","1                     0.639856          0.976430          0.986246   \n","2                     0.545887          0.960385          0.960636   \n","3                     0.682734          0.982170          0.989428   \n","4                     0.648120          0.957160          0.957328   \n","\n","   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n","0             0.883128                  0.010401               0.020705   \n","1             0.885631                  0.949764               0.118323   \n","2             0.775189                  0.035798               0.031529   \n","3             0.907438                  0.872733               0.138131   \n","4             0.809481                  0.206990               0.137857   \n","\n","   answer_type_reason_explanation  answer_well_written  \n","0                        0.939444             0.926792  \n","1                        0.049512             0.904022  \n","2                        0.947075             0.919434  \n","3                        0.785100             0.904953  \n","4                        0.643624             0.907880  \n","\n","[5 rows x 31 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#sub[sub.columns[1:]] = cased_pred\n","sub.to_csv(\"submission.csv\", index=False)\n","sub.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"}},"nbformat":4,"nbformat_minor":4}
