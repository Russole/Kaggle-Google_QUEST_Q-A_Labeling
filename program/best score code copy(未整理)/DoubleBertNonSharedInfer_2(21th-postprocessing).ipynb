{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3815da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:24.606031Z",
     "iopub.status.busy": "2023-03-16T15:40:24.605133Z",
     "iopub.status.idle": "2023-03-16T15:40:36.375507Z",
     "shell.execute_reply": "2023-03-16T15:40:36.374433Z"
    },
    "papermill": {
     "duration": 11.780304,
     "end_time": "2023-03-16T15:40:36.378315",
     "exception": false,
     "start_time": "2023-03-16T15:40:24.598011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "#from transformers import *\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957cad2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:36.390462Z",
     "iopub.status.busy": "2023-03-16T15:40:36.389431Z",
     "iopub.status.idle": "2023-03-16T15:40:36.841398Z",
     "shell.execute_reply": "2023-03-16T15:40:36.840254Z"
    },
    "papermill": {
     "duration": 0.460795,
     "end_time": "2023-03-16T15:40:36.844272",
     "exception": false,
     "start_time": "2023-03-16T15:40:36.383477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv').fillna(' ')\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv').fillna(' ')\n",
    "sub = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e93c06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:36.857850Z",
     "iopub.status.busy": "2023-03-16T15:40:36.856014Z",
     "iopub.status.idle": "2023-03-16T15:40:36.864843Z",
     "shell.execute_reply": "2023-03-16T15:40:36.863857Z"
    },
    "papermill": {
     "duration": 0.017399,
     "end_time": "2023-03-16T15:40:36.867192",
     "exception": false,
     "start_time": "2023-03-16T15:40:36.849793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n",
       "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
       "       'url', 'category', 'host', 'question_asker_intent_understanding',\n",
       "       'question_body_critical', 'question_conversational',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca160bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:36.879708Z",
     "iopub.status.busy": "2023-03-16T15:40:36.879402Z",
     "iopub.status.idle": "2023-03-16T15:40:36.900212Z",
     "shell.execute_reply": "2023-03-16T15:40:36.899345Z"
    },
    "papermill": {
     "duration": 0.029871,
     "end_time": "2023-03-16T15:40:36.902417",
     "exception": false,
     "start_time": "2023-03-16T15:40:36.872546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False\n",
    "                current_segment_id = 1#新增 \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=512-1, \n",
    "                t_max_len=70-1, q_max_len=219, a_max_len=219):#???\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "\n",
    "        t = t[:t_new_len]\n",
    "        q = norm_token_length(q, q_new_len)\n",
    "        a = norm_token_length(a, a_new_len)\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def norm_token_length(tokens, l):\n",
    "    if len(tokens) > l:\n",
    "        head = l//2\n",
    "        tail = l - head\n",
    "        return tokens[:head] + tokens[-tail:]\n",
    "    else:\n",
    "        return tokens[:l]\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, cate, max_sequence_length=512):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    #stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    stoken_1 = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n",
    "    stoken_2 = [\"[CLS]\"] + [cate]+title + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "    input_ids = _get_ids(stoken_1, tokenizer, max_sequence_length)\n",
    "    input_ids_2 = _get_ids(stoken_2, tokenizer, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken_1, max_sequence_length)\n",
    "    input_segments_2 = _get_segments(stoken_2, max_sequence_length)\n",
    "    \n",
    "    #return [input_ids, input_segments]\n",
    "    return input_ids, input_segments,input_ids_2,input_segments_2\n",
    "\n",
    "def convert_row(row,pretrained_weights):\n",
    "    #c = f\"[{row['category'].lower()}]\"\n",
    "\n",
    "    if pretrained_weights == \"bert-base-uncased\":\n",
    "        c = f\"[{row['category'].lower()}]\"#type:str\n",
    "    elif pretrained_weights == \"bert-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    elif pretrained_weights == \"xlnet-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    t, q, a = title = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]#type:str\n",
    "\n",
    "\n",
    "    t, q, a = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]\n",
    "    t, q, a = _trim_input(t, q, a)\n",
    "    #ids, segments = _convert_to_bert_inputs(t, q, a, c)\n",
    "    ids, segments, ids2, segments2 = _convert_to_bert_inputs(t, q, a, c)\n",
    "    #total_input=[np.array([[ids, segments]]),np.array([[ids2, segments2]])]\n",
    "    # total_input=[]\n",
    "    # print(np.array([[ids, segments]]).shape)\n",
    "    # total_input.append(np.array([[ids, segments]]))\n",
    "    # total_input.append(np.array([[ids2, segments2]]))\n",
    "    # return total_input\n",
    "    return np.array([[ids, segments, ids2, segments2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1cdbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:36.913904Z",
     "iopub.status.busy": "2023-03-16T15:40:36.913624Z",
     "iopub.status.idle": "2023-03-16T15:40:36.994545Z",
     "shell.execute_reply": "2023-03-16T15:40:36.993625Z"
    },
    "papermill": {
     "duration": 0.089282,
     "end_time": "2023-03-16T15:40:36.996743",
     "exception": false,
     "start_time": "2023-03-16T15:40:36.907461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model=\"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/token-model-config/token_model_config/tokenizer/\")\n",
    "#tokenizer.add_tokens(\"./bert_based_tokenizer/added_tokens.json\")\n",
    "#tokenizer.add_tokens(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d021c53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:37.009439Z",
     "iopub.status.busy": "2023-03-16T15:40:37.007754Z",
     "iopub.status.idle": "2023-03-16T15:40:37.014601Z",
     "shell.execute_reply": "2023-03-16T15:40:37.013641Z"
    },
    "papermill": {
     "duration": 0.014917,
     "end_time": "2023-03-16T15:40:37.016746",
     "exception": false,
     "start_time": "2023-03-16T15:40:37.001829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f641746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:37.028091Z",
     "iopub.status.busy": "2023-03-16T15:40:37.027770Z",
     "iopub.status.idle": "2023-03-16T15:40:37.045394Z",
     "shell.execute_reply": "2023-03-16T15:40:37.044430Z"
    },
    "papermill": {
     "duration": 0.025803,
     "end_time": "2023-03-16T15:40:37.047547",
     "exception": false,
     "start_time": "2023-03-16T15:40:37.021744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(data,data2, targets,targets2):\n",
    "    \n",
    "    # mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n",
    "    # bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])#??\n",
    "    mse = nn.MSELoss(reduction=\"none\")(data[:,:].sigmoid(), targets[:,:])\n",
    "    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:], targets[:,:])#??\n",
    "    \n",
    "    mse2 = nn.MSELoss(reduction=\"none\")(data2[:,:].sigmoid(), targets2[:,:])\n",
    "    bce2 = nn.BCEWithLogitsLoss(reduction='none')(data2[:,:], targets2[:,:])#??\n",
    "    #w =  targets[:,30:]\n",
    "    #loss = (mse*w).sum() + bce.sum()\n",
    "    loss = (mse).sum()+ bce.sum()+mse2.sum()+bce2.sum()\n",
    "    return loss\n",
    "\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, config_path=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(config_path) \n",
    "        \n",
    "        self.config.Q_labels = 21\n",
    "        self.config.A_labels = 9\n",
    "        self.config.output_hidden_states = True\n",
    "        self.n_use_layer = 4 #原本\n",
    "        #self.n_use_layer = 2\n",
    "        self.double_bert= 1\n",
    "        self.n_labels = self.config.num_labels\n",
    "        #self.config.save_pretrained(\"bert_based_config\")\n",
    "        #self.config.save_pretrained(output_dir+\"config\")\n",
    "        #self.bert = BertModel(config)\n",
    "        self.bert=AutoModel.from_config(self.config)\n",
    "        self.bert2=AutoModel.from_config(self.config)\n",
    "        #self.bert.save_pretrained('bert_based_model')\n",
    "        #self.bert.save_pretrained(output_dir+\"model\")\n",
    "        # self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        # self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        # self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n",
    "\n",
    "        self.dense1 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dense2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.double_bert*self.config.hidden_size*self.n_use_layer)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.Q_labels)\n",
    "        self.classifier2 = nn.Linear(self.double_bert*self.config.hidden_size*self.n_use_layer, self.config.A_labels)\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None\n",
    "                ,input_ids2=None, attention_mask2=None, token_type_ids2=None,position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "\n",
    "        # outputs = self.bert(input_ids,\n",
    "        #                     attention_mask=attention_mask,\n",
    "        #                     token_type_ids=token_type_ids,\n",
    "        #                     position_ids=position_ids,\n",
    "        #                     head_mask=head_mask,\n",
    "        #                     inputs_embeds=inputs_embeds)\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                            )\n",
    "        outputs2 = self.bert2(input_ids2,\n",
    "                            attention_mask=attention_mask2,\n",
    "                            token_type_ids=token_type_ids2\n",
    "                            )\n",
    "        \n",
    "        #print(outputs[2][-1].shape)\n",
    "        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後4個layer的cls output concat在一起，把4個(8,768) concat，變成(8,3072) #原本\n",
    "        pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        #pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#把倒數最後2個layer的cls output concat在一起,把2個(8,768) concat，變成(8,1536)\n",
    "        #pooled_output2 = torch.cat([outputs2[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)#同上\n",
    "        #double_pooled_output=torch.cat([pooled_output,pooled_output],dim=1)#(8,3072)\n",
    "        \n",
    "        pooled_output = self.dense1(pooled_output)\n",
    "        pooled_output = self.dense2(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        pooled_output2 = self.dense1(pooled_output2)\n",
    "        pooled_output2 = self.dense2(pooled_output2)\n",
    "        pooled_output2 = self.dropout(pooled_output2)\n",
    "        logits2 = self.classifier2(pooled_output2)\n",
    "\n",
    "        # double_pooled_output = self.dense1(double_pooled_output)\n",
    "        # double_pooled_output = self.dense2(double_pooled_output)\n",
    "        # double_pooled_output = self.dropout(double_pooled_output)\n",
    "        # logits = self.classifier(double_pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        outputs2 = (logits2,) + outputs2[2:]\n",
    "\n",
    "        return outputs,outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a770a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:37.058813Z",
     "iopub.status.busy": "2023-03-16T15:40:37.058258Z",
     "iopub.status.idle": "2023-03-16T15:40:41.554198Z",
     "shell.execute_reply": "2023-03-16T15:40:41.552958Z"
    },
    "papermill": {
     "duration": 4.50427,
     "end_time": "2023-03-16T15:40:41.556826",
     "exception": false,
     "start_time": "2023-03-16T15:40:37.052556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=CustomBert(\"/kaggle/input/token-model-config/token_model_config/config/config.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4885404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:41.572895Z",
     "iopub.status.busy": "2023-03-16T15:40:41.571519Z",
     "iopub.status.idle": "2023-03-16T15:40:41.577751Z",
     "shell.execute_reply": "2023-03-16T15:40:41.576505Z"
    },
    "papermill": {
     "duration": 0.016144,
     "end_time": "2023-03-16T15:40:41.580307",
     "exception": false,
     "start_time": "2023-03-16T15:40:41.564163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44cc5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:41.592202Z",
     "iopub.status.busy": "2023-03-16T15:40:41.591913Z",
     "iopub.status.idle": "2023-03-16T15:40:42.485524Z",
     "shell.execute_reply": "2023-03-16T15:40:42.484490Z"
    },
    "papermill": {
     "duration": 0.902377,
     "end_time": "2023-03-16T15:40:42.488056",
     "exception": false,
     "start_time": "2023-03-16T15:40:41.585679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4324 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-cased'\n",
    "X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#X_train = train[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#np.vstack(X_test).shape : (476, 2, 512)\n",
    "X_test = np.vstack(X_test).reshape((len(X_test), 2048))\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b629dad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:42.499691Z",
     "iopub.status.busy": "2023-03-16T15:40:42.499381Z",
     "iopub.status.idle": "2023-03-16T15:40:48.710517Z",
     "shell.execute_reply": "2023-03-16T15:40:48.709596Z"
    },
    "papermill": {
     "duration": 6.21949,
     "end_time": "2023-03-16T15:40:48.712778",
     "exception": false,
     "start_time": "2023-03-16T15:40:42.493288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bert2): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dense2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=21, bias=True)\n",
       "  (classifier2): Linear(in_features=3072, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "model.bert2.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99751731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:40:48.726691Z",
     "iopub.status.busy": "2023-03-16T15:40:48.725842Z",
     "iopub.status.idle": "2023-03-16T15:45:10.350924Z",
     "shell.execute_reply": "2023-03-16T15:45:10.349825Z"
    },
    "papermill": {
     "duration": 261.634967,
     "end_time": "2023-03-16T15:45:10.353913",
     "exception": false,
     "start_time": "2023-03-16T15:40:48.718946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_dir_target = \"../input/Optimize binning/bert-base-cased\"#\n",
    "\n",
    "cased_pred_lst = []\n",
    "for fold in range(10):\n",
    "    # if fold in [0,1,2,3,4,5,6,7]:\n",
    "    #     continue\n",
    "    #bert_path = f\"{model_dir_target}/bert-base-cased_f{fold}_best\"\n",
    "    #bert_path=f\"./DoubleBertBasedCase/bce_no_opt_binning/double-bert-based-case_f{fold}_best\"\n",
    "    bert_path=f\"/kaggle/input/non-shared-weights-full-fold/double-bert-based-case_f{fold}_best\"\n",
    "    model.load_state_dict(torch.load(bert_path),strict=False)\n",
    "    \n",
    "    lst = []\n",
    "    for i, (x_batch,)  in enumerate(test_loader):\n",
    "        # input_ids = x_batch[:, :512]\n",
    "        # token_ids = x_batch[:, 512:]\n",
    "        input_ids = x_batch[:, :512]\n",
    "        token_ids = x_batch[:, 512:1024]\n",
    "        input_ids2 = x_batch[:, 1024:1536]\n",
    "        token_ids2 = x_batch[:, 1536:]\n",
    "        #pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n",
    "        pred, pred2 = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device),\n",
    "                     input_ids2=input_ids2.to(device),attention_mask2=(input_ids2 > 0).to(device),token_type_ids2=token_ids2.to(device))\n",
    "        total_y_pred=torch.cat((pred[0],pred2[0]),dim=1)\n",
    "        lst.append(total_y_pred.detach().cpu().squeeze().numpy())\n",
    "    train_pred = np.vstack(lst)#shape:(476, 30)\n",
    "    \n",
    "    cased_pred_lst.append(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e01b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.367472Z",
     "iopub.status.busy": "2023-03-16T15:45:10.367168Z",
     "iopub.status.idle": "2023-03-16T15:45:10.373523Z",
     "shell.execute_reply": "2023-03-16T15:45:10.372450Z"
    },
    "papermill": {
     "duration": 0.016563,
     "end_time": "2023-03-16T15:45:10.376813",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.360250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee84eba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.389639Z",
     "iopub.status.busy": "2023-03-16T15:45:10.389354Z",
     "iopub.status.idle": "2023-03-16T15:45:10.402533Z",
     "shell.execute_reply": "2023-03-16T15:45:10.401623Z"
    },
    "papermill": {
     "duration": 0.022327,
     "end_time": "2023-03-16T15:45:10.404807",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.382480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.9148734 ,  0.587064  , -1.0286921 , ..., -3.941702  ,\n",
       "          3.1086798 ,  2.7866452 ],\n",
       "        [ 1.9138436 , -0.14367293, -5.5822263 , ..., -2.0265658 ,\n",
       "         -2.8845265 ,  2.1542585 ],\n",
       "        [ 2.260144  ,  0.79723394, -4.245135  , ..., -3.3293252 ,\n",
       "          2.716329  ,  2.222594  ],\n",
       "        ...,\n",
       "        [ 1.6526252 , -0.7348393 , -4.6569324 , ..., -1.4699891 ,\n",
       "         -0.48530442,  1.9625344 ],\n",
       "        [ 3.1886616 ,  1.65253   , -4.2482276 , ..., -2.487862  ,\n",
       "          3.2956548 ,  2.9502597 ],\n",
       "        [ 2.3928847 ,  0.23803632, -3.6111562 , ..., -1.6057041 ,\n",
       "         -1.436203  ,  2.1055822 ]], dtype=float32),\n",
       " array([[ 2.5103562 ,  0.4560998 , -2.0337412 , ..., -3.6385992 ,\n",
       "          2.5943546 ,  2.7311163 ],\n",
       "        [ 1.9764315 , -0.17333023, -6.0549254 , ..., -1.9884542 ,\n",
       "         -2.7503848 ,  2.3761358 ],\n",
       "        [ 2.3559234 ,  0.88232833, -4.627334  , ..., -3.3722978 ,\n",
       "          2.693163  ,  2.3779893 ],\n",
       "        ...,\n",
       "        [ 1.5696975 , -0.6460703 , -4.480063  , ..., -1.7597276 ,\n",
       "          0.16211623,  2.448431  ],\n",
       "        [ 2.9438741 ,  1.5556777 , -3.6107452 , ..., -2.4905984 ,\n",
       "          2.6066184 ,  2.9100485 ],\n",
       "        [ 2.502829  , -0.0803836 , -4.2873483 , ..., -2.0626767 ,\n",
       "         -1.9099694 ,  2.1386993 ]], dtype=float32),\n",
       " array([[ 2.7413952,  0.496867 , -1.139848 , ..., -3.5026126,  2.8014877,\n",
       "          2.4525673],\n",
       "        [ 1.8546556, -0.2069725, -5.5248938, ..., -1.9294177, -2.886455 ,\n",
       "          2.0854151],\n",
       "        [ 2.554181 ,  0.9449199, -4.7781215, ..., -2.890626 ,  2.3344173,\n",
       "          2.1901612],\n",
       "        ...,\n",
       "        [ 1.8848642, -0.5185862, -4.894277 , ..., -1.6033951, -1.6913455,\n",
       "          1.8583863],\n",
       "        [ 2.6513493,  1.4080722, -3.4208438, ..., -2.7464566,  3.6349497,\n",
       "          2.7363162],\n",
       "        [ 2.2694721,  0.2298308, -3.7165246, ..., -1.9667454, -1.066046 ,\n",
       "          1.9637209]], dtype=float32),\n",
       " array([[ 2.8536336 ,  0.5542104 , -1.3037099 , ..., -3.724661  ,\n",
       "          2.59153   ,  2.4627233 ],\n",
       "        [ 1.6757438 , -0.20795949, -5.324018  , ..., -2.002275  ,\n",
       "         -3.1192534 ,  1.8289505 ],\n",
       "        [ 2.67334   ,  0.8955481 , -4.2523284 , ..., -3.5183883 ,\n",
       "          2.0763462 ,  2.4355874 ],\n",
       "        ...,\n",
       "        [ 1.5733831 , -0.7812666 , -3.744337  , ..., -1.8286331 ,\n",
       "          0.32921812,  1.7987208 ],\n",
       "        [ 3.0194287 ,  2.0560482 , -3.6404736 , ..., -2.19571   ,\n",
       "          3.1508353 ,  2.6381435 ],\n",
       "        [ 2.3509133 ,  0.07888155, -4.5634437 , ..., -1.6077472 ,\n",
       "         -0.05731663,  2.0099583 ]], dtype=float32),\n",
       " array([[ 2.6895049 ,  0.26972646, -1.8492643 , ..., -3.8140337 ,\n",
       "          2.1177216 ,  2.526196  ],\n",
       "        [ 1.7833078 ,  0.00873061, -5.233292  , ..., -1.7525615 ,\n",
       "         -2.696281  ,  2.3390772 ],\n",
       "        [ 2.477959  ,  0.80492586, -4.435641  , ..., -3.1765947 ,\n",
       "          3.0134478 ,  2.7113779 ],\n",
       "        ...,\n",
       "        [ 1.4198315 , -0.6476246 , -3.776957  , ..., -1.8199568 ,\n",
       "         -0.20344293,  2.4370806 ],\n",
       "        [ 2.780403  ,  2.115128  , -3.8020587 , ..., -2.4431937 ,\n",
       "          3.0494661 ,  2.587918  ],\n",
       "        [ 2.3771398 ,  0.17081822, -3.5545874 , ..., -1.982634  ,\n",
       "         -0.31577834,  2.4182804 ]], dtype=float32),\n",
       " array([[ 2.8235965 ,  0.44112587, -1.3306168 , ..., -4.1427617 ,\n",
       "          2.3605537 ,  2.4052274 ],\n",
       "        [ 1.5948689 , -0.39676344, -5.431217  , ..., -1.7371391 ,\n",
       "         -2.7527637 ,  2.0954149 ],\n",
       "        [ 2.3369076 ,  0.92123   , -3.394778  , ..., -3.7836857 ,\n",
       "          3.0509105 ,  2.3718312 ],\n",
       "        ...,\n",
       "        [ 1.7609894 , -0.60736793, -4.2109847 , ..., -1.3377182 ,\n",
       "          0.03783117,  2.206304  ],\n",
       "        [ 2.5287683 ,  1.578975  , -3.424511  , ..., -2.9056692 ,\n",
       "          3.559938  ,  2.7744796 ],\n",
       "        [ 2.1544816 ,  0.12568754, -3.2179406 , ..., -1.7783103 ,\n",
       "         -1.6189024 ,  2.010519  ]], dtype=float32),\n",
       " array([[ 2.80134   ,  0.43353873, -1.5575542 , ..., -3.2911704 ,\n",
       "          2.7167003 ,  2.2021053 ],\n",
       "        [ 1.8147142 ,  0.10664655, -5.2787476 , ..., -2.1068208 ,\n",
       "         -2.9643526 ,  2.3790815 ],\n",
       "        [ 2.5099387 ,  0.65911573, -4.8322988 , ..., -3.7833636 ,\n",
       "          3.5224454 ,  2.6479976 ],\n",
       "        ...,\n",
       "        [ 1.7268364 , -0.63026553, -4.4037356 , ..., -1.4332489 ,\n",
       "         -0.0845383 ,  2.6559012 ],\n",
       "        [ 2.4932666 ,  1.2886094 , -4.305385  , ..., -2.892618  ,\n",
       "          3.7375238 ,  2.9670742 ],\n",
       "        [ 2.2487023 , -0.13342859, -4.6940217 , ..., -2.0025773 ,\n",
       "         -1.0209801 ,  2.329883  ]], dtype=float32),\n",
       " array([[ 3.0332327 ,  0.3101499 , -1.7405896 , ..., -4.095989  ,\n",
       "          2.7210147 ,  2.6309109 ],\n",
       "        [ 1.9239987 , -0.12701896, -5.091317  , ..., -2.4283075 ,\n",
       "         -2.989905  ,  2.349406  ],\n",
       "        [ 2.2904654 ,  0.71181554, -4.5009336 , ..., -3.7010863 ,\n",
       "          3.1441548 ,  2.4558895 ],\n",
       "        ...,\n",
       "        [ 1.7633353 , -0.65154886, -3.958963  , ..., -1.6939642 ,\n",
       "         -0.8843996 ,  2.0595014 ],\n",
       "        [ 2.561701  ,  1.6283346 , -3.273214  , ..., -2.4250505 ,\n",
       "          3.2331762 ,  2.8914857 ],\n",
       "        [ 2.174029  , -0.03110481, -4.1821513 , ..., -2.3793206 ,\n",
       "         -0.61060333,  2.4704394 ]], dtype=float32),\n",
       " array([[ 2.9836061e+00,  4.8836255e-01, -1.4444852e+00, ...,\n",
       "         -4.3021269e+00,  3.0791318e+00,  2.5806334e+00],\n",
       "        [ 1.9159243e+00,  2.5673158e-02, -5.5604124e+00, ...,\n",
       "         -2.1879957e+00, -3.0817246e+00,  2.6186860e+00],\n",
       "        [ 2.5949299e+00,  7.3588663e-01, -4.1842351e+00, ...,\n",
       "         -3.7180855e+00,  3.3907645e+00,  2.6132977e+00],\n",
       "        ...,\n",
       "        [ 1.7730701e+00, -7.1660751e-01, -4.0451293e+00, ...,\n",
       "         -1.4466894e+00, -2.7978411e-01,  2.0171437e+00],\n",
       "        [ 2.8728821e+00,  1.4406238e+00, -3.6221802e+00, ...,\n",
       "         -2.2268443e+00,  2.2593338e+00,  2.5485733e+00],\n",
       "        [ 2.2660959e+00, -9.1619068e-04, -4.0312061e+00, ...,\n",
       "         -1.8790973e+00, -1.7195102e+00,  2.2321975e+00]], dtype=float32),\n",
       " array([[ 2.6330345 ,  0.36627933, -1.0524104 , ..., -4.110831  ,\n",
       "          3.3260808 ,  2.6060486 ],\n",
       "        [ 1.667268  , -0.14990926, -5.7948112 , ..., -1.9245124 ,\n",
       "         -3.4219625 ,  2.2009091 ],\n",
       "        [ 2.4642437 ,  0.72592056, -4.1336794 , ..., -2.9745278 ,\n",
       "          2.9030645 ,  2.320065  ],\n",
       "        ...,\n",
       "        [ 1.4474843 , -0.81010616, -4.1784062 , ..., -1.5448537 ,\n",
       "         -0.8040443 ,  1.741051  ],\n",
       "        [ 2.7158732 ,  1.7802429 , -3.4755192 , ..., -2.538691  ,\n",
       "          3.004346  ,  2.883173  ],\n",
       "        [ 2.1443026 , -0.14552179, -4.035122  , ..., -2.1688287 ,\n",
       "         -1.5552318 ,  1.9457449 ]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88cb6758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.418535Z",
     "iopub.status.busy": "2023-03-16T15:45:10.417771Z",
     "iopub.status.idle": "2023-03-16T15:45:10.425342Z",
     "shell.execute_reply": "2023-03-16T15:45:10.424378Z"
    },
    "papermill": {
     "duration": 0.016894,
     "end_time": "2023-03-16T15:45:10.427851",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.410957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6]]#(2,3)\n",
    "#b=[[7,8,9],[10,11,12]]\n",
    "a=np.array(a)\n",
    "#b=np.array(b)\n",
    "c=[]\n",
    "c.append(a)\n",
    "#c.append(b)\n",
    "np.array(c).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ee0e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.441184Z",
     "iopub.status.busy": "2023-03-16T15:45:10.440923Z",
     "iopub.status.idle": "2023-03-16T15:45:10.449428Z",
     "shell.execute_reply": "2023-03-16T15:45:10.448372Z"
    },
    "papermill": {
     "duration": 0.017481,
     "end_time": "2023-03-16T15:45:10.451508",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.434027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7984571 ,  0.44034237, -1.4480911 , ..., -3.8564487 ,\n",
       "         2.7417254 ,  2.5384173 ],\n",
       "       [ 1.8120759 , -0.12645765, -5.487586  , ..., -2.008405  ,\n",
       "        -2.9547608 ,  2.2427335 ],\n",
       "       [ 2.4518032 ,  0.80789244, -4.3384485 , ..., -3.4247983 ,\n",
       "         2.8845043 ,  2.434679  ],\n",
       "       ...,\n",
       "       [ 1.6572117 , -0.67442834, -4.2349787 , ..., -1.5938175 ,\n",
       "        -0.39036936,  2.1185055 ],\n",
       "       [ 2.775621  ,  1.6504242 , -3.6823158 , ..., -2.5352693 ,\n",
       "         3.1531842 ,  2.788747  ],\n",
       "       [ 2.288085  ,  0.04518995, -3.98935   , ..., -1.9433639 ,\n",
       "        -1.1310542 ,  2.1625025 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cased_pred_lst).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d6af43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.465666Z",
     "iopub.status.busy": "2023-03-16T15:45:10.464903Z",
     "iopub.status.idle": "2023-03-16T15:45:10.473185Z",
     "shell.execute_reply": "2023-03-16T15:45:10.472040Z"
    },
    "papermill": {
     "duration": 0.017385,
     "end_time": "2023-03-16T15:45:10.475251",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.457866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94259244, 0.6083406 , 0.1902955 , ..., 0.02070519, 0.9394443 ,\n",
       "        0.92679155],\n",
       "       [0.8596125 , 0.46842766, 0.00412077, ..., 0.11832326, 0.04951198,\n",
       "        0.90402186],\n",
       "       [0.9206932 , 0.6916602 , 0.01288849, ..., 0.03152938, 0.9470751 ,\n",
       "        0.91943383],\n",
       "       ...,\n",
       "       [0.83986336, 0.33750597, 0.01427344, ..., 0.16884747, 0.40362844,\n",
       "        0.8926889 ],\n",
       "       [0.9413441 , 0.83894837, 0.02454691, ..., 0.07342236, 0.95903397,\n",
       "        0.94206476],\n",
       "       [0.90788543, 0.5112956 , 0.01817529, ..., 0.12527877, 0.2439666 ,\n",
       "        0.89683133]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "cased_pred = np.array(cased_pred_lst).mean(0)\n",
    "cased_pred = sigmoid(cased_pred)\n",
    "cased_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa06093",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2023-03-16T15:45:10.487452",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.481465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#19th PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2436327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.501766Z",
     "iopub.status.busy": "2023-03-16T15:45:10.500970Z",
     "iopub.status.idle": "2023-03-16T15:45:10.506263Z",
     "shell.execute_reply": "2023-03-16T15:45:10.505252Z"
    },
    "papermill": {
     "duration": 0.014303,
     "end_time": "2023-03-16T15:45:10.508277",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.493974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####21th postprocessing############\n",
    "def postProcessing(x):\n",
    "\n",
    "    x = np.where(x>=0.9241, 1.0, x)\n",
    "    x = np.where(x<=0.0759, 0.0, x)\n",
    "\n",
    "    return x\n",
    "\n",
    "targets = ['question_conversational',\n",
    "           'question_type_compare', \n",
    "           'question_type_consequence', \n",
    "           'question_type_definition', \n",
    "           'question_type_entity', \n",
    "           'question_type_choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42bcca5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.521921Z",
     "iopub.status.busy": "2023-03-16T15:45:10.521652Z",
     "iopub.status.idle": "2023-03-16T15:45:10.537679Z",
     "shell.execute_reply": "2023-03-16T15:45:10.536802Z"
    },
    "papermill": {
     "duration": 0.025174,
     "end_time": "2023-03-16T15:45:10.539801",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.514627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[sub.columns[1:]] = cased_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e6a6663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.553907Z",
     "iopub.status.busy": "2023-03-16T15:45:10.553243Z",
     "iopub.status.idle": "2023-03-16T15:45:10.564306Z",
     "shell.execute_reply": "2023-03-16T15:45:10.563411Z"
    },
    "papermill": {
     "duration": 0.02043,
     "end_time": "2023-03-16T15:45:10.566365",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.545935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.loc[:, targets] = postProcessing(sub.loc[:, targets].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27bca9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T15:45:10.580759Z",
     "iopub.status.busy": "2023-03-16T15:45:10.579988Z",
     "iopub.status.idle": "2023-03-16T15:45:10.620294Z",
     "shell.execute_reply": "2023-03-16T15:45:10.619218Z"
    },
    "papermill": {
     "duration": 0.050135,
     "end_time": "2023-03-16T15:45:10.623033",
     "exception": false,
     "start_time": "2023-03-16T15:45:10.572898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.942592</td>\n",
       "      <td>0.608341</td>\n",
       "      <td>0.190296</td>\n",
       "      <td>0.394527</td>\n",
       "      <td>0.653499</td>\n",
       "      <td>0.488018</td>\n",
       "      <td>0.678720</td>\n",
       "      <td>0.661841</td>\n",
       "      <td>0.806845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926952</td>\n",
       "      <td>0.949924</td>\n",
       "      <td>0.623096</td>\n",
       "      <td>0.979302</td>\n",
       "      <td>0.984692</td>\n",
       "      <td>0.883128</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.939444</td>\n",
       "      <td>0.926792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.859613</td>\n",
       "      <td>0.468428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806487</td>\n",
       "      <td>0.759366</td>\n",
       "      <td>0.950711</td>\n",
       "      <td>0.550465</td>\n",
       "      <td>0.434654</td>\n",
       "      <td>0.107945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612518</td>\n",
       "      <td>0.955891</td>\n",
       "      <td>0.639856</td>\n",
       "      <td>0.976430</td>\n",
       "      <td>0.986246</td>\n",
       "      <td>0.885631</td>\n",
       "      <td>0.949764</td>\n",
       "      <td>0.118323</td>\n",
       "      <td>0.049512</td>\n",
       "      <td>0.904022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.920693</td>\n",
       "      <td>0.691660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766912</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.949284</td>\n",
       "      <td>0.610134</td>\n",
       "      <td>0.523464</td>\n",
       "      <td>0.176267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902476</td>\n",
       "      <td>0.905701</td>\n",
       "      <td>0.545887</td>\n",
       "      <td>0.960385</td>\n",
       "      <td>0.960636</td>\n",
       "      <td>0.775189</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>0.919434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.921804</td>\n",
       "      <td>0.466582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757888</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.927062</td>\n",
       "      <td>0.580946</td>\n",
       "      <td>0.452688</td>\n",
       "      <td>0.052629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733163</td>\n",
       "      <td>0.965430</td>\n",
       "      <td>0.682734</td>\n",
       "      <td>0.982170</td>\n",
       "      <td>0.989428</td>\n",
       "      <td>0.907438</td>\n",
       "      <td>0.872733</td>\n",
       "      <td>0.138131</td>\n",
       "      <td>0.785100</td>\n",
       "      <td>0.904953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.914812</td>\n",
       "      <td>0.473769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831799</td>\n",
       "      <td>0.810358</td>\n",
       "      <td>0.939746</td>\n",
       "      <td>0.625637</td>\n",
       "      <td>0.571752</td>\n",
       "      <td>0.145085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599233</td>\n",
       "      <td>0.902090</td>\n",
       "      <td>0.648120</td>\n",
       "      <td>0.957160</td>\n",
       "      <td>0.957328</td>\n",
       "      <td>0.809481</td>\n",
       "      <td>0.206990</td>\n",
       "      <td>0.137857</td>\n",
       "      <td>0.643624</td>\n",
       "      <td>0.907880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.942592                0.608341   \n",
       "1     46                             0.859613                0.468428   \n",
       "2     70                             0.920693                0.691660   \n",
       "3    132                             0.921804                0.466582   \n",
       "4    200                             0.914812                0.473769   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.190296                      0.394527   \n",
       "1                 0.000000                      0.806487   \n",
       "2                 0.000000                      0.766912   \n",
       "3                 0.000000                      0.757888   \n",
       "4                 0.000000                      0.831799   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.653499                               0.488018   \n",
       "1               0.759366                               0.950711   \n",
       "2               0.928296                               0.949284   \n",
       "3               0.731844                               0.927062   \n",
       "4               0.810358                               0.939746   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.678720                       0.661841   \n",
       "1                         0.550465                       0.434654   \n",
       "2                         0.610134                       0.523464   \n",
       "3                         0.580946                       0.452688   \n",
       "4                         0.625637                       0.571752   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.806845  ...               0.926952        0.949924   \n",
       "1               0.107945  ...               0.612518        0.955891   \n",
       "2               0.176267  ...               0.902476        0.905701   \n",
       "3               0.052629  ...               0.733163        0.965430   \n",
       "4               0.145085  ...               0.599233        0.902090   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.623096          0.979302          0.984692   \n",
       "1                     0.639856          0.976430          0.986246   \n",
       "2                     0.545887          0.960385          0.960636   \n",
       "3                     0.682734          0.982170          0.989428   \n",
       "4                     0.648120          0.957160          0.957328   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.883128                  0.010401               0.020705   \n",
       "1             0.885631                  0.949764               0.118323   \n",
       "2             0.775189                  0.035798               0.031529   \n",
       "3             0.907438                  0.872733               0.138131   \n",
       "4             0.809481                  0.206990               0.137857   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.939444             0.926792  \n",
       "1                        0.049512             0.904022  \n",
       "2                        0.947075             0.919434  \n",
       "3                        0.785100             0.904953  \n",
       "4                        0.643624             0.907880  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sub[sub.columns[1:]] = cased_pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 298.997656,
   "end_time": "2023-03-16T15:45:14.009943",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-16T15:40:15.012287",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
