{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "#from transformers import *\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from math import floor, ceil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/google-quest-challenge/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/google-quest-challenge/test.csv').fillna(' ')\n",
    "sub = pd.read_csv('../input/google-quest-challenge/sample_submission.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_segments_xlnet(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"<sep>\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return [0] * (max_seq_length - len(tokens)) + segments\n",
    "\n",
    "def _get_segments_bert(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))#padding\n",
    "\n",
    "def _get_ids_xlnet(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids =  [5] * (max_seq_length-len(token_ids)) + token_ids\n",
    "    return input_ids\n",
    "\n",
    "def _get_ids_bert(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))#padding\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length=512-1, \n",
    "                t_max_len=70-1, q_max_len=219, a_max_len=219):\n",
    "\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "    # print(type(t))\n",
    "    # print(t)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:#???\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = norm_token_length(q, q_new_len)#??\n",
    "        a = norm_token_length(a, a_new_len)#??\n",
    "        \n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def norm_token_length(tokens, l):\n",
    "    if len(tokens) > l:\n",
    "        head = l//2\n",
    "        tail = l - head\n",
    "        return tokens[:head] + tokens[-tail:]\n",
    "    else:\n",
    "        return tokens[:l]\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, cate, pretrained_weights, max_sequence_length=512):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    if \"bert-base\" in pretrained_weights:\n",
    "        stoken = [\"[CLS]\"] + [cate] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]#type:list\n",
    "        # print(stoken)\n",
    "        # print(\"==================\")\n",
    "        input_ids = _get_ids_bert(stoken, tokenizer, max_sequence_length)\n",
    "        input_segments = _get_segments_bert(stoken, max_sequence_length)\n",
    "        # print(input_ids)\n",
    "        # print(\"==================\")\n",
    "        # print(input_segments)\n",
    "        # print(\"==================\")\n",
    "\n",
    "    elif pretrained_weights == \"xlnet-base-cased\":\n",
    "        stoken = [cate] + title + [\"<sep>\"] + question + [\"<sep>\"] + answer + [\"<sep>\", \"<cls>\"]\n",
    "        input_ids = _get_ids_xlnet(stoken, tokenizer, max_sequence_length)\n",
    "        input_segments = _get_segments_xlnet(stoken, max_sequence_length)\n",
    "        try:\n",
    "            cls_index = input_segments.index(5) - 1\n",
    "        except ValueError:\n",
    "            cls_index = -1\n",
    "        input_segments[cls_index] = 2\n",
    "    \n",
    "    return [input_ids, input_segments]\n",
    "\n",
    "def convert_row(row, pretrained_weights):\n",
    "    # print(row)\n",
    "    # print(\"==================\")\n",
    "    if pretrained_weights == \"bert-base-uncased\":\n",
    "        c = f\"[{row['category'].lower()}]\"#type:str\n",
    "    elif pretrained_weights == \"bert-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    elif pretrained_weights == \"xlnet-base-cased\":\n",
    "        c = f\"[{row['category']}]\"#type:str\n",
    "    t, q, a = title = row[\"question_title\"], row[\"question_body\"], row[\"answer\"]#type:str\n",
    "    # print(type(t))\n",
    "    # print(t)\n",
    "    # print(c)\n",
    "    # print(type(c))\n",
    "    #print(\"=====================\")\n",
    "    t, q, a = _trim_input(t, q, a)\n",
    "    ids, segments = _convert_to_bert_inputs(t, q, a, c, pretrained_weights)\n",
    "    \n",
    "    return np.array([[ids, segments]])#shape:(1, 2, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=\"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./token_model_config/tokenizer/\")\n",
    "#tokenizer.add_tokens(\"./bert_based_tokenizer/added_tokens.json\")\n",
    "#tokenizer.add_tokens(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    mse = nn.MSELoss(reduction=\"none\")(data[:,:30].sigmoid(), targets[:,:30])\n",
    "    bce = nn.BCEWithLogitsLoss(reduction='none')(data[:,:30], targets[:,:30])\n",
    "    w =  targets[:,30:]\n",
    "    loss = (mse*w).sum() + bce.sum()\n",
    "    return loss\n",
    "\n",
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, config_path=None):\n",
    "        super(CustomBert, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(config_path) \n",
    "        #self.config = torch.load(config_path,output_hidden_states=True)\n",
    "        self.config.num_labels = 30\n",
    "        self.config.output_hidden_states = True\n",
    "        self.n_use_layer = 4\n",
    "        self.n_labels = self.config.num_labels\n",
    "        #self.config.save_pretrained(\"bert_based_config\")\n",
    "        #self.bert = BertModel(config)\n",
    "        self.bert=AutoModel.from_config(self.config)\n",
    "        #self.bert.save_pretrained('bert_based_model')\n",
    "        self.dense1 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        self.dense2 = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.hidden_size*self.n_use_layer)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.config.hidden_size*self.n_use_layer, self.config.num_labels)\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
    "                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "\n",
    "        # outputs = self.bert(input_ids,\n",
    "        #                     attention_mask=attention_mask,\n",
    "        #                     token_type_ids=token_type_ids,\n",
    "        #                     position_ids=position_ids,\n",
    "        #                     head_mask=head_mask,\n",
    "        #                     inputs_embeds=inputs_embeds)\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                            )\n",
    "        \n",
    "        pooled_output = torch.cat([outputs[2][-1*(i+1)][:,0] for i in range(self.n_use_layer)], dim=1)\n",
    "        pooled_output = self.dense1(pooled_output)\n",
    "        pooled_output = self.dense2(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CustomBert(\"token_model_config/config/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4324 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-cased'\n",
    "#X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].progress_apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "X_test = test[[\"question_title\", \"question_body\", \"answer\", \"category\"]].apply(lambda x: convert_row(x, pretrained_weights), axis=1).values#shape(476)\n",
    "#np.vstack(X_test).shape : (476, 2, 512)\n",
    "X_test = np.vstack(X_test).reshape((len(X_test), 1024))\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 1024)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29001, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dense2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=3072, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.bert.resize_token_embeddings(len(tokenizer))#??\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dir_target = \"../input/Optimize binning/bert-base-cased\"#\n",
    "\n",
    "cased_pred_lst = []\n",
    "for fold in range(10):\n",
    "    if fold in [0,1,2,3,4,5,6,7,8]:\n",
    "        continue\n",
    "    #bert_path = f\"{model_dir_target}/bert-base-cased_f{fold}_best\"\n",
    "    bert_path=f\"./bert_based_case/no_bce_no_opt_binning/bert-based-case_f{fold}_best\"\n",
    "    model.load_state_dict(torch.load(bert_path),strict=False)\n",
    "    \n",
    "    lst = []\n",
    "    for i, (x_batch,)  in enumerate(test_loader):\n",
    "        input_ids = x_batch[:, :512]\n",
    "        token_ids = x_batch[:, 512:]\n",
    "        pred = model(input_ids.to(device), attention_mask=(input_ids > 0).to(device), token_type_ids=token_ids.to(device))\n",
    "        \n",
    "        lst.append(pred[0].detach().cpu().squeeze().numpy())\n",
    "    test_pred = np.vstack(lst)#shape:(476, 30)\n",
    "    \n",
    "    cased_pred_lst.append(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cased_pred_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9526806 , 0.683275  , 0.05784913, ..., 0.02111472, 0.9475731 ,\n",
       "        0.9419046 ],\n",
       "       [0.75497913, 0.42909217, 0.00516468, ..., 0.05026854, 0.02080454,\n",
       "        0.87417156],\n",
       "       [0.9288383 , 0.76316243, 0.02282806, ..., 0.06160448, 0.95960975,\n",
       "        0.9164232 ],\n",
       "       ...,\n",
       "       [0.8807903 , 0.43563855, 0.0088164 , ..., 0.19514424, 0.3707464 ,\n",
       "        0.8879043 ],\n",
       "       [0.9017531 , 0.769908  , 0.00463597, ..., 0.01312383, 0.9181951 ,\n",
       "        0.93142515],\n",
       "       [0.94508386, 0.537904  , 0.02420256, ..., 0.02967194, 0.11720841,\n",
       "        0.95941395]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "cased_pred = np.array(cased_pred_lst).mean(0)\n",
    "cased_pred = sigmoid(cased_pred)\n",
    "cased_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred = bert_pred*0.4 + cased_pred*0.6\n",
    "test_pred=cased_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lgbm_models = pickle.load(open(\"C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/26th-solution/inference/input/quest-lgbm/lgbm_question_type_spelling.pkl\", 'rb'))\n",
    "count_vectorizers = pickle.load(open(\"C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/26th-solution/inference/input/quest-lgbm/tfidf_vectorizers.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will leaving corpses lying around upset my prisoners?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"question_title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<476x604 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1666 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizers[0].transform(test[\"question_title\"])#將字串轉換成604維度的稀疏矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476, 8325)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for idx, col_name in enumerate([\"question_title\", \"question_body\", \"answer\"]):\n",
    "    X = count_vectorizers[idx].transform(test[col_name])\n",
    "    \n",
    "    feat = [f\"{col_name}_{c}\".encode(\"utf-8\") for c in count_vectorizers[idx].get_feature_names()]\n",
    "    #print(len(feat))\n",
    "    # print(\"=========================\")\n",
    "    df = pd.DataFrame(X.toarray(), columns=feat)\n",
    "    #print(df)\n",
    "    dfs.append(df)\n",
    "test_x = pd.concat(dfs, axis=1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pred = np.zeros(len(test_x))\n",
    "for fold in range(4):\n",
    "    lgbm_pred += lgbm_models[fold].predict(test_x)/4\n",
    "lgbm_pred.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_asker_intent_understanding', 'question_body_critical',\n",
       "       'question_conversational', 'question_expect_short_answer',\n",
       "       'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.5, 0, 1]\n",
      "{0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5}\n"
     ]
    }
   ],
   "source": [
    "unique_values=train[\"answer_type_procedure\"].unique()\n",
    "print(list(unique_values)+[0,1])\n",
    "print(set(list(unique_values)+[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_asker_intent_understanding': 18,\n",
       " 'question_body_critical': 18,\n",
       " 'question_conversational': 6,\n",
       " 'question_expect_short_answer': 6,\n",
       " 'question_fact_seeking': 6,\n",
       " 'question_has_commonly_accepted_answer': 6,\n",
       " 'question_interestingness_others': 18,\n",
       " 'question_interestingness_self': 18,\n",
       " 'question_multi_intent': 6,\n",
       " 'question_not_really_a_question': 6,\n",
       " 'question_opinion_seeking': 6,\n",
       " 'question_type_choice': 6,\n",
       " 'question_type_compare': 6,\n",
       " 'question_type_consequence': 6,\n",
       " 'question_type_definition': 6,\n",
       " 'question_type_entity': 6,\n",
       " 'question_type_instructions': 6,\n",
       " 'question_type_procedure': 6,\n",
       " 'question_type_reason_explanation': 6,\n",
       " 'question_type_spelling': 3,\n",
       " 'question_well_written': 18,\n",
       " 'answer_helpful': 18,\n",
       " 'answer_level_of_information': 18,\n",
       " 'answer_plausible': 18,\n",
       " 'answer_relevance': 18,\n",
       " 'answer_satisfaction': 30,\n",
       " 'answer_type_instructions': 6,\n",
       " 'answer_type_procedure': 6,\n",
       " 'answer_type_reason_explanation': 6,\n",
       " 'answer_well_written': 18}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict = {}\n",
    "for c in sub.columns[1:]:\n",
    "  unique_values = train[c].unique()\n",
    "  unique_values = list(set(list(unique_values)+[0,1]))\n",
    "  lst = []\n",
    "  for common_num in range(90):#90? 0\n",
    "    num = 90 - common_num#90\n",
    "    bunbo = [round((1/num)*n, 8) for n in range(num+1)]\n",
    "    #print(len(bunbo))\n",
    "    kyoutu = [round(v, 8) for v in unique_values if round(v, 8) in bunbo]\n",
    "    #print(kyoutu)\n",
    "    if len(kyoutu) == len(unique_values):\n",
    "      lst.append(num)\n",
    "  norm_dict[c] = min(lst)\n",
    "norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_corr(y_true, y_pred):\n",
    "    if np.ndim(y_pred) == 2:\n",
    "        corr = np.nan_to_num([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])]).mean()\n",
    "    else:\n",
    "        corr = stats.spearmanr(y_true, y_pred)[0]\n",
    "    return corr\n",
    "\n",
    "\n",
    "# ref: https://qiita.com/kaggle_master-arai-san/items/d59b2fb7142ec7e270a5\n",
    "# thank you kaggle masterのアライさん!!\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self,\n",
    "                 n_overall: int = 5,\n",
    "                 n_classwise: int = 5,\n",
    "                 n_classes: int = 7,\n",
    "                 metric: str = \"qwk\"):\n",
    "        self.n_overall = n_overall\n",
    "        self.n_classwise = n_classwise\n",
    "        self.n_classes = n_classes\n",
    "        self.coef = [1.0 / n_classes * i for i in range(1, n_classes)]\n",
    "        self.metric_str = metric\n",
    "        self.metric = spearman_corr\n",
    "\n",
    "    def _loss(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        X_p = np.digitize(X, self.coef)\n",
    "        ll = -self.metric(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [\n",
    "            (0.01, 1.0 / self.n_classes + 0.05),\n",
    "        ]\n",
    "        for i in range(1, self.n_classes):\n",
    "            ab_start.append((i * 1.0 / self.n_classes + 0.05,\n",
    "                             (i + 1) * 1.0 / self.n_classes + 0.05))\n",
    "        for _ in range(self.n_overall):\n",
    "            for idx in range(self.n_classes - 1):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                self.coef[idx] = a\n",
    "                la = self._loss(X, y)\n",
    "                self.coef[idx] = b\n",
    "                lb = self._loss(X, y)\n",
    "                for it in range(self.n_classwise):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        self.coef[idx] = a\n",
    "                        la = self._loss(X, y)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        self.coef[idx] = b\n",
    "                        lb = self._loss(X, y)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        X_p = np.digitize(X, self.coef)\n",
    "        return X_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR_lst = pickle.load(open(\"C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/26th-solution/inference/input/quest-optimizedrounder/optR_lst_10fold_ensemble_v3.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optR_lst[25].coef)#類別數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010000018984111226,\n",
       " 0.10263158973379526,\n",
       " 0.15526316868116366,\n",
       " 0.20789474762853208,\n",
       " 0.26052632657590047,\n",
       " 0.3131579055232689,\n",
       " 0.3657894844706373,\n",
       " 0.4184210634180057,\n",
       " 0.47105264236537414,\n",
       " 0.5236842213127426,\n",
       " 0.5763158002601111,\n",
       " 0.6289473792074796,\n",
       " 0.7199743973515239,\n",
       " 0.7769234872385886,\n",
       " 0.8270511143653743,\n",
       " 0.8669055421005689,\n",
       " 0.9245306419996713,\n",
       " 0.9466500749755824]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR_lst[0].coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "18\n",
      "18\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "30\n",
      "6\n",
      "6\n",
      "6\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for optR in optR_lst:\n",
    "    print(len(optR.coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_asker_intent_understanding': 18,\n",
       " 'question_body_critical': 18,\n",
       " 'question_conversational': 6,\n",
       " 'question_expect_short_answer': 6,\n",
       " 'question_fact_seeking': 6,\n",
       " 'question_has_commonly_accepted_answer': 6,\n",
       " 'question_interestingness_others': 18,\n",
       " 'question_interestingness_self': 18,\n",
       " 'question_multi_intent': 6,\n",
       " 'question_not_really_a_question': 6,\n",
       " 'question_opinion_seeking': 6,\n",
       " 'question_type_choice': 6,\n",
       " 'question_type_compare': 6,\n",
       " 'question_type_consequence': 6,\n",
       " 'question_type_definition': 6,\n",
       " 'question_type_entity': 6,\n",
       " 'question_type_instructions': 6,\n",
       " 'question_type_procedure': 6,\n",
       " 'question_type_reason_explanation': 6,\n",
       " 'question_type_spelling': 3,\n",
       " 'question_well_written': 18,\n",
       " 'answer_helpful': 18,\n",
       " 'answer_level_of_information': 18,\n",
       " 'answer_plausible': 18,\n",
       " 'answer_relevance': 18,\n",
       " 'answer_satisfaction': 30,\n",
       " 'answer_type_instructions': 6,\n",
       " 'answer_type_procedure': 6,\n",
       " 'answer_type_reason_explanation': 6,\n",
       " 'answer_well_written': 18}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#測試OptimizedRounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.026483684940355287,\n",
       " 0.2057350217167954,\n",
       " 0.34859216457393827,\n",
       " 0.4914493074310811,\n",
       " 0.6343064502882241,\n",
       " 0.7771635931453669]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_OptimizedRounder=OptimizedRounder()\n",
    "train_sample=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "train_y_sample=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "test_OptimizedRounder.fit(train_sample,train_y_sample)\n",
    "test_OptimizedRounder.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.OptimizedRounder at 0x1be39ba5388>,\n",
       " <__main__.OptimizedRounder at 0x1be3905e148>,\n",
       " <__main__.OptimizedRounder at 0x1be108d99c8>,\n",
       " <__main__.OptimizedRounder at 0x1be108d9048>,\n",
       " <__main__.OptimizedRounder at 0x1be108d9cc8>,\n",
       " <__main__.OptimizedRounder at 0x1be108a3a88>,\n",
       " <__main__.OptimizedRounder at 0x1be108a3808>,\n",
       " <__main__.OptimizedRounder at 0x1be108a3688>,\n",
       " <__main__.OptimizedRounder at 0x1be108a3e88>,\n",
       " <__main__.OptimizedRounder at 0x1be108a3908>,\n",
       " <__main__.OptimizedRounder at 0x1be10946408>,\n",
       " <__main__.OptimizedRounder at 0x1be10946988>,\n",
       " <__main__.OptimizedRounder at 0x1be0e19ab08>,\n",
       " <__main__.OptimizedRounder at 0x1be10948748>,\n",
       " <__main__.OptimizedRounder at 0x1be10948948>,\n",
       " <__main__.OptimizedRounder at 0x1be10948fc8>,\n",
       " <__main__.OptimizedRounder at 0x1be109484c8>,\n",
       " <__main__.OptimizedRounder at 0x1be109488c8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948d48>,\n",
       " <__main__.OptimizedRounder at 0x1be10948dc8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948148>,\n",
       " <__main__.OptimizedRounder at 0x1be109487c8>,\n",
       " <__main__.OptimizedRounder at 0x1be109481c8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948248>,\n",
       " <__main__.OptimizedRounder at 0x1be10948448>,\n",
       " <__main__.OptimizedRounder at 0x1be109483c8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948cc8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948ec8>,\n",
       " <__main__.OptimizedRounder at 0x1be109485c8>,\n",
       " <__main__.OptimizedRounder at 0x1be10948648>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optR_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optR_lst = pickle.load(open(\"C:/Users/Lab000/Desktop/kaggle/kaggle_competetion/Google_Quest_LABEL/26th-solution/inference/input/quest-optimizedrounder/optR_lst_10fold_ensemble_v3.pkl\", 'rb'))\n",
    "\n",
    "lst = []\n",
    "for idx, optR in enumerate(optR_lst):\n",
    "    \n",
    "    coeff = optR.predict(test_pred[:, idx])#ouput:476\n",
    "    lst.append(coeff/norm_dict[sub.columns[1:][idx]])#476\n",
    "    #print(len(lst[idx]))\n",
    "#print(np.array(lst).shape)\n",
    "opt_preds = np.array(lst).T\n",
    "test_pred = opt_preds\n",
    "test_pred[:,19]=cased_pred[:,19]#不能有全欄位在全部的列都等於0\n",
    "#test_pred[:,19] = lgbm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66666667, 0.        , ..., 0.        , 1.        ,\n",
       "        0.88888889],\n",
       "       [0.77777778, 0.44444444, 0.        , ..., 0.        , 0.        ,\n",
       "        0.83333333],\n",
       "       [0.94444444, 0.77777778, 0.        , ..., 0.        , 1.        ,\n",
       "        0.88888889],\n",
       "       ...,\n",
       "       [0.83333333, 0.33333333, 0.        , ..., 0.16666667, 0.33333333,\n",
       "        0.88888889],\n",
       "       [0.88888889, 0.83333333, 0.        , ..., 0.        , 1.        ,\n",
       "        0.88888889],\n",
       "       [0.94444444, 0.5       , 0.        , ..., 0.        , 0.        ,\n",
       "        0.94444444]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[:,19] = lgbm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[test[test[\"category\"] != \"CULTURE\"].index, 19] = 0.0\n",
    "\n",
    "test[\"host_info\"] = test[\"question_user_page\"].map(lambda x: x.split(\"/\")[2].replace(\".stackexchange.com\", \"\"))\n",
    "test_pred[test[test[\"host_info\"].map(lambda x: x not in [\"english\", \"ell\"])].index, 19] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             1.000000                0.666667   \n",
       "1     46                             0.777778                0.444444   \n",
       "2     70                             0.944444                0.777778   \n",
       "3    132                             1.000000                0.500000   \n",
       "4    200                             0.944444                0.500000   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                      0.0                      0.833333   \n",
       "1                      0.0                      1.000000   \n",
       "2                      0.0                      1.000000   \n",
       "3                      0.0                      1.000000   \n",
       "4                      0.0                      1.000000   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.500000                                    1.0   \n",
       "1               0.833333                                    1.0   \n",
       "2               0.833333                                    1.0   \n",
       "3               0.833333                                    1.0   \n",
       "4               0.833333                                    1.0   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.722222                       0.611111   \n",
       "1                         0.555556                       0.444444   \n",
       "2                         0.666667                       0.555556   \n",
       "3                         0.611111                       0.444444   \n",
       "4                         0.555556                       0.555556   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.666667  ...               0.944444        0.944444   \n",
       "1               0.166667  ...               0.555556        0.944444   \n",
       "2               0.000000  ...               0.888889        0.888889   \n",
       "3               0.000000  ...               0.777778        0.944444   \n",
       "4               0.166667  ...               0.666667        0.944444   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.500000          1.000000          1.000000   \n",
       "1                     0.666667          1.000000          1.000000   \n",
       "2                     0.500000          0.944444          0.944444   \n",
       "3                     0.666667          1.000000          1.000000   \n",
       "4                     0.666667          1.000000          0.944444   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.8                  0.000000               0.000000   \n",
       "1                  0.9                  1.000000               0.000000   \n",
       "2                  0.7                  0.000000               0.000000   \n",
       "3                  0.9                  0.666667               0.000000   \n",
       "4                  0.8                  0.333333               0.333333   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        1.000000             0.888889  \n",
       "1                        0.000000             0.833333  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             0.944444  \n",
       "4                        0.666667             0.944444  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.columns[1:]] = test_pred\n",
    "sub.to_csv(\"加上post_posprocessing_submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_learning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "490296f01f129d1791d2b0949f01d8bcbb5336528260279af7e468eefab7c316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
